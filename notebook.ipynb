{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/gerritgr/MaskedGraphGen/blob/main/notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ulnOzsCCmA8g"
   },
   "source": [
    "\n",
    "# <img src=\"https://mario.wiki.gallery/images/thumb/8/89/MPS_Toad_Artwork.png/170px-MPS_Toad_Artwork.png\" alt=\"Dataset Summary\" width=\"3%\">  Batched Toad  <img src=\"https://mario.wiki.gallery/images/thumb/8/89/MPS_Toad_Artwork.png/170px-MPS_Toad_Artwork.png\" alt=\"Dataset Summary\" width=\"3%\"> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rCWLJT5DLH78"
   },
   "source": [
    "Todos:\n",
    "- weightes sampling\n",
    "- multi-channel\n",
    "- uncertainty\n",
    "- better ensable like skip one during training or learn weights\n",
    "- to make network better: virutal node, degree input, spectral input, edge \n",
    "features\n",
    "- fix order, e.g. based on degree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x-k6-4CDmEwH"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Csn1_ff8mJCE"
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "if IN_COLAB:\n",
    "  os.system(\"pip install wandb -Uq\")\n",
    "  #!pip install torch==1.8.0+cu111 torchvision==0.9.0+cu111 torchaudio==0.8.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "  #os.system(\"pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv torch_geometric -f https://data.pyg.org/whl/torch-1.13.0+cu117.html\")\n",
    "  os.system(\"pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\")\n",
    "  os.system(\"pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\")\n",
    "  os.system(\"pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\")\n",
    "  os.system(\"pip install pyemd\")\n",
    "\n",
    "\n",
    "PATH_TO_NOTEBOOK = \"Batched Toad 3.ipynb\"\n",
    "PROJECT_NAME = \"toad_double\"\n",
    "KEY = \"e306abc657482e172a5ccc8d7c0b81bc4d297dd4\"\n",
    "WANDB_MODE = \"online\"   # \"online\" or \"dryrun\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "cN9PW__MvfFk"
   },
   "outputs": [],
   "source": [
    "def get_wand_api_key():\n",
    "  api_key = KEY\n",
    "  # use   echo \"your_api_key_here\" > ~/api_key.txt   to write the api key to the home file dir    \n",
    "  if api_key != \"\":\n",
    "    return api_key\n",
    "  home_dir = os.path.expanduser('~')\n",
    "  file_path = os.path.join(home_dir, 'api_key.txt')\n",
    "  with open(file_path, 'r') as file:\n",
    "      api_key = file.read().strip()\n",
    "  return api_key\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mUcQ44Bj42GY"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "nKbKpbiSmMfW"
   },
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.dpi'] = 100 # Set this to 300 to get better image quality\n",
    "from PIL import Image # We use PIL to load images\n",
    "import seaborn as sns\n",
    "import imageio # to generate .gifs\n",
    "\n",
    "# always good to have\n",
    "import glob, random, os, traceback\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import math\n",
    "\n",
    "# the typical pytorch imports\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torch.nn import Linear as Lin\n",
    "from torch.nn import Sequential as Seq\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# PyG\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import erdos_renyi_graph, to_networkx, from_networkx\n",
    "from torch_geometric.nn import GINConv\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import global_mean_pool, global_add_pool\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "#Video\n",
    "from PIL import Image, ImageDraw\n",
    "#import cv2\n",
    "from IPython.display import HTML\n",
    "from base64 import b64encode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SAyrOuvomPAE"
   },
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZaElc28pmSzf",
    "outputId": "93b40587-aa74-40ea-b2a5-7e8b889f47a2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_NODES = 12 #12   \n",
    "DEGREE = 3 #3\n",
    "NUM_EPOCHS = 1000\n",
    "\n",
    "NUM_SAMPLES = 1000\n",
    "NUM_GRAPHS_GENERATE = 10 # 40 in compare set, but they use 10 in spectre\n",
    "\n",
    "GENERATE_X_EPOCHS = 100\n",
    "\n",
    "NO_EDGE_INDICATOR = 3.0\n",
    "EDGE_INDICATOR = 1.0 \n",
    "DUMMY = 0.0 # this node is an actual node not a placeholder for an edge\n",
    "MASK = 2.0\n",
    "NUM_CLASSES = 4  #todo change to 5 an\n",
    "\n",
    "EPSILON = 0.000000001\n",
    "\n",
    "NODE_FEATURE_EXTEND = 3\n",
    "\n",
    "# do i need this\n",
    "#BATCH_SIZE_TEST = 10\n",
    "\n",
    "#TIME_EMBEDDING_DIM = 1\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#DEVICE = torch.device('cpu')\n",
    "DEVICE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qWpdimGn3fDH"
   },
   "source": [
    "### Seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "eCtxrGI4mVz2"
   },
   "outputs": [],
   "source": [
    "# from stack overflow\n",
    "def str_to_float(s, encoding=\"utf-8\"):\n",
    "  from zlib import crc32\n",
    "  def bytes_to_float(b):\n",
    "    return float(crc32(b) & 0xffffffff) / 2**32\n",
    "  return bytes_to_float(s.encode(encoding))\n",
    "\n",
    "    \n",
    "def set_seeds(seed=42):\n",
    "  if not \"int\" in str(type(seed)):\n",
    "    seed = int(str_to_float(str(seed))*1000 % 100000000)\n",
    "  np.random.seed(seed)\n",
    "  torch.random.manual_seed(seed)\n",
    "  random.seed(seed)\n",
    "  torch.cuda.manual_seed_all(seed)\n",
    "  os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "  torch.backends.cudnn.deterministic = True\n",
    "\n",
    "set_seeds()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "32hyXlJG8360"
   },
   "source": [
    "## Weights and Biases Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i_pixfTW84rq",
    "outputId": "2d61a2f9-8b76-4999-b2a9-22f371c013d8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgerritgr\u001b[0m (\u001b[33mnextaid\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /Users/gerritgrossmann/.netrc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'method': 'random',\n",
      " 'metric': {'goal': 'minimize', 'name': 'graph-unmasking/gen-loss'},\n",
      " 'name': 'graph-unmasking',\n",
      " 'parameters': {'batch_size': {'values': [100]},\n",
      "                'candidate_selection_radius': {'values': [1, 5]},\n",
      "                'double_inference': {'values': [True, False]},\n",
      "                'dropout': {'values': [0.0]},\n",
      "                'graph_transform': {'values': [True, False]},\n",
      "                'hidden_dim': {'values': [16, 32, 64]},\n",
      "                'hidden_layer': {'values': [4, 5, 6]},\n",
      "                'learning_rate': {'values': [1e-05, 0.0001]},\n",
      "                'loss': {'values': ['bce']},\n",
      "                'model': {'values': ['pna']},\n",
      "                'noise_probability': {'values': [0.0, 0.05, 0.1]},\n",
      "                'normalization': {'values': [True, False]},\n",
      "                'pre_post_layers': {'values': [1]},\n",
      "                'single_pass': {'values': [True]},\n",
      "                'towers': {'values': [1, 2]}}}\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login(key=get_wand_api_key())\n",
    "\n",
    "sweep_config = {\n",
    "    \"name\": \"graph-unmasking\",\n",
    "    \"method\": \"random\",\n",
    "    \"metric\": {\n",
    "        \"name\": \"graph-unmasking/gen-loss\",\n",
    "        \"goal\": \"minimize\",\n",
    "    },\n",
    "    \"parameters\": {\n",
    "        \"batch_size\": {\"values\": [100]},  # write only\n",
    "        \"hidden_dim\": {\"values\": [16,32, 64]},  \n",
    "        \"hidden_layer\": {\"values\": [4,5,6]},\n",
    "        \"learning_rate\": {\"values\": [0.00001,0.0001]},\n",
    "        \"dropout\": {\"values\": [0.0]},\n",
    "        \"normalization\": {\"values\": [True, False]},\n",
    "        \"model\": {\"values\": [\"pna\"]},  # [ \"pnamulti\", \"pna\",\"pna2\", \"attention\",\"transformer\", \"unet\"]}, \n",
    "        \"candidate_selection_radius\": {\"values\": [1, 5]},\n",
    "        \"loss\": {\"values\": [\"bce\"]},   # \"loss\": {\"values\": [\"l2\",\"l1\", \"bce\"]}, \n",
    "        \"single_pass\": {\"values\": [True]},  \n",
    "        \"towers\": {\"values\": [1, 2]},   \n",
    "        \"noise_probability\": {\"values\": [0.0, 0.05, 0.1]},\n",
    "        \"graph_transform\": {\"values\": [True, False]},    \n",
    "        \"pre_post_layers\": {\"values\": [1]},   \n",
    "        \"double_inference\": {\"values\": [True, False]}, \n",
    "    },\n",
    "}\n",
    "\n",
    "import pprint\n",
    "pprint.pprint(sweep_config)\n",
    "torch.set_printoptions(threshold=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dQyrEbzkmMCL"
   },
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "9_zto3HQmp5v"
   },
   "outputs": [],
   "source": [
    "def lift_nx_to_pyg(g_nx):\n",
    "  import torch_geometric.transforms as T\n",
    "  transform = T.Compose([T.ToUndirected()])\n",
    "\n",
    "  # g_nx has to have node_labels 0 ... number_of_nodes-1\n",
    "  num_nodes = g_nx.number_of_nodes()\n",
    "  g_complete_nx = nx.complete_graph(num_nodes)\n",
    "\n",
    "  edges_new = list()\n",
    "  node_value_dict = dict()\n",
    "  for v1, v2 in g_complete_nx.edges():\n",
    "    v3 = (v1+1)*10000+(v2+1)*100000000000\n",
    "    edges_new.append((v1, v3))\n",
    "    edges_new.append((v2, v3))\n",
    "    node_value_dict[v1] = DUMMY\n",
    "    node_value_dict[v2] = DUMMY\n",
    "    node_value_dict[v3] = EDGE_INDICATOR if g_nx.has_edge(v1,v2) else NO_EDGE_INDICATOR\n",
    "\n",
    "  graph_new = nx.from_edgelist(edges_new)\n",
    "  for node, x_value in node_value_dict.items():\n",
    "    graph_new.nodes[node]['x'] = x_value\n",
    "\n",
    "  graph_new = nx.convert_node_labels_to_integers(graph_new, ordering='sorted')\n",
    "\n",
    "  g = from_networkx(graph_new, group_node_attrs=['x'])\n",
    "  g = transform(g)  # probably unnecs.\n",
    "  return g\n",
    "\n",
    "\n",
    "def reduce_nx_graph(g_old):\n",
    "  g_new = nx.Graph()\n",
    "  for v_i in g_old.nodes():\n",
    "    if g_old.nodes[v_i]['x'] == DUMMY:\n",
    "      g_new.add_node(v_i)\n",
    "      g_new.nodes[v_i]['x'] = DUMMY\n",
    "\n",
    "  for v_i in g_old.nodes():\n",
    "    if g_old.nodes[v_i]['x'] == EDGE_INDICATOR:\n",
    "      neigh_list = list(g_old.neighbors(v_i))\n",
    "      assert(len(neigh_list) == 2)\n",
    "      g_new.add_edge(neigh_list[0], neigh_list[1])\n",
    "\n",
    "  return g_new\n",
    "\n",
    "def pyg_graph_to_nx(g_pyg):\n",
    "  g_nx = to_networkx(g_pyg, node_attrs=['x'], to_undirected=True,)\n",
    "  g_nx = reduce_nx_graph(g_nx)\n",
    "  return g_nx\n",
    "\n",
    "def draw_pyg(g_pyg, ax = None, filename = None):\n",
    "  if ax is None:\n",
    "    plt.clf()\n",
    "\n",
    "  g_nx = pyg_graph_to_nx(g_pyg)\n",
    "\n",
    "  node_labels = {i: g_nx.nodes[i]['x'] for i in g_nx.nodes}\n",
    "  pos = nx.spring_layout(g_nx, seed=1234)\n",
    "  try:\n",
    "    nx.draw(g_nx, with_labels = True, labels=node_labels, ax=ax, pos=pos)\n",
    "  except:\n",
    "    pass\n",
    "  if filename is not None:\n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "  return g_nx\n",
    "\n",
    "\n",
    "def shuffle_tensor(x):\n",
    "  x = x.clone()\n",
    "  x_shape = x.shape\n",
    "  x = x.flatten()\n",
    "  x = x[torch.randperm(x.numel())]\n",
    "  return x.reshape(x.shape)\n",
    "\n",
    "\n",
    "def note_features_to_one_hot(x):\n",
    "  # create indicator vector for NUM_CLASSES classes, values outside are set to all zeros (first to special class that then gets truncated)\n",
    "  x_cut = torch.where((x < -0.1) | (x > NUM_CLASSES-0.5), torch.tensor(NUM_CLASSES, device = DEVICE, dtype=torch.float), x)\n",
    "  x_one_hot = torch.zeros(x.shape[0], NUM_CLASSES+1, device = DEVICE)\n",
    "  x_one_hot.scatter_(1, x_cut.round().long().view(-1).unsqueeze(1), 1)\n",
    "  x_one_hot = x_one_hot[:,0:NUM_CLASSES]\n",
    "  return x_one_hot\n",
    "\n",
    "def global_mask_pool(x, x_in, batch):\n",
    "  mask_indicator = torch.lt(torch.sum(x_in, dim=1), 0.5).view(-1, 1)\n",
    "  x = x * mask_indicator\n",
    "  x = global_add_pool(x, batch)\n",
    "  return x \n",
    "\n",
    "\n",
    "def flip_edges_randomly(tensor, probability):\n",
    "  if probability < EPSILON:\n",
    "    return tensor\n",
    "\n",
    "  # Find the positions where the tensor has values 1.0 or 3.0\n",
    "  ones_positions = (tensor == EDGE_INDICATOR).to(DEVICE)\n",
    "  threes_positions = (tensor == NO_EDGE_INDICATOR).to(DEVICE)\n",
    "\n",
    "  # Generate a random binary mask for switching values\n",
    "  mask = torch.rand(tensor.shape, device=DEVICE) < probability\n",
    "\n",
    "  # Switch 1.0s to 3.0s using the random binary mask\n",
    "  tensor = torch.where(ones_positions & mask, torch.tensor(NO_EDGE_INDICATOR, device=DEVICE), tensor)\n",
    "\n",
    "  # Switch 3.0s to 1.0s using the inverted random binary mask\n",
    "  tensor = torch.where(threes_positions & mask, torch.tensor(EDGE_INDICATOR, device=DEVICE), tensor)\n",
    "\n",
    "  return tensor\n",
    "\n",
    "def extend_node_features(x, edge_index, batch):\n",
    "  assert(NODE_FEATURE_EXTEND == 3)\n",
    "\n",
    "  num_graphs = batch.max()+1\n",
    "  num_nodes = x.shape[0]\n",
    "  degree_feature = torch.zeros([num_nodes, NODE_FEATURE_EXTEND], device=DEVICE)\n",
    "  for i in range(edge_index.shape[1]):\n",
    "    src_node = edge_index[0,i]\n",
    "    target_node = edge_index[1,i]\n",
    "    # if src is real node and connection is edge indicator \n",
    "    if x[src_node, round(DUMMY)].item() > 0.5 and x[target_node, round(EDGE_INDICATOR)].item() > 0.5:\n",
    "      degree_feature[src_node,0] += 1.0\n",
    "    if x[src_node, round(DUMMY)].item() > 0.5 and x[target_node, round(MASK)].item() > 0.5:\n",
    "      degree_feature[src_node,1] += 1.0\n",
    "  for i in range(num_graphs):\n",
    "    num_mask_in_this_graph = torch.sum(x[batch == i,round(MASK)])\n",
    "    degree_feature[batch == i, 2] = num_mask_in_this_graph\n",
    "  x = torch.cat([x, degree_feature], dim=1)\n",
    "\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rEusLk_fd7hC",
    "outputId": "a378c5cb-eddf-450c-e156-4dc5ff9d4c64"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[4, 4], edge_index=[2, 8])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch_geometric.transforms as T\n",
    "transform = T.Compose([T.ToUndirected()])\n",
    "\n",
    "edge_index = torch.tensor([[0, 1, 2, 3, 1, 2, 3],\n",
    "                           [1, 2, 3, 1, 0, 1, 2]], dtype=torch.long).to(DEVICE)\n",
    "x = torch.tensor([[0,1,0,0], [1,0,0,1], [0,0,1,1], [0,1,0,0]], dtype=torch.float).to(DEVICE)\n",
    "\n",
    "data = Data(x=x, edge_index=edge_index)\n",
    "\n",
    "data = transform(data)\n",
    "data\n",
    "#extend_node_features(data.x, data.edge_index, batch=torch.zeros(data.x.shape[0], dtype=torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 516
    },
    "id": "bJ3hIT0pmBXp",
    "outputId": "e560fd6e-07fc-48f4-f758-8b7aef4850c7"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "edge_index = torch.tensor([[0, 1, 2, 3, 1, 2, 3, 1],\n",
    "                           [1, 2, 3, 1, 0, 1, 2, 3]], dtype=torch.long).to(DEVICE)\n",
    "x = torch.tensor([[-1], [0], [1], [1]], dtype=torch.float).to(DEVICE)\n",
    "\n",
    "data = Data(x=x, edge_index=edge_index)\n",
    "\n",
    "g = torch_geometric.utils.to_networkx(data, to_undirected=True, node_attrs=['x'])\n",
    "try:\n",
    "  nx.draw(g, pos=nx.spring_layout(g),  with_labels = True)\n",
    "except:\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AiLapF9HnilF",
    "outputId": "839b03a1-c60c-471e-aab3-6a510e9bd49f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Data(edge_index=[2, 24], x=[10, 1]),\n",
       " tensor([[0.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [3.],\n",
       "         [0.],\n",
       "         [3.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.]]),\n",
       " tensor([[0, 0, 0, 1, 1, 2, 2, 2, 3, 3, 4, 4, 4, 5, 5, 6, 6, 6, 7, 7, 8, 8, 9, 9],\n",
       "         [1, 3, 5, 0, 2, 1, 7, 8, 0, 4, 3, 7, 9, 0, 6, 5, 8, 9, 2, 4, 2, 6, 4, 6]]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = lift_nx_to_pyg(g)\n",
    "data, data.x, data.edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 516
    },
    "id": "cgkOkx4amnfY",
    "outputId": "849946a8-af1e-4e85-95f4-920d9a86be26"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_pyg(data, filename='examplegraph.png')\n",
    "if IN_COLAB:\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iaElQYAbWu8M"
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FwdGZitSyjKi"
   },
   "source": [
    "### d-Regular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "mCpXui1mW9mp"
   },
   "outputs": [],
   "source": [
    "class ShuffleList:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.index = 0\n",
    "\n",
    "    def __iter__(self):\n",
    "        random.shuffle(self.data)\n",
    "        self.index = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.index < len(self.data):\n",
    "            value = self.data[self.index]\n",
    "            self.index += 1\n",
    "            return value\n",
    "        else:\n",
    "            raise StopIteration\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "IgbW4Z0tWuN1"
   },
   "outputs": [],
   "source": [
    "def build_dataset(num_nodes=NUM_NODES, num_samples=NUM_SAMPLES, degree=DEGREE, seed=1234):\n",
    "  graph_dataset = list() \n",
    "\n",
    "  for _ in range(num_samples):\n",
    "    while True:\n",
    "      seed += 1\n",
    "      graph = nx.random_regular_graph(d=degree, n=num_nodes, seed=seed)\n",
    "      if nx.is_connected(graph):\n",
    "        graph.x = torch.ones(num_nodes).t()\n",
    "        graph_dataset.append(lift_nx_to_pyg(graph))\n",
    "        break\n",
    "\n",
    "  graph_dataset_train = graph_dataset[:int(len(graph_dataset)*0.8)]\n",
    "  graph_dataset_test = graph_dataset[int(len(graph_dataset)*0.8):]\n",
    "  return ShuffleList(graph_dataset_train), ShuffleList(graph_dataset_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "3QWWQlO36fzH"
   },
   "outputs": [],
   "source": [
    "#def build_test_set_nx(seed):\n",
    "#  graph_dataset = build_dataset(num_samples=10, seed=seed)\n",
    "#  graph_dataset_nx = list()\n",
    "#  for i, g in enumerate(graph_dataset):\n",
    "#    nx_orig_graph = draw_pyg(g, filename=f\"test_graph_sample{str(i).zfill(5)}.jpg\")\n",
    "#    graph_dataset_nx.append(nx_orig_graph)\n",
    "#  return graph_dataset_nx\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 533
    },
    "id": "xKqFT6D7XHE7",
    "outputId": "394e07f2-265b-452e-e6ee-3e0356e65e6c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<networkx.classes.graph.Graph at 0x2aac296d0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset, _  = build_dataset()\n",
    "data = dataset[0]\n",
    "draw_pyg(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 264], x=[78, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U2FUnVjG4Cwh",
    "outputId": "21044bdc-2c5c-4816-9804-267531ed3c57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1:\n",
      "=======\n",
      "Number of graphs in the current batch: 10\n",
      "DataBatch(edge_index=[2, 2640], x=[780, 1], batch=[780], ptr=[11])\n",
      "\n",
      "tensor([0., 1., 0., 1., 0., 3., 0., 1., 0., 3., 0., 3., 0., 3., 0., 3., 0., 3.,\n",
      "        0., 3., 0., 3., 0., 1., 3., 3., 3., 3., 3., 3., 3., 3., 1., 3., 3., 3.,\n",
      "        3., 3., 3., 3., 1., 3., 3., 1., 3., 3., 3., 1., 1., 3., 1., 3., 3., 1.,\n",
      "        3., 3., 3., 3., 3., 1., 3., 3., 3., 1., 3., 1., 3., 1., 1., 3., 3., 1.,\n",
      "        3., 3., 3., 1., 3., 3., 0., 3., 0., 3., 0., 1., 0., 1., 0., 3., 0., 3.,\n",
      "        0., 3., 0., 3., 0., 3., 0., 1., 0., 3., 0., 3., 3., 3., 3., 1., 3., 1.,\n",
      "        3., 3., 1., 3., 3., 1., 1., 3., 3., 3., 3., 1., 3., 3., 3., 3., 1., 1.,\n",
      "        3., 3., 3., 3., 1., 1., 3., 3., 3., 3., 3., 3., 1., 1., 3., 1., 3., 3.,\n",
      "        3., 3., 3., 3., 3., 1., 3., 3., 3., 1., 3., 3., 0., 3., 0., 3., 0., 3.,\n",
      "        0., 3., 0., 3., 0., 1., 0., 1., 0., 3., 0., 3., 0., 3., 0., 1., 0., 3.,\n",
      "        3., 1., 1., 3., 3., 3., 3., 3., 1., 3., 3., 3., 3., 3., 1., 1., 3., 1.,\n",
      "        3., 3., 1., 3., 3., 1., 1., 3., 1., 3., 3., 3., 3., 1., 3., 3., 1., 3.,\n",
      "        3., 3., 3., 3., 3., 1., 3., 3., 1., 3., 3., 3., 3., 1., 3., 3., 3., 3.,\n",
      "        0., 3., 0., 1., 0., 3., 0., 3., 0., 3., 0., 1., 0., 3., 0., 3., 0., 3.,\n",
      "        0., 1., 0., 3., 0., 3., 3., 3., 1., 3., 3., 1., 3., 3., 1., 3., 3., 1.,\n",
      "        3., 3., 3., 3., 1., 3., 3., 1., 3., 3., 1., 1., 3., 3., 3., 1., 1., 3.,\n",
      "        3., 3., 1., 3., 3., 3., 3., 3., 3., 3., 3., 1., 3., 3., 3., 1., 1., 3.,\n",
      "        3., 3., 1., 3., 3., 3., 0., 1., 0., 1., 0., 3., 0., 3., 0., 3., 0., 3.,\n",
      "        0., 3., 0., 1., 0., 3., 0., 3., 0., 3., 0., 3., 1., 1., 3., 3., 3., 3.,\n",
      "        3., 3., 3., 1., 3., 3., 3., 3., 3., 3., 3., 1., 3., 1., 3., 3., 3., 3.,\n",
      "        3., 3., 3., 3., 3., 1., 1., 3., 3., 3., 1., 3., 3., 1., 3., 1., 1., 3.,\n",
      "        1., 3., 3., 1., 3., 3., 3., 3., 3., 3., 1., 1., 0., 1., 0., 3., 0., 1.,\n",
      "        0., 3., 0., 3., 0., 3., 0., 3., 0., 3., 0., 1., 0., 3., 0., 3., 0., 3.,\n",
      "        3., 3., 3., 3., 3., 1., 1., 3., 3., 3., 3., 3., 3., 1., 3., 1., 3., 1.,\n",
      "        1., 3., 3., 3., 3., 3., 3., 1., 3., 1., 3., 3., 3., 1., 3., 3., 1., 3.,\n",
      "        3., 1., 1., 3., 1., 3., 1., 3., 1., 3., 3., 3., 3., 3., 3., 3., 3., 3.,\n",
      "        0., 3., 0., 1., 0., 3., 0., 3., 0., 1., 0., 1., 0., 3., 0., 3., 0., 3.,\n",
      "        0., 3., 0., 3., 0., 3., 3., 3., 3., 3., 1., 1., 3., 3., 1., 3., 3., 3.,\n",
      "        3., 3., 3., 3., 1., 1., 1., 3., 3., 3., 3., 1., 1., 3., 3., 1., 3., 3.,\n",
      "        1., 3., 3., 1., 1., 3., 3., 3., 3., 3., 3., 3., 3., 3., 1., 3., 3., 3.,\n",
      "        3., 3., 1., 1., 3., 3., 0., 3., 0., 1., 0., 3., 0., 3., 0., 3., 0., 3.,\n",
      "        0., 3., 0., 3., 0., 1., 0., 3., 0., 1., 0., 3., 3., 3., 3., 3., 3., 3.,\n",
      "        1., 1., 1., 1., 1., 3., 3., 3., 3., 3., 3., 3., 1., 3., 1., 3., 3., 3.,\n",
      "        3., 3., 3., 3., 1., 3., 3., 3., 3., 1., 3., 1., 3., 3., 1., 3., 1., 3.,\n",
      "        3., 3., 3., 1., 1., 3., 3., 1., 3., 3., 3., 3., 0., 3., 0., 1., 0., 1.,\n",
      "        0., 3., 0., 3., 0., 1., 0., 3., 0., 3., 0., 3., 0., 3., 0., 3., 0., 1.,\n",
      "        3., 3., 3., 3., 3., 1., 3., 1., 3., 3., 3., 3., 3., 1., 3., 3., 3., 3.,\n",
      "        1., 3., 3., 3., 1., 3., 3., 3., 1., 3., 3., 3., 1., 3., 3., 3., 3., 3.,\n",
      "        1., 3., 1., 1., 1., 3., 3., 3., 3., 3., 3., 1., 3., 3., 3., 1., 3., 1.,\n",
      "        0., 3., 0., 3., 0., 1., 0., 1., 0., 1., 0., 3., 0., 3., 0., 3., 0., 3.,\n",
      "        0., 3., 0., 3., 0., 1., 1., 3., 3., 3., 3., 3., 3., 3., 1., 3., 3., 3.,\n",
      "        3., 1., 3., 1., 3., 3., 3., 3., 1., 3., 3., 3., 3., 3., 3., 1., 3., 3.,\n",
      "        3., 3., 1., 3., 1., 3., 3., 1., 3., 3., 1., 3., 3., 3., 3., 1., 3., 3.,\n",
      "        3., 1., 1., 1., 3., 3.]) tensor([[  0,   0,   0,  ..., 778, 779, 779],\n",
      "        [  1,   3,   5,  ..., 724, 722, 724]]) tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7,\n",
      "        7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
      "        7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
      "        7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
      "        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
      "        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
      "        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
      "        8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
      "        9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
      "        9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
      "        9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9])\n"
     ]
    }
   ],
   "source": [
    "# TODO dataloader\n",
    "from torch_geometric.loader import DataLoader\n",
    "train_loader = DataLoader(dataset, batch_size=10, shuffle=True)\n",
    "for step, data in enumerate(train_loader):\n",
    "  print(f'Step {step + 1}:')\n",
    "  print('=======')\n",
    "  print(f'Number of graphs in the current batch: {data.num_graphs}')\n",
    "  print(data)\n",
    "  print()\n",
    "  print(data.x.flatten(), data.edge_index, data.batch)\n",
    "  break\n",
    "\n",
    "\n",
    "# for gen of training sample:\n",
    "# 1) mask 0 ... (all -1) (inclusivly) \n",
    "# 2) swich exactly 1 of the unmasked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AS8w-Xw0ynzU"
   },
   "source": [
    "### Planar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nlDyM555ypd8",
    "outputId": "5e2d2606-b605-4dbc-9fe0-f53679663f15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset sizes: train 128, val 32, test 40\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<__main__.ShuffleList at 0x2a8cf9250>, <__main__.ShuffleList at 0x2a8cf9280>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from torch.utils.data import random_split, Dataset\n",
    "import torch_geometric.utils\n",
    "\n",
    "def load_dataset_planar():\n",
    "  nx_set = list()\n",
    "  num_nodes = 64\n",
    "  graph_dataset = list() \n",
    "  if not os.path.exists(\"SPECTRE\"):\n",
    "    os.system(\"git clone https://github.com/KarolisMart/SPECTRE.git\")\n",
    "  adjs, eigvals, eigvecs, n_nodes, max_eigval, min_eigval, same_sample, n_max = torch.load('SPECTRE/data/planar_64_200.pt')\n",
    "  for adj in adjs:\n",
    "    # from adj matrix to nx\n",
    "    graph = nx.from_numpy_array(adj.numpy())\n",
    "    # from nx to pyg\n",
    "    graph.x = torch.ones(num_nodes).t()\n",
    "    graph_dataset.append(lift_nx_to_pyg(graph))\n",
    "\n",
    "  #graph_dataset_train = graph_dataset[:int(len(graph_dataset)*0.8)]\n",
    "  #graph_dataset_test = graph_dataset[int(len(graph_dataset)*0.8):]\n",
    "  #return ShuffleList(graph_dataset_train), ShuffleList(graph_dataset_test)\n",
    "\n",
    "  test_len = int(round(len(graph_dataset) * 0.2))\n",
    "  train_len = int(round((len(graph_dataset) - test_len) * 0.8))\n",
    "  val_len = len(graph_dataset) - train_len - test_len\n",
    "  print(f'Dataset sizes: train {train_len}, val {val_len}, test {test_len}')\n",
    "  splits = random_split(graph_dataset, [train_len, val_len, test_len], generator=torch.Generator().manual_seed(1234))\n",
    "  datasets = {'train': splits[0], 'val': splits[1], 'test': splits[2]}\n",
    "  return ShuffleList(list(datasets['train'])), ShuffleList(list(datasets['test']))\n",
    "\n",
    "\n",
    "load_dataset_planar()  # get baseline by comparing 128 with 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lvjLUJSMUb_E",
    "outputId": "eca6abe4-e963-4351-f674-d455b270c2de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset sizes: train 128, val 32, test 40\n"
     ]
    }
   ],
   "source": [
    "graph_dataset, _ = load_dataset_planar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5OIcsvOpU9AC",
    "outputId": "b342f4ab-7be5-4074-8bf1-8aad297761e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Data(edge_index=[2, 8064], x=[2080, 1]),\n",
       " Data(edge_index=[2, 8064], x=[2080, 1]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_dataset[0],graph_dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "obBv2OMEWaKA"
   },
   "outputs": [],
   "source": [
    "#draw_pyg(graph_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "78c_wYnEiPAx"
   },
   "source": [
    "### Block\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T2Wp0Za7iSzn",
    "outputId": "bab4242a-1963-4de7-a4b6-b6ff07858958"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nodes  172\n",
      "number of nodes  92\n",
      "number of nodes  61\n",
      "number of nodes  64\n",
      "number of nodes  115\n",
      "number of nodes  101\n",
      "number of nodes  90\n",
      "number of nodes  123\n",
      "number of nodes  168\n",
      "number of nodes  61\n",
      "number of nodes  130\n",
      "number of nodes  62\n",
      "number of nodes  163\n",
      "number of nodes  58\n",
      "number of nodes  71\n",
      "number of nodes  156\n",
      "number of nodes  77\n",
      "number of nodes  169\n",
      "number of nodes  141\n",
      "number of nodes  103\n",
      "number of nodes  89\n",
      "number of nodes  81\n",
      "number of nodes  88\n",
      "number of nodes  164\n",
      "number of nodes  88\n",
      "number of nodes  117\n",
      "number of nodes  128\n",
      "number of nodes  69\n",
      "number of nodes  64\n",
      "number of nodes  58\n",
      "number of nodes  152\n",
      "number of nodes  97\n",
      "number of nodes  166\n",
      "number of nodes  101\n",
      "number of nodes  106\n",
      "number of nodes  57\n",
      "number of nodes  76\n",
      "number of nodes  115\n",
      "number of nodes  52\n",
      "number of nodes  112\n",
      "number of nodes  64\n",
      "number of nodes  63\n",
      "number of nodes  169\n",
      "number of nodes  54\n",
      "number of nodes  90\n",
      "number of nodes  129\n",
      "number of nodes  105\n",
      "number of nodes  53\n",
      "number of nodes  53\n",
      "number of nodes  55\n",
      "number of nodes  53\n",
      "number of nodes  88\n",
      "number of nodes  65\n",
      "number of nodes  127\n",
      "number of nodes  77\n",
      "number of nodes  94\n",
      "number of nodes  57\n",
      "number of nodes  139\n",
      "number of nodes  56\n",
      "number of nodes  148\n",
      "number of nodes  79\n",
      "number of nodes  58\n",
      "number of nodes  94\n",
      "number of nodes  112\n",
      "number of nodes  99\n",
      "number of nodes  89\n",
      "number of nodes  75\n",
      "number of nodes  137\n",
      "number of nodes  63\n",
      "number of nodes  115\n",
      "number of nodes  159\n",
      "number of nodes  74\n",
      "number of nodes  72\n",
      "number of nodes  129\n",
      "number of nodes  124\n",
      "number of nodes  72\n",
      "number of nodes  99\n",
      "number of nodes  166\n",
      "number of nodes  164\n",
      "number of nodes  160\n",
      "number of nodes  80\n",
      "number of nodes  61\n",
      "number of nodes  138\n",
      "number of nodes  78\n",
      "number of nodes  83\n",
      "number of nodes  167\n",
      "number of nodes  147\n",
      "number of nodes  70\n",
      "number of nodes  99\n",
      "number of nodes  91\n",
      "number of nodes  60\n",
      "number of nodes  135\n",
      "number of nodes  73\n",
      "number of nodes  139\n",
      "number of nodes  97\n",
      "number of nodes  84\n",
      "number of nodes  113\n",
      "number of nodes  73\n",
      "number of nodes  157\n",
      "number of nodes  102\n",
      "number of nodes  123\n",
      "number of nodes  125\n",
      "number of nodes  127\n",
      "number of nodes  79\n",
      "number of nodes  106\n",
      "number of nodes  81\n",
      "number of nodes  122\n",
      "number of nodes  71\n",
      "number of nodes  120\n",
      "number of nodes  76\n",
      "number of nodes  85\n",
      "number of nodes  98\n",
      "number of nodes  55\n",
      "number of nodes  142\n",
      "number of nodes  168\n",
      "number of nodes  161\n",
      "number of nodes  52\n",
      "number of nodes  92\n",
      "number of nodes  163\n",
      "number of nodes  187\n",
      "number of nodes  90\n",
      "number of nodes  144\n",
      "number of nodes  59\n",
      "number of nodes  157\n",
      "number of nodes  129\n",
      "number of nodes  44\n",
      "number of nodes  163\n",
      "number of nodes  162\n",
      "number of nodes  64\n",
      "number of nodes  157\n",
      "number of nodes  93\n",
      "number of nodes  143\n",
      "number of nodes  61\n",
      "number of nodes  80\n",
      "number of nodes  91\n",
      "number of nodes  91\n",
      "number of nodes  127\n",
      "number of nodes  87\n",
      "number of nodes  82\n",
      "number of nodes  102\n",
      "number of nodes  67\n",
      "number of nodes  164\n",
      "number of nodes  97\n",
      "number of nodes  92\n",
      "number of nodes  140\n",
      "number of nodes  104\n",
      "number of nodes  165\n",
      "number of nodes  62\n",
      "number of nodes  69\n",
      "number of nodes  156\n",
      "number of nodes  61\n",
      "number of nodes  85\n",
      "number of nodes  55\n",
      "number of nodes  59\n",
      "number of nodes  144\n",
      "number of nodes  132\n",
      "number of nodes  141\n",
      "number of nodes  56\n",
      "number of nodes  169\n",
      "number of nodes  125\n",
      "number of nodes  158\n",
      "number of nodes  58\n",
      "number of nodes  61\n",
      "number of nodes  141\n",
      "number of nodes  60\n",
      "number of nodes  102\n",
      "number of nodes  134\n",
      "number of nodes  69\n",
      "number of nodes  94\n",
      "number of nodes  174\n",
      "number of nodes  64\n",
      "number of nodes  116\n",
      "number of nodes  141\n",
      "number of nodes  63\n",
      "number of nodes  75\n",
      "number of nodes  149\n",
      "number of nodes  152\n",
      "number of nodes  110\n",
      "number of nodes  107\n",
      "number of nodes  100\n",
      "number of nodes  84\n",
      "number of nodes  116\n",
      "number of nodes  105\n",
      "number of nodes  109\n",
      "number of nodes  141\n",
      "number of nodes  64\n",
      "number of nodes  67\n",
      "number of nodes  125\n",
      "number of nodes  69\n",
      "number of nodes  103\n",
      "number of nodes  174\n",
      "number of nodes  139\n",
      "number of nodes  180\n",
      "number of nodes  49\n",
      "number of nodes  55\n",
      "number of nodes  119\n",
      "number of nodes  76\n",
      "number of nodes  139\n",
      "number of nodes  85\n",
      "number of nodes  90\n",
      "Dataset sizes: train 128, val 32, test 40\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<__main__.ShuffleList at 0x2aabd8850>, <__main__.ShuffleList at 0x2a4db9b20>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_dataset_block():\n",
    "  nx_set = list()\n",
    "  num_nodes = 64\n",
    "  graph_dataset = list() \n",
    "  if not os.path.exists(\"SPECTRE\"):\n",
    "    os.system(\"git clone https://github.com/KarolisMart/SPECTRE.git\")\n",
    "  adjs, eigvals, eigvecs, n_nodes, max_eigval, min_eigval, same_sample, n_max = torch.load('SPECTRE/data/sbm_200.pt')\n",
    "  for adj in adjs:\n",
    "    # from adj matrix to nx\n",
    "    graph = nx.from_numpy_array(adj.numpy())\n",
    "    print('number of nodes ', graph.number_of_nodes())\n",
    "    # from nx to pyg\n",
    "    graph.x = torch.ones(num_nodes).t()\n",
    "    graph_dataset.append(lift_nx_to_pyg(graph))\n",
    "\n",
    "  #graph_dataset_train = graph_dataset[:int(len(graph_dataset)*0.8)]\n",
    "  #graph_dataset_test = graph_dataset[int(len(graph_dataset)*0.8):]\n",
    "  #return ShuffleList(graph_dataset_train), ShuffleList(graph_dataset_test)\n",
    "\n",
    "  test_len = int(round(len(graph_dataset) * 0.2))\n",
    "  train_len = int(round((len(graph_dataset) - test_len) * 0.8))\n",
    "  val_len = len(graph_dataset) - train_len - test_len\n",
    "  print(f'Dataset sizes: train {train_len}, val {val_len}, test {test_len}')\n",
    "  splits = random_split(graph_dataset, [train_len, val_len, test_len], generator=torch.Generator().manual_seed(1234))\n",
    "  datasets = {'train': splits[0], 'val': splits[1], 'test': splits[2]}\n",
    "  return ShuffleList(list(datasets['train'])), ShuffleList(list(datasets['test']))\n",
    "\n",
    "\n",
    "load_dataset_block()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LlPP_ASmqHrQ",
    "outputId": "53905ab3-d656-45c3-da51-e3361fc27e64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nodes  172\n",
      "number of nodes  92\n",
      "number of nodes  61\n",
      "number of nodes  64\n",
      "number of nodes  115\n",
      "number of nodes  101\n",
      "number of nodes  90\n",
      "number of nodes  123\n",
      "number of nodes  168\n",
      "number of nodes  61\n",
      "number of nodes  130\n",
      "number of nodes  62\n",
      "number of nodes  163\n",
      "number of nodes  58\n",
      "number of nodes  71\n",
      "number of nodes  156\n",
      "number of nodes  77\n",
      "number of nodes  169\n",
      "number of nodes  141\n",
      "number of nodes  103\n",
      "number of nodes  89\n",
      "number of nodes  81\n",
      "number of nodes  88\n",
      "number of nodes  164\n",
      "number of nodes  88\n",
      "number of nodes  117\n",
      "number of nodes  128\n",
      "number of nodes  69\n",
      "number of nodes  64\n",
      "number of nodes  58\n",
      "number of nodes  152\n",
      "number of nodes  97\n",
      "number of nodes  166\n",
      "number of nodes  101\n",
      "number of nodes  106\n",
      "number of nodes  57\n",
      "number of nodes  76\n",
      "number of nodes  115\n",
      "number of nodes  52\n",
      "number of nodes  112\n",
      "number of nodes  64\n",
      "number of nodes  63\n",
      "number of nodes  169\n",
      "number of nodes  54\n",
      "number of nodes  90\n",
      "number of nodes  129\n",
      "number of nodes  105\n",
      "number of nodes  53\n",
      "number of nodes  53\n",
      "number of nodes  55\n",
      "number of nodes  53\n",
      "number of nodes  88\n",
      "number of nodes  65\n",
      "number of nodes  127\n",
      "number of nodes  77\n",
      "number of nodes  94\n",
      "number of nodes  57\n",
      "number of nodes  139\n",
      "number of nodes  56\n",
      "number of nodes  148\n",
      "number of nodes  79\n",
      "number of nodes  58\n",
      "number of nodes  94\n",
      "number of nodes  112\n",
      "number of nodes  99\n",
      "number of nodes  89\n",
      "number of nodes  75\n",
      "number of nodes  137\n",
      "number of nodes  63\n",
      "number of nodes  115\n",
      "number of nodes  159\n",
      "number of nodes  74\n",
      "number of nodes  72\n",
      "number of nodes  129\n",
      "number of nodes  124\n",
      "number of nodes  72\n",
      "number of nodes  99\n",
      "number of nodes  166\n",
      "number of nodes  164\n",
      "number of nodes  160\n",
      "number of nodes  80\n",
      "number of nodes  61\n",
      "number of nodes  138\n",
      "number of nodes  78\n",
      "number of nodes  83\n",
      "number of nodes  167\n",
      "number of nodes  147\n",
      "number of nodes  70\n",
      "number of nodes  99\n",
      "number of nodes  91\n",
      "number of nodes  60\n",
      "number of nodes  135\n",
      "number of nodes  73\n",
      "number of nodes  139\n",
      "number of nodes  97\n",
      "number of nodes  84\n",
      "number of nodes  113\n",
      "number of nodes  73\n",
      "number of nodes  157\n",
      "number of nodes  102\n",
      "number of nodes  123\n",
      "number of nodes  125\n",
      "number of nodes  127\n",
      "number of nodes  79\n",
      "number of nodes  106\n",
      "number of nodes  81\n",
      "number of nodes  122\n",
      "number of nodes  71\n",
      "number of nodes  120\n",
      "number of nodes  76\n",
      "number of nodes  85\n",
      "number of nodes  98\n",
      "number of nodes  55\n",
      "number of nodes  142\n",
      "number of nodes  168\n",
      "number of nodes  161\n",
      "number of nodes  52\n",
      "number of nodes  92\n",
      "number of nodes  163\n",
      "number of nodes  187\n",
      "number of nodes  90\n",
      "number of nodes  144\n",
      "number of nodes  59\n",
      "number of nodes  157\n",
      "number of nodes  129\n",
      "number of nodes  44\n",
      "number of nodes  163\n",
      "number of nodes  162\n",
      "number of nodes  64\n",
      "number of nodes  157\n",
      "number of nodes  93\n",
      "number of nodes  143\n",
      "number of nodes  61\n",
      "number of nodes  80\n",
      "number of nodes  91\n",
      "number of nodes  91\n",
      "number of nodes  127\n",
      "number of nodes  87\n",
      "number of nodes  82\n",
      "number of nodes  102\n",
      "number of nodes  67\n",
      "number of nodes  164\n",
      "number of nodes  97\n",
      "number of nodes  92\n",
      "number of nodes  140\n",
      "number of nodes  104\n",
      "number of nodes  165\n",
      "number of nodes  62\n",
      "number of nodes  69\n",
      "number of nodes  156\n",
      "number of nodes  61\n",
      "number of nodes  85\n",
      "number of nodes  55\n",
      "number of nodes  59\n",
      "number of nodes  144\n",
      "number of nodes  132\n",
      "number of nodes  141\n",
      "number of nodes  56\n",
      "number of nodes  169\n",
      "number of nodes  125\n",
      "number of nodes  158\n",
      "number of nodes  58\n",
      "number of nodes  61\n",
      "number of nodes  141\n",
      "number of nodes  60\n",
      "number of nodes  102\n",
      "number of nodes  134\n",
      "number of nodes  69\n",
      "number of nodes  94\n",
      "number of nodes  174\n",
      "number of nodes  64\n",
      "number of nodes  116\n",
      "number of nodes  141\n",
      "number of nodes  63\n",
      "number of nodes  75\n",
      "number of nodes  149\n",
      "number of nodes  152\n",
      "number of nodes  110\n",
      "number of nodes  107\n",
      "number of nodes  100\n",
      "number of nodes  84\n",
      "number of nodes  116\n",
      "number of nodes  105\n",
      "number of nodes  109\n",
      "number of nodes  141\n",
      "number of nodes  64\n",
      "number of nodes  67\n",
      "number of nodes  125\n",
      "number of nodes  69\n",
      "number of nodes  103\n",
      "number of nodes  174\n",
      "number of nodes  139\n",
      "number of nodes  180\n",
      "number of nodes  49\n",
      "number of nodes  55\n",
      "number of nodes  119\n",
      "number of nodes  76\n",
      "number of nodes  139\n",
      "number of nodes  85\n",
      "number of nodes  90\n",
      "Dataset sizes: train 128, val 32, test 40\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.ShuffleList at 0x2aaceb310>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,_ = load_dataset_block()\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "97PuI5WRyX9n",
    "outputId": "c5e4ea88-eba3-471c-e1ad-a1153961c641"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 44104], x=[11175, 1])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VL2Kr3jD-WwW"
   },
   "source": [
    "## Loss & Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "4bFAJnqX-ZO_"
   },
   "outputs": [],
   "source": [
    "import pyemd\n",
    "import numpy as np\n",
    "import concurrent.futures\n",
    "from functools import partial\n",
    "from scipy.linalg import toeplitz\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "PRINT_TIME = False\n",
    "\n",
    "def degree_worker(G):\n",
    "    return np.array(nx.degree_histogram(G))\n",
    "\n",
    "def degree_stats(graph_ref_list, graph_pred_list, is_parallel=True, compute_emd=False):\n",
    "    ''' Compute the distance between the degree distributions of two unordered sets of graphs.\n",
    "        Args:\n",
    "            graph_ref_list, graph_target_list: two lists of networkx graphs to be evaluated\n",
    "        '''\n",
    "    sample_ref = []\n",
    "    sample_pred = []\n",
    "    # in case an empty graph is generated\n",
    "    graph_pred_list_remove_empty = [\n",
    "        G for G in graph_pred_list if not G.number_of_nodes() == 0\n",
    "    ]\n",
    "\n",
    "    prev = datetime.now()\n",
    "    if is_parallel:\n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            for deg_hist in executor.map(degree_worker, graph_ref_list):\n",
    "                sample_ref.append(deg_hist)\n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            for deg_hist in executor.map(degree_worker, graph_pred_list_remove_empty):\n",
    "                sample_pred.append(deg_hist)\n",
    "    else:\n",
    "        for i in range(len(graph_ref_list)):\n",
    "            degree_temp = np.array(nx.degree_histogram(graph_ref_list[i]))\n",
    "            sample_ref.append(degree_temp)\n",
    "        for i in range(len(graph_pred_list_remove_empty)):\n",
    "            degree_temp = np.array(\n",
    "                nx.degree_histogram(graph_pred_list_remove_empty[i]))\n",
    "            sample_pred.append(degree_temp)\n",
    "\n",
    "    # mmd_dist = compute_mmd(sample_ref, sample_pred, kernel=gaussian_emd)\n",
    "    # mmd_dist = compute_mmd(sample_ref, sample_pred, kernel=emd)\n",
    "    if compute_emd:\n",
    "        # EMD option uses the same computation as GraphRNN, the alternative is MMD as computed by GRAN\n",
    "        # mmd_dist = compute_mmd(sample_ref, sample_pred, kernel=emd)\n",
    "        mmd_dist = compute_mmd(sample_ref, sample_pred, kernel=gaussian_emd)\n",
    "    else:\n",
    "        mmd_dist = compute_mmd(sample_ref, sample_pred, kernel=gaussian_tv)\n",
    "    # mmd_dist = compute_mmd(sample_ref, sample_pred, kernel=gaussian)\n",
    "\n",
    "    elapsed = datetime.now() - prev\n",
    "    if PRINT_TIME:\n",
    "        print('Time computing degree mmd: ', elapsed)\n",
    "    return mmd_dist\n",
    "\n",
    "\n",
    "\n",
    "def clustering_worker(param):\n",
    "    G, bins = param\n",
    "    clustering_coeffs_list = list(nx.clustering(G).values())\n",
    "    hist, _ = np.histogram(\n",
    "        clustering_coeffs_list, bins=bins, range=(0.0, 1.0), density=False)\n",
    "    return hist\n",
    "\n",
    "\n",
    "def clustering_stats(graph_ref_list,\n",
    "                     graph_pred_list,\n",
    "                     bins=100,\n",
    "                     is_parallel=True, compute_emd=False):\n",
    "    sample_ref = []\n",
    "    sample_pred = []\n",
    "    graph_pred_list_remove_empty = [\n",
    "        G for G in graph_pred_list if not G.number_of_nodes() == 0\n",
    "    ]\n",
    "\n",
    "    prev = datetime.now()\n",
    "    if is_parallel:\n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            for clustering_hist in executor.map(clustering_worker,\n",
    "                                                [(G, bins) for G in graph_ref_list]):\n",
    "                sample_ref.append(clustering_hist)\n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            for clustering_hist in executor.map(\n",
    "                    clustering_worker, [(G, bins) for G in graph_pred_list_remove_empty]):\n",
    "                sample_pred.append(clustering_hist)\n",
    "\n",
    "        # check non-zero elements in hist\n",
    "        # total = 0\n",
    "        # for i in range(len(sample_pred)):\n",
    "        #    nz = np.nonzero(sample_pred[i])[0].shape[0]\n",
    "        #    total += nz\n",
    "        # print(total)\n",
    "    else:\n",
    "        for i in range(len(graph_ref_list)):\n",
    "            clustering_coeffs_list = list(nx.clustering(graph_ref_list[i]).values())\n",
    "            hist, _ = np.histogram(\n",
    "                clustering_coeffs_list, bins=bins, range=(0.0, 1.0), density=False)\n",
    "            sample_ref.append(hist)\n",
    "\n",
    "        for i in range(len(graph_pred_list_remove_empty)):\n",
    "            clustering_coeffs_list = list(\n",
    "                nx.clustering(graph_pred_list_remove_empty[i]).values())\n",
    "            hist, _ = np.histogram(\n",
    "                clustering_coeffs_list, bins=bins, range=(0.0, 1.0), density=False)\n",
    "            sample_pred.append(hist)\n",
    "\n",
    "    if compute_emd:\n",
    "        # EMD option uses the same computation as GraphRNN, the alternative is MMD as computed by GRAN\n",
    "        # mmd_dist = compute_mmd(sample_ref, sample_pred, kernel=emd, sigma=1.0 / 10)\n",
    "        mmd_dist = compute_mmd(sample_ref, sample_pred, kernel=gaussian_emd, sigma=1.0 / 10, distance_scaling=bins)\n",
    "    else:\n",
    "        mmd_dist = compute_mmd(sample_ref, sample_pred, kernel=gaussian_tv, sigma=1.0 / 10)\n",
    "\n",
    "    elapsed = datetime.now() - prev\n",
    "    if PRINT_TIME:\n",
    "        print('Time computing clustering mmd: ', elapsed)\n",
    "    return mmd_dist\n",
    "\n",
    "\n",
    "\n",
    "# maps motif/orbit name string to its corresponding list of indices from orca output\n",
    "motif_to_indices = {\n",
    "    '3path': [1, 2],\n",
    "    '4cycle': [8],\n",
    "}\n",
    "COUNT_START_STR = 'orbit counts:'\n",
    "\n",
    "\n",
    "def edge_list_reindexed(G):\n",
    "    idx = 0\n",
    "    id2idx = dict()\n",
    "    for u in G.nodes():\n",
    "        id2idx[str(u)] = idx\n",
    "        idx += 1\n",
    "\n",
    "    edges = []\n",
    "    for (u, v) in G.edges():\n",
    "        edges.append((id2idx[str(u)], id2idx[str(v)]))\n",
    "    return edges\n",
    "\n",
    "def orca(graph):\n",
    "    # tmp_fname = f'analysis/orca/tmp_{\"\".join(secrets.choice(ascii_uppercase + digits) for i in range(8))}.txt'\n",
    "    tmp_fname = f'orca/tmp_{\"\".join(secrets.choice(ascii_uppercase + digits) for i in range(8))}.txt'\n",
    "    tmp_fname = os.path.join(os.path.dirname(os.path.realpath(__file__)), tmp_fname)\n",
    "    # print(tmp_fname, flush=True)\n",
    "    f = open(tmp_fname, 'w')\n",
    "    f.write(\n",
    "        str(graph.number_of_nodes()) + ' ' + str(graph.number_of_edges()) + '\\n')\n",
    "    for (u, v) in edge_list_reindexed(graph):\n",
    "        f.write(str(u) + ' ' + str(v) + '\\n')\n",
    "    f.close()\n",
    "    output = sp.check_output(\n",
    "        [str(os.path.join(os.path.dirname(os.path.realpath(__file__)), 'orca/orca')), 'node', '4', tmp_fname, 'std'])\n",
    "    output = output.decode('utf8').strip()\n",
    "    idx = output.find(COUNT_START_STR) + len(COUNT_START_STR) + 2\n",
    "    output = output[idx:]\n",
    "    node_orbit_counts = np.array([\n",
    "        list(map(int,\n",
    "                 node_cnts.strip().split(' ')))\n",
    "        for node_cnts in output.strip('\\n').split('\\n')\n",
    "    ])\n",
    "\n",
    "    try:\n",
    "        os.remove(tmp_fname)\n",
    "    except OSError:\n",
    "        pass\n",
    "\n",
    "    return node_orbit_counts\n",
    "\n",
    "\n",
    "def orbit_stats_all(graph_ref_list, graph_pred_list, compute_emd=False):\n",
    "    total_counts_ref = []\n",
    "    total_counts_pred = []\n",
    "\n",
    "    graph_pred_list_remove_empty = [\n",
    "        G for G in graph_pred_list if not G.number_of_nodes() == 0\n",
    "    ]\n",
    "\n",
    "    for G in graph_ref_list:\n",
    "        orbit_counts = orca(G)\n",
    "        orbit_counts_graph = np.sum(orbit_counts, axis=0) / G.number_of_nodes()\n",
    "        total_counts_ref.append(orbit_counts_graph)\n",
    "\n",
    "    for G in graph_pred_list:\n",
    "        orbit_counts = orca(G)\n",
    "        orbit_counts_graph = np.sum(orbit_counts, axis=0) / G.number_of_nodes()\n",
    "        total_counts_pred.append(orbit_counts_graph)\n",
    "\n",
    "    total_counts_ref = np.array(total_counts_ref)\n",
    "    total_counts_pred = np.array(total_counts_pred)\n",
    "\n",
    "    # mmd_dist = compute_mmd(\n",
    "    #     total_counts_ref,\n",
    "    #     total_counts_pred,\n",
    "    #     kernel=gaussian,\n",
    "    #     is_hist=False,\n",
    "    #     sigma=30.0)\n",
    "\n",
    "    # mmd_dist = compute_mmd(\n",
    "    #         total_counts_ref,\n",
    "    #         total_counts_pred,\n",
    "    #         kernel=gaussian_tv,\n",
    "    #         is_hist=False,\n",
    "    #         sigma=30.0)  \n",
    "\n",
    "    if compute_emd:\n",
    "        # mmd_dist = compute_mmd(total_counts_ref, total_counts_pred, kernel=emd, sigma=30.0)\n",
    "        # EMD option uses the same computation as GraphRNN, the alternative is MMD as computed by GRAN\n",
    "        mmd_dist = compute_mmd(total_counts_ref, total_counts_pred, kernel=gaussian, is_hist=False, sigma=30.0)\n",
    "    else:\n",
    "        mmd_dist = compute_mmd(total_counts_ref, total_counts_pred, kernel=gaussian_tv, is_hist=False, sigma=30.0)\n",
    "    return mmd_dist\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def gaussian(x, y, sigma=1.0):\n",
    "    support_size = max(len(x), len(y))\n",
    "    # convert histogram values x and y to float, and make them equal len\n",
    "    x = x.astype(float)\n",
    "    y = y.astype(float)\n",
    "    if len(x) < len(y):\n",
    "        x = np.hstack((x, [0.0] * (support_size - len(x))))\n",
    "    elif len(y) < len(x):\n",
    "        y = np.hstack((y, [0.0] * (support_size - len(y))))\n",
    "\n",
    "    dist = np.linalg.norm(x - y, 2)\n",
    "    return np.exp(-dist * dist / (2 * sigma * sigma))\n",
    "\n",
    "\n",
    "def gaussian_tv(x, y, sigma=1.0):  \n",
    "    support_size = max(len(x), len(y))\n",
    "    # convert histogram values x and y to float, and make them equal len\n",
    "    x = x.astype(float)\n",
    "    y = y.astype(float)\n",
    "    if len(x) < len(y):\n",
    "        x = np.hstack((x, [0.0] * (support_size - len(x))))\n",
    "    elif len(y) < len(x):\n",
    "        y = np.hstack((y, [0.0] * (support_size - len(y))))\n",
    "\n",
    "    dist = np.abs(x - y).sum() / 2.0\n",
    "    return np.exp(-dist * dist / (2 * sigma * sigma))\n",
    "\n",
    "\n",
    "def kernel_parallel_unpacked(x, samples2, kernel):\n",
    "    d = 0\n",
    "    for s2 in samples2:\n",
    "        d += kernel(x, s2)\n",
    "    return d\n",
    "\n",
    "\n",
    "def kernel_parallel_worker(t):\n",
    "    return kernel_parallel_unpacked(*t)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def disc(samples1, samples2, kernel, is_parallel=True, *args, **kwargs):\n",
    "    ''' Discrepancy between 2 samples '''\n",
    "    d = 0\n",
    "\n",
    "    if not is_parallel:\n",
    "        for s1 in samples1:\n",
    "            for s2 in samples2:\n",
    "                d += kernel(s1, s2, *args, **kwargs)\n",
    "    else:\n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            for dist in executor.map(kernel_parallel_worker, [\n",
    "                    (s1, samples2, partial(kernel, *args, **kwargs)) for s1 in samples1\n",
    "            ]):\n",
    "                d += dist\n",
    "    if len(samples1) * len(samples2) > 0:\n",
    "        d /= len(samples1) * len(samples2)\n",
    "    else:\n",
    "        d = 1e+6\n",
    "    #print('error')\n",
    "    return d\n",
    "\n",
    "\n",
    "def compute_mmd(samples1, samples2, kernel, is_hist=True, *args, **kwargs):\n",
    "    ''' MMD between two samples '''\n",
    "    # normalize histograms into pmf\n",
    "    if is_hist:\n",
    "        samples1 = [s1 / (np.sum(s1) + 1e-6) for s1 in samples1]\n",
    "        samples2 = [s2 / (np.sum(s2) + 1e-6) for s2 in samples2]\n",
    "    #print(samples1)\n",
    "    return disc(samples1, samples1, kernel, *args, **kwargs) + disc(samples2, samples2, kernel, *args, **kwargs) - \\\n",
    "                2 * disc(samples1, samples2, kernel, *args, **kwargs)\n",
    "\n",
    "\n",
    "def compute_emd(samples1, samples2, kernel, is_hist=True, *args, **kwargs):\n",
    "    ''' EMD between average of two samples '''\n",
    "    # normalize histograms into pmf\n",
    "    if is_hist:\n",
    "        samples1 = [np.mean(samples1)]\n",
    "        samples2 = [np.mean(samples2)]\n",
    "    return disc(samples1, samples2, kernel, *args,\n",
    "                            **kwargs), [samples1[0], samples2[0]]\n",
    "\n",
    "\n",
    "\n",
    "def compute_mmd_stats(graphs_ref_nx, graphs_pred_nx):\n",
    "  if 'networkx' not in str(type(graphs_ref_nx[0])):\n",
    "    graphs_ref_nx = [pyg_graph_to_nx(g) for g in graphs_ref_nx]\n",
    "  if 'networkx' not in str(type(graphs_pred_nx[0])):\n",
    "    graphs_pred_nx = [pyg_graph_to_nx(g) for g in graphs_pred_nx]\n",
    "  return degree_stats(graphs_ref_nx, graphs_pred_nx), clustering_stats(graphs_ref_nx, graphs_pred_nx)\n",
    "\n",
    "\n",
    "def compute_expected_optimal_loss(graph_dataset_train, graph_dataset_test):\n",
    "  graph_dataset_train_nx = [pyg_graph_to_nx(g) for g in graph_dataset_train]\n",
    "  graph_dataset_test_nx = [pyg_graph_to_nx(g) for g in graph_dataset_test]\n",
    "  return compute_mmd_stats(graph_dataset_train_nx, graph_dataset_test_nx)\n",
    "\n",
    "#def compute_expected_optimal_loss(graphs_ref_nx):\n",
    "#  graphs_ref_nx2 = build_test_set_nx(1337)\n",
    "#  return compute_mmd_stats(graphs_ref_nx, graphs_ref_nx2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dqztDRIj0UdF"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kV_DnkKhs9P-"
   },
   "source": [
    "#### AttentionNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "eoLXRG6utBBU"
   },
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GATv2Conv, GraphNorm, BatchNorm\n",
    "\n",
    "class AttentionNet(torch.nn.Module):\n",
    "  def __init__(self, hidden_dim=32, layer_num=6, dropout=0.1, normalization=False, single_pass_pooling=False):\n",
    "    super(AttentionNet, self).__init__()\n",
    "\n",
    "    self.mlp_list = nn.ModuleList()\n",
    "    self.conv_list = nn.ModuleList()\n",
    "    self.sigmoid = nn.Sigmoid()\n",
    "    self.dropout = dropout\n",
    "    self.graph_norms = nn.ModuleList()\n",
    "    self.normalization = normalization\n",
    "    self.single_pass_pooling = single_pass_pooling\n",
    "    assert(hidden_dim % 2 == 0)\n",
    "    input_channels = NUM_CLASSES\n",
    "\n",
    "    for i in range(layer_num):\n",
    "      in_dim = hidden_dim if i > 0 else input_channels \n",
    "      out_dim = hidden_dim if i < layer_num-1 else 1 \n",
    "      self.conv_list.append(GATv2Conv(in_channels=in_dim, out_channels=hidden_dim // 2, heads=2))\n",
    "      self.graph_norms.append(BatchNorm(hidden_dim))\n",
    "      self.mlp_list.append(Seq(Lin(hidden_dim, hidden_dim), nn.ReLU(), Lin(hidden_dim, hidden_dim), nn.ReLU(), Lin(hidden_dim, out_dim)))\n",
    "\n",
    "  def forward(self, x_in, edge_index, batch):\n",
    "    x = note_features_to_one_hot(x_in)\n",
    "    for i in range(len(self.conv_list)):\n",
    "      x = self.conv_list[i](x, edge_index)\n",
    "      x = F.relu(x)\n",
    "      if self.normalization:\n",
    "        x = self.graph_norms[i](x)\n",
    "      x = self.mlp_list[i](x)\n",
    "      #if i == 0:\n",
    "      #  x = self.dropout(x)\n",
    "\n",
    "    if self.single_pass_pooling:\n",
    "      x = global_mask_pool(x, x_in, batch)\n",
    "    else:\n",
    "      x = global_mean_pool(x, batch)\n",
    "    x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "    x = self.sigmoid(x) + EPSILON\n",
    "    return x.flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iTUh3uVOtEMO",
    "outputId": "65bca9cf-0b24-4c80-d5bf-e3281ee745e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AttentionNet(\n",
      "  (mlp_list): ModuleList(\n",
      "    (0-4): 5 x Sequential(\n",
      "      (0): Linear(in_features=32, out_features=32, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=32, out_features=32, bias=True)\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): Linear(in_features=32, out_features=32, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=32, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (conv_list): ModuleList(\n",
      "    (0): GATv2Conv(4, 16, heads=2)\n",
      "    (1-5): 5 x GATv2Conv(32, 16, heads=2)\n",
      "  )\n",
      "  (sigmoid): Sigmoid()\n",
      "  (graph_norms): ModuleList(\n",
      "    (0-5): 6 x BatchNorm(32)\n",
      "  )\n",
      ")\n",
      "tensor([0.5210, 0.5210, 0.5210, 0.5210, 0.5210, 0.5210, 0.5210, 0.5210, 0.5210,\n",
      "        0.5000], grad_fn=<ReshapeAliasBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = AttentionNet(single_pass_pooling=True)\n",
    "model.to(DEVICE)\n",
    "print(model) \n",
    "for step, data in enumerate(train_loader):\n",
    "  data = data.to(DEVICE)\n",
    "  print(model(data.x, data.edge_index, data.batch))\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SaQ7f2E4dCqd"
   },
   "source": [
    "#### TransformerNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "nS3CzlgcdEAK"
   },
   "outputs": [],
   "source": [
    "#relu = nn.Relu() ## todo: changed to relu here\n",
    "from torch_geometric.nn import TransformerConv\n",
    "\n",
    "class TransformerNet(torch.nn.Module):\n",
    "  def __init__(self, hidden_dim=32, layer_num=6, dropout=0.1, normalization=False, single_pass_pooling = False):\n",
    "    super(TransformerNet, self).__init__()\n",
    "\n",
    "    self.mlp_list = nn.ModuleList()\n",
    "    self.conv_list = nn.ModuleList()\n",
    "    self.sigmoid = nn.Sigmoid()\n",
    "    self.graph_norms = nn.ModuleList()\n",
    "    self.dropout = dropout\n",
    "    self.normalization = normalization\n",
    "    assert(hidden_dim % 2 == 0)\n",
    "    input_channels = NUM_CLASSES\n",
    "    self.single_pass_pooling = single_pass_pooling\n",
    "\n",
    "\n",
    "    for i in range(layer_num):\n",
    "      in_dim = hidden_dim if i > 0 else input_channels \n",
    "      out_dim = hidden_dim if i < layer_num-1 else 1 \n",
    "      self.conv_list.append(TransformerConv(in_channels=in_dim, out_channels=hidden_dim // 2, heads=2))\n",
    "      self.graph_norms.append(BatchNorm(hidden_dim))\n",
    "      self.mlp_list.append(Seq(Lin(hidden_dim, hidden_dim), nn.ReLU(), Lin(hidden_dim, hidden_dim), nn.ReLU(), Lin(hidden_dim, out_dim)))\n",
    "\n",
    "  def forward(self, x_in, edge_index, batch):\n",
    "    x = note_features_to_one_hot(x_in)\n",
    "    for i in range(len(self.conv_list)):\n",
    "      x = self.conv_list[i](x, edge_index)\n",
    "      if self.normalization:\n",
    "        x = self.graph_norms[i](x)\n",
    "      x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "      x = self.mlp_list[i](x)\n",
    "    \n",
    "    if self.single_pass_pooling:\n",
    "      x = global_mask_pool(x, x_in, batch)\n",
    "    else:\n",
    "      x = global_mean_pool(x, batch)\n",
    "\n",
    "    x = self.sigmoid(x) + EPSILON\n",
    "    return x.flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "plkfTVUrXRO-",
    "outputId": "a55bbb21-48d3-456f-a39d-b39b9252a9b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TransformerNet(\n",
      "  (mlp_list): ModuleList(\n",
      "    (0-4): 5 x Sequential(\n",
      "      (0): Linear(in_features=32, out_features=32, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=32, out_features=32, bias=True)\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): Linear(in_features=32, out_features=32, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=32, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (conv_list): ModuleList(\n",
      "    (0): TransformerConv(4, 16, heads=2)\n",
      "    (1-5): 5 x TransformerConv(32, 16, heads=2)\n",
      "  )\n",
      "  (sigmoid): Sigmoid()\n",
      "  (graph_norms): ModuleList(\n",
      "    (0-5): 6 x BatchNorm(32)\n",
      "  )\n",
      ")\n",
      "tensor([0.4885, 0.4883, 0.4884, 0.4885, 0.4884, 0.4884, 0.4883, 0.4883, 0.4884,\n",
      "        0.4884], grad_fn=<ReshapeAliasBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = TransformerNet()\n",
    "model.to(DEVICE)\n",
    "print(model) \n",
    "for step, data in enumerate(train_loader):\n",
    "  data = data.to(DEVICE)\n",
    "  print(model(data.x, data.edge_index, data.batch))\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UwghOZsDdEJz"
   },
   "source": [
    "#### Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "LEwIcO4w0VaR"
   },
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GraphUNet\n",
    "\n",
    "class Unet(torch.nn.Module):\n",
    "  def __init__(self, hidden_channels=32, out_channels=1, depth=4, single_pass_pooling = False):\n",
    "    super(Unet, self).__init__()\n",
    "    self.sigmoid = nn.Sigmoid()\n",
    "    in_channels = NUM_CLASSES\n",
    "    self.single_pass_pooling = single_pass_pooling\n",
    "    self.unet = GraphUNet(in_channels=in_channels, hidden_channels=hidden_channels, out_channels=out_channels, depth=depth)\n",
    "\n",
    "  def forward(self, x_in, edge_index, batch):\n",
    "    x = note_features_to_one_hot(x_in)\n",
    "    x = self.unet(x, edge_index)\n",
    "\n",
    "    if self.single_pass_pooling:\n",
    "      x = global_mask_pool(x, x_in, batch)\n",
    "    else:\n",
    "      x = global_mean_pool(x, batch)\n",
    "\n",
    "    x = self.sigmoid(x) + 0.0000001 # add eps to avoid div. by zero\n",
    "    return x.flatten()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YBYSWAp9XOLz",
    "outputId": "f5ef7b55-9c1c-47f0-972d-46334d938ba2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unet(\n",
      "  (sigmoid): Sigmoid()\n",
      "  (unet): GraphUNet(4, 32, 1, depth=4, pool_ratios=[0.5, 0.5, 0.5, 0.5])\n",
      ")\n",
      "tensor([0.5508, 0.5508, 0.5508, 0.5508, 0.5508, 0.5502, 0.5505, 0.5508, 0.5506,\n",
      "        0.5507], grad_fn=<ReshapeAliasBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gerritgrossmann/anaconda3/envs/nextaid/lib/python3.9/site-packages/torch_sparse/matmul.py:97: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1682343673238/work/aten/src/ATen/SparseCsrTensorImpl.cpp:56.)\n",
      "  C = torch.sparse.mm(A, B)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Unet()\n",
    "model.to(DEVICE)\n",
    "print(model) \n",
    "for step, data in enumerate(train_loader):\n",
    "  data.to(DEVICE)\n",
    "  print(model(data.x, data.edge_index, data.batch))\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ir4sFS6YS5UY"
   },
   "source": [
    "#### PNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "ydDINWbaaSav"
   },
   "outputs": [],
   "source": [
    "def print_inputs(*args):\n",
    "    for arg in args:\n",
    "        print(arg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "U_8SApKdS3wo"
   },
   "outputs": [],
   "source": [
    "from torch_geometric.nn import PNA\n",
    "from torch_geometric.utils import degree\n",
    "\n",
    "#train_dataset = build_dataset()\n",
    "\n",
    "def dataset_to_degree_bin(train_dataset):\n",
    "  # Compute the maximum in-degree in the training data.\n",
    "  max_degree = -1\n",
    "  for data in train_dataset:\n",
    "      d = degree(data.edge_index[1], num_nodes=data.num_nodes, dtype=torch.long)\n",
    "      max_degree = max(max_degree, int(d.max()))\n",
    "\n",
    "  deg = torch.zeros(max_degree + 1, dtype=torch.long)\n",
    "  for data in train_dataset:\n",
    "      d = degree(data.edge_index[1], num_nodes=data.num_nodes, dtype=torch.long)\n",
    "      deg += torch.bincount(d, minlength=deg.numel())\n",
    "  return deg\n",
    "\n",
    "class PNAnet(torch.nn.Module):\n",
    "  def __init__(self, train_dataset_example, hidden_channels=32, depth=4, dropout=0.0, towers=2, single_pass_pooling=False, graph_transform=False, normalization=True, pre_post_layers=1):\n",
    "    super(PNAnet, self).__init__()\n",
    "    self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    # Calculate x as the difference between mult_y and hidden_dim\n",
    "    hidden_channels = towers * ((hidden_channels // towers) + 1)\n",
    "    #out_channels = towers * ((out_channels // towers) + 1)\n",
    "\n",
    "    in_channels = NUM_CLASSES\n",
    "    if graph_transform:\n",
    "      in_channels += NODE_FEATURE_EXTEND\n",
    "    deg = dataset_to_degree_bin(train_dataset_example)\n",
    "    aggregators = ['mean', 'min', 'max', 'std']\n",
    "    scalers = ['identity', 'amplification', 'attenuation']\n",
    "    self.normalization = BatchNorm(hidden_channels) if normalization else None\n",
    "    self.pnanet = PNA(in_channels=in_channels, hidden_channels=hidden_channels, out_channels=hidden_channels, num_layers=depth, aggregators=aggregators, scalers=scalers, deg=deg, dropout=dropout, towers=towers, norm=self.normalization, pre_layers=pre_post_layers, post_layers=pre_post_layers)\n",
    "    self.single_pass_pooling = single_pass_pooling\n",
    "    self.graph_transform = graph_transform\n",
    "\n",
    "    self.final_mlp = Seq(Lin(hidden_channels, hidden_channels), nn.ReLU(), Lin(hidden_channels, hidden_channels), nn.ReLU(), Lin(hidden_channels, 1))\n",
    "\n",
    "\n",
    "  def forward(self, x_in, edge_index, batch):\n",
    "    x = note_features_to_one_hot(x_in)\n",
    "    if self.graph_transform:\n",
    "      x = extend_node_features(x, edge_index, batch)\n",
    "    x = self.pnanet(x, edge_index)\n",
    "\n",
    "    if self.single_pass_pooling:\n",
    "      x = global_mask_pool(x, x_in, batch)\n",
    "    else:\n",
    "      x = global_mean_pool(x, batch)\n",
    "\n",
    "    #x = x.sum(dim=1)\n",
    "    x = self.final_mlp(x)\n",
    "    x = self.sigmoid(x) + EPSILON # add eps to avoid div. by zero\n",
    "    return x.flatten()\n",
    "\n",
    "class PNAmulti(torch.nn.Module):\n",
    "  def __init__(self, train_dataset_example, hidden_channels=32, graph_transform=False, depth=4, dropout=0.0, towers=1, model_num=5, single_pass_pooling=False, normalization=True, pre_post_layers=1):\n",
    "    super(PNAmulti, self).__init__()\n",
    "    self.model_num = model_num\n",
    "    self.pna_list = nn.ModuleList()\n",
    "    self.sigmoid = nn.Sigmoid()\n",
    "    weights = torch.ones(model_num)\n",
    "    self.weights = nn.Parameter(weights)  # nn.Parameter is a Tensor that's a module parameter.\n",
    "    for i in range(model_num):\n",
    "      # towers is i+1\n",
    "      pna_model = PNAnet(train_dataset_example, hidden_channels=hidden_channels, graph_transform=graph_transform, depth=depth, dropout=dropout, towers=i+1, single_pass_pooling=single_pass_pooling, normalization=normalization, pre_post_layers=pre_post_layers)\n",
    "      self.pna_list.append(pna_model)\n",
    "\n",
    "  def get_normalized_weights(self):\n",
    "    w_sigmoid = self.sigmoid(self.weights)\n",
    "    w = w_sigmoid/w_sigmoid.sum()\n",
    "    return w\n",
    "\n",
    "  def forward(self, x, edge_index, batch):\n",
    "    x_agg = None\n",
    "    i_not = random.choice(range(len(self.pna_list))) if self.training  and len(self.pna_list) > 1 else -1 # skip 1 during training\n",
    "    w = self.get_normalized_weights()\n",
    "    for i, pna_model in enumerate(self.pna_list):\n",
    "      if i == i_not:\n",
    "        continue\n",
    "      if x_agg is None:\n",
    "        x_agg = pna_model(x, edge_index, batch) * w[i]\n",
    "      else:\n",
    "        x_agg = x_agg + pna_model( x, edge_index, batch) * w[i]\n",
    "    return x_agg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TTvXwuajPPOJ",
    "outputId": "a919e1b7-cfc1-418e-bba0-c88274816465"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNAmulti(\n",
      "  (pna_list): ModuleList(\n",
      "    (0): PNAnet(\n",
      "      (sigmoid): Sigmoid()\n",
      "      (normalization): BatchNorm(33)\n",
      "      (pnanet): PNA(4, 33, num_layers=4)\n",
      "      (final_mlp): Sequential(\n",
      "        (0): Linear(in_features=33, out_features=33, bias=True)\n",
      "        (1): ReLU()\n",
      "        (2): Linear(in_features=33, out_features=33, bias=True)\n",
      "        (3): ReLU()\n",
      "        (4): Linear(in_features=33, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (1): PNAnet(\n",
      "      (sigmoid): Sigmoid()\n",
      "      (normalization): BatchNorm(34)\n",
      "      (pnanet): PNA(4, 34, num_layers=4)\n",
      "      (final_mlp): Sequential(\n",
      "        (0): Linear(in_features=34, out_features=34, bias=True)\n",
      "        (1): ReLU()\n",
      "        (2): Linear(in_features=34, out_features=34, bias=True)\n",
      "        (3): ReLU()\n",
      "        (4): Linear(in_features=34, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (2): PNAnet(\n",
      "      (sigmoid): Sigmoid()\n",
      "      (normalization): BatchNorm(33)\n",
      "      (pnanet): PNA(4, 33, num_layers=4)\n",
      "      (final_mlp): Sequential(\n",
      "        (0): Linear(in_features=33, out_features=33, bias=True)\n",
      "        (1): ReLU()\n",
      "        (2): Linear(in_features=33, out_features=33, bias=True)\n",
      "        (3): ReLU()\n",
      "        (4): Linear(in_features=33, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (3): PNAnet(\n",
      "      (sigmoid): Sigmoid()\n",
      "      (normalization): BatchNorm(36)\n",
      "      (pnanet): PNA(4, 36, num_layers=4)\n",
      "      (final_mlp): Sequential(\n",
      "        (0): Linear(in_features=36, out_features=36, bias=True)\n",
      "        (1): ReLU()\n",
      "        (2): Linear(in_features=36, out_features=36, bias=True)\n",
      "        (3): ReLU()\n",
      "        (4): Linear(in_features=36, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (4): PNAnet(\n",
      "      (sigmoid): Sigmoid()\n",
      "      (normalization): BatchNorm(35)\n",
      "      (pnanet): PNA(4, 35, num_layers=4)\n",
      "      (final_mlp): Sequential(\n",
      "        (0): Linear(in_features=35, out_features=35, bias=True)\n",
      "        (1): ReLU()\n",
      "        (2): Linear(in_features=35, out_features=35, bias=True)\n",
      "        (3): ReLU()\n",
      "        (4): Linear(in_features=35, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "tensor([0.4104, 0.4104, 0.4104, 0.4104, 0.4104, 0.4104, 0.4104, 0.4104, 0.4104,\n",
      "        0.4104], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = PNAmulti(build_dataset()[0])\n",
    "model.to(DEVICE)\n",
    "print(model) \n",
    "for step, data in enumerate(train_loader):\n",
    "  data.to(DEVICE)\n",
    "  print(model(data.x, data.edge_index, data.batch))\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hSyYUfY1X6Os",
    "outputId": "507c64d0-2f3e-442d-8f1f-fb5aece60a4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNAnet(\n",
      "  (sigmoid): Sigmoid()\n",
      "  (normalization): BatchNorm(34)\n",
      "  (pnanet): PNA(4, 34, num_layers=4)\n",
      "  (final_mlp): Sequential(\n",
      "    (0): Linear(in_features=34, out_features=34, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=34, out_features=34, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=34, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "tensor([0.5186, 0.5186, 0.5186, 0.5186, 0.5186, 0.5186, 0.5186, 0.5186, 0.5186,\n",
      "        0.5186], grad_fn=<ReshapeAliasBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = PNAnet(build_dataset()[0])\n",
    "model.to(DEVICE)\n",
    "print(model) \n",
    "for step, data in enumerate(train_loader):\n",
    "  data.to(DEVICE)\n",
    "  print(model(data.x, data.edge_index, data.batch))\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jB6WbKuwVdix"
   },
   "source": [
    "#### PNA2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "6Mvgyb_hVgpv"
   },
   "outputs": [],
   "source": [
    "from torch_geometric.nn import PNAConv\n",
    "\n",
    "class PNA2net(torch.nn.Module):\n",
    "  def __init__(self, train_dataset_example, hidden_dim=32, layer_num=4, dropout=0.0, normalization=False, tower_num=5, single_pass_pooling=False):\n",
    "    super().__init__()\n",
    "\n",
    "    aggregators = ['mean', 'min', 'max', 'std', 'var', 'sum']\n",
    "    scalers = ['identity', 'amplification', 'attenuation']\n",
    "    deg = dataset_to_degree_bin(train_dataset_example)\n",
    "\n",
    "    # Calculate x as the difference between mult_y and hidden_dim\n",
    "    hidden_dim = tower_num * ((hidden_dim // tower_num) + 1)\n",
    "\n",
    "    self.conv_list = nn.ModuleList()\n",
    "    self.batchnorm_list = nn.ModuleList()\n",
    "    self.mlp_list = nn.ModuleList()\n",
    "\n",
    "    self.dropout = dropout\n",
    "    self.normalization = normalization\n",
    "    self.sigmoid = nn.Sigmoid()\n",
    "    self.single_pass_pooling = single_pass_pooling\n",
    "\n",
    "    input_channels = NUM_CLASSES\n",
    "  \n",
    "\n",
    "    for i in range(layer_num):\n",
    "      in_dim = hidden_dim if i > 0 else input_channels \n",
    "      out_dim = hidden_dim if i < layer_num-1 else 1 \n",
    "      self.conv_list.append(PNAConv(in_channels=in_dim, out_channels=hidden_dim, aggregators=aggregators, scalers=scalers, deg=deg, towers=tower_num, pre_layers=1, post_layers=1, divide_input=False))\n",
    "      self.batchnorm_list.append(BatchNorm(hidden_dim))\n",
    "      self.mlp_list.append(Seq(nn.ReLU(), Lin(hidden_dim+NUM_CLASSES+in_dim, hidden_dim+NUM_CLASSES+in_dim), nn.ReLU(), Lin(hidden_dim+NUM_CLASSES+in_dim, hidden_dim+NUM_CLASSES+in_dim), nn.ReLU(), Lin(hidden_dim+NUM_CLASSES+in_dim, out_dim)))\n",
    "          \n",
    "  def forward(self, x_in, edge_index, batch):\n",
    "    x_onehot = note_features_to_one_hot(x_in)\n",
    "    x = x_onehot.clone()\n",
    "    for i in range(len(self.conv_list)):\n",
    "      x_in = x.clone()\n",
    "      x = self.conv_list[i](x, edge_index)\n",
    "      if self.normalization:\n",
    "        x = self.batchnorm_list[i](x)\n",
    "      x_concat = torch.concat([x, x_onehot, x_in], dim=1)\n",
    "      x = self.mlp_list[i](x_concat)\n",
    "      if i < len(self.conv_list)-1:\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "\n",
    "    if self.single_pass_pooling:\n",
    "      x = global_mask_pool(x, x_in, batch)\n",
    "    else:\n",
    "      x = global_mean_pool(x, batch)\n",
    "      \n",
    "    x = self.sigmoid(x) + EPSILON\n",
    "    return x.flatten()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rgjqgcfhY1gC",
    "outputId": "43446f0e-9b7e-4570-a660-f15f06c99bd1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNA2net(\n",
      "  (conv_list): ModuleList(\n",
      "    (0): PNAConv(4, 35, towers=5, edge_dim=None)\n",
      "    (1-3): 3 x PNAConv(35, 35, towers=5, edge_dim=None)\n",
      "  )\n",
      "  (batchnorm_list): ModuleList(\n",
      "    (0-3): 4 x BatchNorm(35)\n",
      "  )\n",
      "  (mlp_list): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): ReLU()\n",
      "      (1): Linear(in_features=43, out_features=43, bias=True)\n",
      "      (2): ReLU()\n",
      "      (3): Linear(in_features=43, out_features=43, bias=True)\n",
      "      (4): ReLU()\n",
      "      (5): Linear(in_features=43, out_features=35, bias=True)\n",
      "    )\n",
      "    (1-2): 2 x Sequential(\n",
      "      (0): ReLU()\n",
      "      (1): Linear(in_features=74, out_features=74, bias=True)\n",
      "      (2): ReLU()\n",
      "      (3): Linear(in_features=74, out_features=74, bias=True)\n",
      "      (4): ReLU()\n",
      "      (5): Linear(in_features=74, out_features=35, bias=True)\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): ReLU()\n",
      "      (1): Linear(in_features=74, out_features=74, bias=True)\n",
      "      (2): ReLU()\n",
      "      (3): Linear(in_features=74, out_features=74, bias=True)\n",
      "      (4): ReLU()\n",
      "      (5): Linear(in_features=74, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "tensor([0.4878, 0.4878, 0.4878, 0.4878, 0.4878, 0.4878, 0.4878, 0.4878, 0.4878,\n",
      "        0.4878], grad_fn=<ReshapeAliasBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = PNA2net(build_dataset()[0])\n",
    "model.to(DEVICE)\n",
    "print(model) \n",
    "for step, data in enumerate(train_loader):\n",
    "  data.to(DEVICE)\n",
    "  print(model(data.x, data.edge_index, data.batch))\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tph0rjhNS6iS"
   },
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_K0Yuz5FNVdy"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "gDKYLoMV6z6J"
   },
   "outputs": [],
   "source": [
    "def build_model(config, dataset):\n",
    "  hidden_dim = config.hidden_dim\n",
    "  single_pass_pooling = config.single_pass\n",
    "  if config.model == \"unet\":\n",
    "    model =  Unet(hidden_channels = hidden_dim,  out_channels = 1, depth=config.hidden_layer, single_pass_pooling=single_pass_pooling)\n",
    "  elif config.model == \"attention\":\n",
    "     model = AttentionNet(hidden_dim=hidden_dim, layer_num=config.hidden_layer, dropout=config.dropout, normalization=config.normalization, single_pass_pooling=single_pass_pooling)\n",
    "  elif config.model == \"transformer\":\n",
    "    model = TransformerNet(hidden_dim=hidden_dim, layer_num=config.hidden_layer, dropout=config.dropout, normalization=config.normalization, single_pass_pooling=single_pass_pooling)\n",
    "  elif config.model == \"pna\":\n",
    "    model = PNAnet(dataset, hidden_channels=hidden_dim, depth=config.hidden_layer, dropout=config.dropout, towers=config.towers, single_pass_pooling=single_pass_pooling, graph_transform=config.graph_transform, normalization=config.normalization, pre_post_layers=config.pre_post_layers)\n",
    "  elif config.model == \"pnamulti\":\n",
    "    model = PNAmulti(dataset, hidden_channels=hidden_dim, depth=config.hidden_layer, dropout=config.dropout, towers=config.towers, single_pass_pooling=single_pass_pooling, graph_transform=config.graph_transform, normalization=config.normalization, pre_post_layers=config.pre_post_layers)\n",
    "  elif config.model == \"pna2\":\n",
    "    model = PNA2net(dataset, hidden_dim=hidden_dim, layer_num=config.hidden_layer, dropout=config.dropout, normalization=config.normalization, single_pass_pooling=single_pass_pooling)\n",
    "  else:\n",
    "    ValueError(\"illegal net\")\n",
    "  return model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2GDOIysiiIGT"
   },
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "FsofkLkkP3GK"
   },
   "outputs": [],
   "source": [
    "def find_best_choice(model, g, test_choices, x, x_shape):\n",
    "  p_0_list = list()\n",
    "  p_1_list = list()\n",
    "  x_noedge_list = list()\n",
    "  x_edge_list = list()\n",
    "  mask_indicator_list = list()\n",
    "\n",
    "  for i, mask_indicator in enumerate(test_choices):\n",
    "    x_noedge, x_edge = x.clone(), x.clone()\n",
    "    x_noedge[mask_indicator] = NO_EDGE_INDICATOR\n",
    "    x_edge[mask_indicator] = EDGE_INDICATOR\n",
    "    batch = torch.zeros(x_shape[0], dtype=torch.long).to(DEVICE)\n",
    "    p_0 = model(x_noedge.view(x_shape), g.edge_index, batch=batch).item()\n",
    "    p_1 = model(x_edge.view(x_shape), g.edge_index, batch=batch).item()\n",
    "\n",
    "    p_0_list.append(p_0/(p_0+p_1))\n",
    "    p_1_list.append(p_1/(p_0+p_1))\n",
    "    x_noedge_list.append(x_noedge)\n",
    "    x_edge_list.append(x_edge)\n",
    "    mask_indicator_list.append(mask_indicator)\n",
    "\n",
    "  best_i = np.argmax(p_1_list)\n",
    "  return p_0_list[best_i], p_1_list[best_i], x_noedge_list[best_i],  x_edge_list[best_i], mask_indicator_list[best_i]\n",
    "\n",
    "\n",
    "def generate_graph_multi(model, g, choice_num=5):\n",
    "  x = g.x\n",
    "  x_shape = x.shape\n",
    "  x = x.flatten()\n",
    "  indices_of_edges = (x != DUMMY).nonzero(as_tuple=False).flatten()\n",
    "  num_edges = indices_of_edges.numel()\n",
    "  x[indices_of_edges] = MASK\n",
    "  indices_of_edges = indices_of_edges.flatten().tolist()\n",
    "\n",
    "  for _ in range(num_edges):\n",
    "    random.shuffle(indices_of_edges)\n",
    "    choice_num_i = min(choice_num, len(indices_of_edges)) \n",
    "    test_choices = indices_of_edges[0:choice_num_i]\n",
    "    p_0, p_1, x_noedge, x_edge, mask_indicator = find_best_choice(model, g, test_choices, x, x_shape)\n",
    "    random_selection_index = int(np.random.choice([0, 1], size=1, p=[p_0, p_1]))\n",
    "    x = (x_noedge, x_edge)[random_selection_index]\n",
    "    indices_of_edges.remove(mask_indicator)\n",
    "\n",
    "  g.x = x.reshape(x_shape)\n",
    "  return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 131
    },
    "id": "DQay_Zy35bHr",
    "outputId": "8b841102-0192-46a7-b1b4-b1ced222de41"
   },
   "outputs": [],
   "source": [
    "def test_candidates(candidates, x, g, batch, x_shape):\n",
    "  best_edge_index = None\n",
    "  best_edge_prob = None\n",
    "\n",
    "  for edge_index in candidates:\n",
    "    x[edge_index] = -1.0\n",
    "    edge_prob = model(x.view(x_shape), g.edge_index, batch=batch).item()\n",
    "    x[edge_index] = MASK\n",
    "    if best_edge_prob is None or max(edge_prob, 1.0-edge_prob) > best_edge_prob:\n",
    "      best_edge_index = edge_index\n",
    "      best_edge_prob = edge_prob\n",
    "\n",
    "  return best_edge_index, best_edge_prob\n",
    "\n",
    "def generate_graph_singlepass(model, g, choice_num = 1, config = None):\n",
    "  # does not have multi\n",
    "  x = g.x\n",
    "  x_shape = x.shape\n",
    "  x = x.flatten()\n",
    "  indices_of_edges = (x != DUMMY).nonzero(as_tuple=False).flatten()\n",
    "  num_edges = indices_of_edges.numel()\n",
    "  x[indices_of_edges] = MASK\n",
    "  indices_of_edges = indices_of_edges.flatten().tolist()\n",
    "  random.shuffle(indices_of_edges)\n",
    "  batch = torch.zeros(x_shape[0], dtype=torch.long).to(DEVICE)\n",
    "\n",
    "  if config is not None and config.double_inference == True:\n",
    "    indices_of_edges = list(indices_of_edges) + list(indices_of_edges)\n",
    "\n",
    "  for i in range(len(indices_of_edges)):  \n",
    "    i_dyn = min(choice_num, len(indices_of_edges) - i)\n",
    "    candidates = indices_of_edges[i:i+i_dyn]\n",
    "    #print(\"candidates \",candidates)\n",
    "    edge_index, edge_prob = test_candidates(candidates, x, g, batch, x_shape)\n",
    "\n",
    "    assert(edge_prob > 0.0 and edge_prob < 1.0)\n",
    "    if random.random() < edge_prob:\n",
    "      x[edge_index] = EDGE_INDICATOR\n",
    "    else:\n",
    "      x[edge_index] = NO_EDGE_INDICATOR\n",
    "\n",
    "  g.x = x.reshape(x_shape)\n",
    "  return g\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "_cN5gKKUiJTR"
   },
   "outputs": [],
   "source": [
    "@torch.inference_mode()\n",
    "def generate_graphs(num, epoch_i, model, g_like, config):\n",
    "  model.eval()\n",
    "  mean_degree_list = list()\n",
    "  var_degree_list = list()\n",
    "  nx_graph_list = list()\n",
    "  for j in range(num):\n",
    "    if config.single_pass:\n",
    "      g = generate_graph_singlepass(model, g_like, choice_num = config.candidate_selection_radius, config=config)\n",
    "    else:\n",
    "      g = generate_graph_multi(model, g_like, choice_num = config.candidate_selection_radius)\n",
    "    nx_orig_graph = draw_pyg(g, filename=f\"generated_graph_epoch{str(epoch_i).zfill(5)}_sample{str(j).zfill(5)}.jpg\")\n",
    "    degree_list = [nx_orig_graph.degree(i) for i in nx_orig_graph.nodes()]\n",
    "    mean_degree_list.append(np.mean(degree_list))\n",
    "    var_degree_list.append(np.var(degree_list))\n",
    "    nx_graph_list.append(nx_orig_graph)\n",
    "  return np.mean(mean_degree_list), np.mean(var_degree_list), nx_graph_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GKxurLjrXnCo"
   },
   "source": [
    "## Generat Samples for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "nALlwSTtXmhx"
   },
   "outputs": [],
   "source": [
    "def gen_random_training_sample_unused(x):\n",
    "  x_masked = x.clone().reshape(-1)\n",
    "  indices_of_edges = (x_masked != DUMMY).nonzero(as_tuple=False).flatten()\n",
    "  num_edges = indices_of_edges.numel()\n",
    "  num_masked = torch.randint(1, num_edges+1, size=(1,), device=DEVICE)\n",
    "  #num_masked = sample_num_masked_geometric(1, num_edges+1)\n",
    "\n",
    "  shuffled_indices_of_edges = indices_of_edges[torch.randperm(indices_of_edges.numel())]\n",
    "  indices_of_edges_to_mask = shuffled_indices_of_edges[:num_masked]\n",
    "  \n",
    "  gt_value = x_masked[indices_of_edges_to_mask[0]].item() # we will change the first value back\n",
    "  x_masked[indices_of_edges_to_mask] = MASK\n",
    "\n",
    "\n",
    "  x_masked_0 = x_masked.clone()\n",
    "  x_masked_0[indices_of_edges_to_mask[0]] = NO_EDGE_INDICATOR\n",
    "  x_masked_0 = x_masked_0.reshape(x.shape)\n",
    "\n",
    "  x_masked_1 = x_masked.clone()\n",
    "  x_masked_1[indices_of_edges_to_mask[0]] = EDGE_INDICATOR\n",
    "  x_masked_1 = x_masked_1.reshape(x.shape)\n",
    "\n",
    "  if gt_value == NO_EDGE_INDICATOR:\n",
    "    return x_masked_0, x_masked_1\n",
    "  elif gt_value == EDGE_INDICATOR:\n",
    "    return x_masked_1, x_masked_0 \n",
    "  assert(False)\n",
    "\n",
    "  return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "G-gIs8GVYm5l"
   },
   "outputs": [],
   "source": [
    "def sample_mask_and_flip(batch, x):\n",
    "  num_graphs = batch.view(-1)[-1]\n",
    "  x_id_mask = list()\n",
    "  x_id_flip = list()\n",
    "\n",
    "  for graph_id in range(num_graphs+1):\n",
    "    #num_nodes = (batch == graph_id).sum()\n",
    "    #indices_of_edges = (x != DUMMY and batch == graph_id).nonzero(as_tuple=False)\n",
    "    edge_indicator = x.view(-1) != DUMMY\n",
    "    batch_indicator = batch.view(-1) == graph_id \n",
    "    indices_of_edges = torch.nonzero(batch_indicator & edge_indicator)\n",
    "    indices_of_edges = indices_of_edges.flatten().tolist()\n",
    "    random.shuffle(indices_of_edges)\n",
    "    x_id_flip.append(indices_of_edges[-1])\n",
    "    num_masked = random.choice(range(len(indices_of_edges)))\n",
    "    x_id_mask = x_id_mask + indices_of_edges[:num_masked]\n",
    "\n",
    "  mask_and_flip_indicator = torch.zeros(batch.numel(), dtype=torch.long).to(DEVICE)\n",
    "  mask_and_flip_indicator[x_id_mask] = 1\n",
    "  mask_and_flip_indicator[x_id_flip] = 2\n",
    "\n",
    "  return mask_and_flip_indicator\n",
    "\n",
    "def mask_x_based_on_indicator(x, mask_and_flip_indicator):\n",
    "  x_new = x.clone()\n",
    "  to_mask = mask_and_flip_indicator == 1\n",
    "  x_new.view(-1)[to_mask] = MASK\n",
    "  return x_new\n",
    "\n",
    "\n",
    "# this is done inplace!\n",
    "def flip_x_based_on_indicator(x, mask_and_flip_indicator):\n",
    "  to_flip = (mask_and_flip_indicator == 2)#.to(DEVICE)\n",
    "  x = x.clone()  #sadly in-place operation not allowed here\n",
    "\n",
    "  #x[to_flip] = -x[to_flip]\n",
    "\n",
    "  x[to_flip] = torch.where(x[to_flip] == EDGE_INDICATOR, torch.tensor(NO_EDGE_INDICATOR).to(DEVICE), torch.tensor(EDGE_INDICATOR).to(DEVICE))\n",
    "\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "1La4pbjWakyz"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for step, data in enumerate(train_loader):\n",
    "  data.to(DEVICE)\n",
    "  mask_and_flip_indicator = sample_mask_and_flip(data.batch, data.x)\n",
    "  break\n",
    "\n",
    "\n",
    "x = (mask_x_based_on_indicator(data.x, mask_and_flip_indicator))\n",
    "xz = x.clone()\n",
    "xx = (flip_x_based_on_indicator(x, mask_and_flip_indicator))\n",
    "\n",
    "(xz == xx).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TulPGAH8R0Eo"
   },
   "source": [
    "## Compute Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "flDsYTRKR1ZB"
   },
   "outputs": [],
   "source": [
    "bce_loss = nn.BCELoss()\n",
    "def reduce_loss(loss_for_graph, config):\n",
    "  # loss_for_graph should be > 0\n",
    "  if config.loss == \"l1\":\n",
    "    return loss_for_graph.sum() \n",
    "  elif config.loss == \"l2\":\n",
    "    return F.mse_loss(loss_for_graph, torch.zeros_like(loss_for_graph))\n",
    "  elif config.loss == \"bce\":\n",
    "    return bce_loss(loss_for_graph, torch.zeros_like(loss_for_graph))\n",
    "  else:\n",
    "    raise ValueError(\"Illegal loss value\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SVx9HGc89VFe"
   },
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "K4M0XZ5Vpk5Z"
   },
   "outputs": [],
   "source": [
    "def prepare_x_for_single_pass(mask_and_flip_indicator, x):\n",
    "  x_new = x.clone()\n",
    "  to_mask = mask_and_flip_indicator == 1\n",
    "  x_new.view(-1)[to_mask] = MASK\n",
    "  choice_indicator = mask_and_flip_indicator == 2\n",
    "  x_new.view(-1)[choice_indicator] = -1 # this will be set to zero in the one hot encoding step\n",
    "  gt = x.clone().flatten()[choice_indicator]\n",
    "  gt = torch.where(gt == EDGE_INDICATOR, torch.tensor(1.0, device = DEVICE), torch.zeros_like(gt))\n",
    "  return x_new, gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "gj5td9zue7HT"
   },
   "outputs": [],
   "source": [
    "def single_pass_prediction(data, model, config):\n",
    "  mask_and_flip_indicator = sample_mask_and_flip(data.batch, data.x)\n",
    "  x_in, out_gt = prepare_x_for_single_pass(mask_and_flip_indicator, data.x)\n",
    "\n",
    "  if model.training: x_in = flip_edges_randomly(x_in, config.noise_probability)\n",
    "\n",
    "  out_prediction = model(x_in, data.edge_index, data.batch) # between 0 ,1 \n",
    "\n",
    "  #print(\"out gt: \", out_gt.flatten(), \"   out pred:   \", out_prediction.flatten())\n",
    "\n",
    "  loss_for_graph =  torch.abs(out_prediction.flatten() - out_gt.flatten()) # between 0 and 1\n",
    "  return loss_for_graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "sUfUS3OYfNxu"
   },
   "outputs": [],
   "source": [
    "def multi_pass_prediction(data, model, config):\n",
    "  mask_and_flip_indicator = sample_mask_and_flip(data.batch, data.x) # this then should also return gt \n",
    "  x = mask_x_based_on_indicator(data.x, mask_and_flip_indicator)\n",
    "\n",
    "  if model.training: x = flip_edges_randomly(x, config.noise_probability)\n",
    "\n",
    "  out_correct = model(x, data.edge_index, data.batch)  # is supposed to be 1 everywhere\n",
    "  x = flip_x_based_on_indicator(x, mask_and_flip_indicator)  # important to use x here and not data.x\n",
    "  out_incorrect = model(x, data.edge_index, data.batch) # is supposed to be 0 everywhere\n",
    "  loss_for_graph =  out_incorrect - out_correct # between -1 and 1\n",
    "  loss_for_graph = (loss_for_graph + 1.0) / 2.0   # between 0 and 1,\n",
    "  return loss_for_graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "-_84ieMIoYh5"
   },
   "outputs": [],
   "source": [
    "def feed_data_to_model(data, model, config):\n",
    "  if config.single_pass == True:\n",
    "    return single_pass_prediction(data, model, config)\n",
    "  return multi_pass_prediction(data, model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 264], x=[78, 1])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_dataset_train, graph_dataset_test  = build_dataset()\n",
    "graph_dataset_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f8RF9E-wfDXW"
   },
   "source": [
    "### Start Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "lDBAh9XPiO-a"
   },
   "outputs": [],
   "source": [
    "def start_agent(config):\n",
    "  graph_dataset_train, graph_dataset_test = build_dataset()\n",
    "  #graphs_ref_nx = build_test_set_nx(seed=42)\n",
    "  degree_loss, cluster_loss = compute_expected_optimal_loss(graph_dataset_train, graph_dataset_test)\n",
    "  print('Reference distance is: ', degree_loss, cluster_loss)\n",
    "  wandb.log({\"stats/degree_train\": degree_loss,  \"stats/cluster_train\": cluster_loss})\n",
    "\n",
    "  model = build_model(config, graph_dataset)\n",
    "  wandb.log({\"num_parameters\": sum(p.numel() for p in model.parameters())})\n",
    "\n",
    "  optimizer = Adam(model.parameters(), lr = config.learning_rate) \n",
    "  train_loader = DataLoader(graph_dataset_train, batch_size=config.batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "  for epoch_i in range(NUM_EPOCHS):\n",
    "    loss_list = list()\n",
    "    for step, data in enumerate(train_loader):\n",
    "      data.to(DEVICE)\n",
    "      model.train()\n",
    "      model.zero_grad()\n",
    "\n",
    "      loss_for_graph = feed_data_to_model(data, model, config) # between 0 and 1, probabilty of the incorrect choice\n",
    "      loss = reduce_loss(loss_for_graph, config)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      loss =  ((loss_for_graph.mean()).item()  -0.5 ) * 2.0 # between - 0.5 and 0.5 -> between - 1 and 1\n",
    "      loss_list.append(loss)\n",
    "      #wandb.log({\"epoch\": epoch_i+1, \"loss\": np.mean(loss_list)})\n",
    "\n",
    "    \n",
    "    # early stopping\n",
    "    if np.mean(loss_list) > -0.000001 and (epoch_i > 199 and epoch_i % 100 == 0):\n",
    "      return\n",
    "\n",
    "    print('epoch: {:06}  loss: {:.5f}'.format(epoch_i+1 ,np.mean(loss_list)))\n",
    "\n",
    "    if epoch_i % GENERATE_X_EPOCHS == 0 or epoch_i == NUM_EPOCHS-1:\n",
    "      dummy_graph = graph_dataset_train[0].clone().to(DEVICE)\n",
    "      print(\"start graph generation\")\n",
    "      deg_mean, deg_var, graphs_pred_nx = generate_graphs(NUM_GRAPHS_GENERATE, epoch_i, model, dummy_graph, config)\n",
    "      print(\"finish graph generation\")\n",
    "      generator_loss = (DEGREE-deg_mean)**2 + deg_var\n",
    "      wandb.log({\"graph-unmasking/gen-loss\": generator_loss, \"mean degree\": deg_mean, \"mean degree var\":deg_var, \"graph-unmasking/loss\": np.mean(loss_list)})\n",
    "      degree_loss, cluster_loss = compute_mmd_stats(graphs_pred_nx, graph_dataset_test)\n",
    "      wandb.log({\"stats/degree\": degree_loss,  \"stats/cluster\": cluster_loss})\n",
    "      print(deg_mean, deg_var, degree_loss, cluster_loss)\n",
    "\n",
    "  torch.save(model.state_dict(), \"model.weights\")\n",
    "  wandb.log_artifact(\"model.weights\", name=f'nn_weights_{SWEEP_ID}', type='weights') \n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "qPcPralV7IF0"
   },
   "outputs": [],
   "source": [
    "def start_agent_envelope():\n",
    "  try:\n",
    "    with wandb.init():\n",
    "      config = wandb.config\n",
    "      set_seeds(SWEEP_ID)\n",
    "      print(SWEEP_ID, config)\n",
    "      if not IN_COLAB:\n",
    "        for python_file in sorted(glob.glob('*.ipynb')):\n",
    "          wandb.log_artifact(python_file, name=f\"src_ipynb_{SWEEP_ID}\", type=\"my_dataset\")\n",
    "        for python_file in sorted(glob.glob('*.py')):\n",
    "          wandb.log_artifact(python_file, name=f\"src_py_{SWEEP_ID}\", type=\"my_dataset\")\n",
    "      return start_agent(config)\n",
    "  except Exception:\n",
    "    print(traceback.format_exc())\n",
    "    wandb.log({\"graph-unmasking/gen-loss\": -1,  \"epoch\": -1, \"graph-unmasking/loss\": -1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "OHuZY5f_4NrN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: j8frw6u2\n",
      "Sweep URL: https://wandb.ai/nextaid/toad_double/sweeps/j8frw6u2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: qt0uuvcc with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcandidate_selection_radius: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdouble_inference: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgraph_transform: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: bce\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: pna\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnoise_probability: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnormalization: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_post_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_pass: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttowers: 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/gerritgrossmann/Documents/devel/MaskedGraphGen/wandb/run-20230531_091052-qt0uuvcc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nextaid/toad_double/runs/qt0uuvcc' target=\"_blank\">glamorous-sweep-1</a></strong> to <a href='https://wandb.ai/nextaid/toad_double' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/nextaid/toad_double/sweeps/j8frw6u2' target=\"_blank\">https://wandb.ai/nextaid/toad_double/sweeps/j8frw6u2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nextaid/toad_double' target=\"_blank\">https://wandb.ai/nextaid/toad_double</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/nextaid/toad_double/sweeps/j8frw6u2' target=\"_blank\">https://wandb.ai/nextaid/toad_double/sweeps/j8frw6u2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nextaid/toad_double/runs/qt0uuvcc' target=\"_blank\">https://wandb.ai/nextaid/toad_double/runs/qt0uuvcc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j8frw6u2 {'batch_size': 100, 'candidate_selection_radius': 1, 'double_inference': True, 'dropout': 0, 'graph_transform': True, 'hidden_dim': 16, 'hidden_layer': 6, 'learning_rate': 0.0001, 'loss': 'bce', 'model': 'pna', 'noise_probability': 0.1, 'normalization': True, 'pre_post_layers': 1, 'single_pass': True, 'towers': 2}\n",
      "Reference distance is:  0.0 0.009534636872396862\n",
      "epoch: 000001  loss: 0.03623\n",
      "start graph generation\n",
      "finish graph generation\n",
      "5.35 1.8972222222222226 0.6076309238344242 0.33750724398481696\n",
      "epoch: 000101  loss: -0.23779\n",
      "start graph generation\n",
      "finish graph generation\n",
      "5.216666666666667 1.8694444444444447 0.5754343672400637 0.33735153552099295\n",
      "epoch: 000201  loss: -0.29192\n",
      "start graph generation\n",
      "finish graph generation\n",
      "5.016666666666667 2.519444444444445 0.553641177676883 0.33825591556312656\n",
      "epoch: 000301  loss: -0.30255\n",
      "start graph generation\n",
      "finish graph generation\n",
      "5.416666666666666 2.063888888888889 0.6185010263130417 0.3372160875581092\n",
      "epoch: 000400  loss: -0.30007\n",
      "start graph generation\n",
      "finish graph generation\n",
      "5.6000000000000005 2.172222222222222 0.6077117606523617 0.3372091466563732\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>graph-unmasking/gen-loss</td><td>▃▂▁▅█</td></tr><tr><td>graph-unmasking/loss</td><td>█▂▁▁▁</td></tr><tr><td>mean degree</td><td>▅▃▁▆█</td></tr><tr><td>mean degree var</td><td>▁▁█▃▄</td></tr><tr><td>num_parameters</td><td>▁</td></tr><tr><td>stats/cluster</td><td>▃▂█▁▁</td></tr><tr><td>stats/cluster_train</td><td>▁</td></tr><tr><td>stats/degree</td><td>▇▃▁█▇</td></tr><tr><td>stats/degree_train</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>graph-unmasking/gen-loss</td><td>8.93222</td></tr><tr><td>graph-unmasking/loss</td><td>-0.30007</td></tr><tr><td>mean degree</td><td>5.6</td></tr><tr><td>mean degree var</td><td>2.17222</td></tr><tr><td>num_parameters</td><td>32647</td></tr><tr><td>stats/cluster</td><td>0.33721</td></tr><tr><td>stats/cluster_train</td><td>0.00953</td></tr><tr><td>stats/degree</td><td>0.60771</td></tr><tr><td>stats/degree_train</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">glamorous-sweep-1</strong> at: <a href='https://wandb.ai/nextaid/toad_double/runs/qt0uuvcc' target=\"_blank\">https://wandb.ai/nextaid/toad_double/runs/qt0uuvcc</a><br/>Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230531_091052-qt0uuvcc/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: k7f4du9w with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcandidate_selection_radius: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdouble_inference: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgraph_transform: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: bce\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: pna\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnoise_probability: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnormalization: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_post_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_pass: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttowers: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/gerritgrossmann/Documents/devel/MaskedGraphGen/wandb/run-20230531_093818-k7f4du9w</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nextaid/toad_double/runs/k7f4du9w' target=\"_blank\">golden-sweep-2</a></strong> to <a href='https://wandb.ai/nextaid/toad_double' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/nextaid/toad_double/sweeps/j8frw6u2' target=\"_blank\">https://wandb.ai/nextaid/toad_double/sweeps/j8frw6u2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nextaid/toad_double' target=\"_blank\">https://wandb.ai/nextaid/toad_double</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/nextaid/toad_double/sweeps/j8frw6u2' target=\"_blank\">https://wandb.ai/nextaid/toad_double/sweeps/j8frw6u2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nextaid/toad_double/runs/k7f4du9w' target=\"_blank\">https://wandb.ai/nextaid/toad_double/runs/k7f4du9w</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j8frw6u2 {'batch_size': 100, 'candidate_selection_radius': 1, 'double_inference': True, 'dropout': 0, 'graph_transform': False, 'hidden_dim': 16, 'hidden_layer': 5, 'learning_rate': 0.0001, 'loss': 'bce', 'model': 'pna', 'noise_probability': 0, 'normalization': True, 'pre_post_layers': 1, 'single_pass': True, 'towers': 1}\n",
      "Reference distance is:  0.0 0.009534636872396862\n",
      "epoch: 000001  loss: -0.08174\n",
      "start graph generation\n",
      "finish graph generation\n",
      "5.35 1.8972222222222226 0.6076309238344242 0.33750724398481696\n",
      "epoch: 000101  loss: -0.45360\n",
      "start graph generation\n",
      "finish graph generation\n",
      "5.216666666666667 1.8694444444444447 0.5754343672400637 0.33735153552099295\n",
      "epoch: 000201  loss: -0.45896\n",
      "start graph generation\n",
      "finish graph generation\n",
      "5.016666666666667 2.519444444444445 0.553641177676883 0.33825591556312656\n",
      "epoch: 000301  loss: -0.48973\n",
      "start graph generation\n",
      "finish graph generation\n",
      "5.416666666666666 2.063888888888889 0.6185010263130417 0.3372160875581092\n",
      "epoch: 000400  loss: -0.51427\n",
      "start graph generation\n",
      "finish graph generation\n",
      "5.6000000000000005 2.172222222222222 0.6077117606523617 0.3372091466563732\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>graph-unmasking/gen-loss</td><td>▃▂▁▅█</td></tr><tr><td>graph-unmasking/loss</td><td>█▂▂▁▁</td></tr><tr><td>mean degree</td><td>▅▃▁▆█</td></tr><tr><td>mean degree var</td><td>▁▁█▃▄</td></tr><tr><td>num_parameters</td><td>▁</td></tr><tr><td>stats/cluster</td><td>▃▂█▁▁</td></tr><tr><td>stats/cluster_train</td><td>▁</td></tr><tr><td>stats/degree</td><td>▇▃▁█▇</td></tr><tr><td>stats/degree_train</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>graph-unmasking/gen-loss</td><td>8.93222</td></tr><tr><td>graph-unmasking/loss</td><td>-0.51427</td></tr><tr><td>mean degree</td><td>5.6</td></tr><tr><td>mean degree var</td><td>2.17222</td></tr><tr><td>num_parameters</td><td>20743</td></tr><tr><td>stats/cluster</td><td>0.33721</td></tr><tr><td>stats/cluster_train</td><td>0.00953</td></tr><tr><td>stats/degree</td><td>0.60771</td></tr><tr><td>stats/degree_train</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">golden-sweep-2</strong> at: <a href='https://wandb.ai/nextaid/toad_double/runs/k7f4du9w' target=\"_blank\">https://wandb.ai/nextaid/toad_double/runs/k7f4du9w</a><br/>Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230531_093818-k7f4du9w/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: bgqv1nk1 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcandidate_selection_radius: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdouble_inference: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgraph_transform: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: bce\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: pna\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnoise_probability: 0.05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnormalization: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_post_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_pass: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttowers: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/gerritgrossmann/Documents/devel/MaskedGraphGen/wandb/run-20230531_094602-bgqv1nk1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nextaid/toad_double/runs/bgqv1nk1' target=\"_blank\">skilled-sweep-3</a></strong> to <a href='https://wandb.ai/nextaid/toad_double' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/nextaid/toad_double/sweeps/j8frw6u2' target=\"_blank\">https://wandb.ai/nextaid/toad_double/sweeps/j8frw6u2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nextaid/toad_double' target=\"_blank\">https://wandb.ai/nextaid/toad_double</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/nextaid/toad_double/sweeps/j8frw6u2' target=\"_blank\">https://wandb.ai/nextaid/toad_double/sweeps/j8frw6u2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nextaid/toad_double/runs/bgqv1nk1' target=\"_blank\">https://wandb.ai/nextaid/toad_double/runs/bgqv1nk1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j8frw6u2 {'batch_size': 100, 'candidate_selection_radius': 5, 'double_inference': False, 'dropout': 0, 'graph_transform': False, 'hidden_dim': 16, 'hidden_layer': 5, 'learning_rate': 0.0001, 'loss': 'bce', 'model': 'pna', 'noise_probability': 0.05, 'normalization': False, 'pre_post_layers': 1, 'single_pass': True, 'towers': 1}\n",
      "Reference distance is:  0.0 0.009534636872396862\n",
      "epoch: 000001  loss: -0.00178\n",
      "start graph generation\n",
      "finish graph generation\n",
      "0.08333333333333333 0.06944444444444445 0.7800421389997036 0.9963103123950465\n",
      "epoch: 000101  loss: -0.21428\n",
      "start graph generation\n",
      "finish graph generation\n",
      "0.11666666666666667 0.09722222222222222 0.7811455694775593 0.9963103123950467\n",
      "epoch: 000201  loss: -0.20137\n",
      "start graph generation\n",
      "finish graph generation\n",
      "0.1 0.08333333333333334 0.7803179966191676 0.9963103123950467\n",
      "epoch: 000301  loss: -0.28752\n",
      "start graph generation\n",
      "finish graph generation\n",
      "0.05 0.041666666666666664 0.7811455694775593 0.9963103123950467\n",
      "epoch: 000400  loss: -0.28393\n",
      "start graph generation\n",
      "finish graph generation\n",
      "0.09999999999999999 0.08333333333333334 0.7803179966191676 0.9963103123950465\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>graph-unmasking/gen-loss</td><td>▄▁▃█▃</td></tr><tr><td>graph-unmasking/loss</td><td>█▃▃▁▁</td></tr><tr><td>mean degree</td><td>▅█▆▁▆</td></tr><tr><td>mean degree var</td><td>▅█▆▁▆</td></tr><tr><td>num_parameters</td><td>▁</td></tr><tr><td>stats/cluster</td><td>▁▁▁▁▁</td></tr><tr><td>stats/cluster_train</td><td>▁</td></tr><tr><td>stats/degree</td><td>▁█▃█▃</td></tr><tr><td>stats/degree_train</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>graph-unmasking/gen-loss</td><td>8.49333</td></tr><tr><td>graph-unmasking/loss</td><td>-0.28393</td></tr><tr><td>mean degree</td><td>0.1</td></tr><tr><td>mean degree var</td><td>0.08333</td></tr><tr><td>num_parameters</td><td>20573</td></tr><tr><td>stats/cluster</td><td>0.99631</td></tr><tr><td>stats/cluster_train</td><td>0.00953</td></tr><tr><td>stats/degree</td><td>0.78032</td></tr><tr><td>stats/degree_train</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">skilled-sweep-3</strong> at: <a href='https://wandb.ai/nextaid/toad_double/runs/bgqv1nk1' target=\"_blank\">https://wandb.ai/nextaid/toad_double/runs/bgqv1nk1</a><br/>Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230531_094602-bgqv1nk1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ghn3ypb4 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcandidate_selection_radius: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdouble_inference: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgraph_transform: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: bce\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: pna\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnoise_probability: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnormalization: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_post_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_pass: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttowers: 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/gerritgrossmann/Documents/devel/MaskedGraphGen/wandb/run-20230531_095324-ghn3ypb4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nextaid/toad_double/runs/ghn3ypb4' target=\"_blank\">comfy-sweep-4</a></strong> to <a href='https://wandb.ai/nextaid/toad_double' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/nextaid/toad_double/sweeps/j8frw6u2' target=\"_blank\">https://wandb.ai/nextaid/toad_double/sweeps/j8frw6u2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nextaid/toad_double' target=\"_blank\">https://wandb.ai/nextaid/toad_double</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/nextaid/toad_double/sweeps/j8frw6u2' target=\"_blank\">https://wandb.ai/nextaid/toad_double/sweeps/j8frw6u2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nextaid/toad_double/runs/ghn3ypb4' target=\"_blank\">https://wandb.ai/nextaid/toad_double/runs/ghn3ypb4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j8frw6u2 {'batch_size': 100, 'candidate_selection_radius': 5, 'double_inference': True, 'dropout': 0, 'graph_transform': False, 'hidden_dim': 16, 'hidden_layer': 4, 'learning_rate': 1e-05, 'loss': 'bce', 'model': 'pna', 'noise_probability': 0, 'normalization': False, 'pre_post_layers': 1, 'single_pass': True, 'towers': 2}\n",
      "Reference distance is:  0.0 0.009534636872396862\n",
      "epoch: 000001  loss: 0.02758\n",
      "start graph generation\n",
      "finish graph generation\n",
      "0.08333333333333333 0.06944444444444445 0.7800421389997036 0.9963103123950469\n",
      "epoch: 000101  loss: -0.20725\n",
      "start graph generation\n",
      "finish graph generation\n",
      "0.13333333333333333 0.11111111111111112 0.7825248575748791 0.9963103123950467\n",
      "epoch: 000201  loss: -0.19713\n",
      "start graph generation\n",
      "finish graph generation\n",
      "0.06666666666666667 0.055555555555555546 0.7803179966191676 0.9963103123950465\n",
      "epoch: 000301  loss: -0.22760\n",
      "start graph generation\n",
      "finish graph generation\n",
      "0.08333333333333333 0.06944444444444443 0.7800421389997036 0.9963103123950465\n",
      "epoch: 000400  loss: -0.22481\n",
      "start graph generation\n",
      "finish graph generation\n",
      "0.09999999999999999 0.08333333333333333 0.7803179966191676 0.9963103123950465\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>graph-unmasking/gen-loss</td><td>▆▁█▆▄</td></tr><tr><td>graph-unmasking/loss</td><td>█▂▂▁▁</td></tr><tr><td>mean degree</td><td>▃█▁▃▄</td></tr><tr><td>mean degree var</td><td>▃█▁▃▅</td></tr><tr><td>num_parameters</td><td>▁</td></tr><tr><td>stats/cluster</td><td>▁▁▁▁▁</td></tr><tr><td>stats/cluster_train</td><td>▁</td></tr><tr><td>stats/degree</td><td>▁█▂▁▂</td></tr><tr><td>stats/degree_train</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>graph-unmasking/gen-loss</td><td>8.49333</td></tr><tr><td>graph-unmasking/loss</td><td>-0.22481</td></tr><tr><td>mean degree</td><td>0.1</td></tr><tr><td>mean degree var</td><td>0.08333</td></tr><tr><td>num_parameters</td><td>19783</td></tr><tr><td>stats/cluster</td><td>0.99631</td></tr><tr><td>stats/cluster_train</td><td>0.00953</td></tr><tr><td>stats/degree</td><td>0.78032</td></tr><tr><td>stats/degree_train</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">comfy-sweep-4</strong> at: <a href='https://wandb.ai/nextaid/toad_double/runs/ghn3ypb4' target=\"_blank\">https://wandb.ai/nextaid/toad_double/runs/ghn3ypb4</a><br/>Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230531_095324-ghn3ypb4/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: rq3ksc9g with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcandidate_selection_radius: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdouble_inference: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgraph_transform: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: bce\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: pna\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnoise_probability: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnormalization: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_post_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_pass: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttowers: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/gerritgrossmann/Documents/devel/MaskedGraphGen/wandb/run-20230531_100446-rq3ksc9g</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nextaid/toad_double/runs/rq3ksc9g' target=\"_blank\">winter-sweep-5</a></strong> to <a href='https://wandb.ai/nextaid/toad_double' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/nextaid/toad_double/sweeps/j8frw6u2' target=\"_blank\">https://wandb.ai/nextaid/toad_double/sweeps/j8frw6u2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nextaid/toad_double' target=\"_blank\">https://wandb.ai/nextaid/toad_double</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/nextaid/toad_double/sweeps/j8frw6u2' target=\"_blank\">https://wandb.ai/nextaid/toad_double/sweeps/j8frw6u2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nextaid/toad_double/runs/rq3ksc9g' target=\"_blank\">https://wandb.ai/nextaid/toad_double/runs/rq3ksc9g</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j8frw6u2 {'batch_size': 100, 'candidate_selection_radius': 5, 'double_inference': False, 'dropout': 0, 'graph_transform': False, 'hidden_dim': 32, 'hidden_layer': 5, 'learning_rate': 0.0001, 'loss': 'bce', 'model': 'pna', 'noise_probability': 0.1, 'normalization': False, 'pre_post_layers': 1, 'single_pass': True, 'towers': 1}\n",
      "Reference distance is:  0.0 0.009534636872396862\n",
      "epoch: 000001  loss: -0.01477\n",
      "start graph generation\n",
      "finish graph generation\n",
      "0.08333333333333333 0.06944444444444445 0.7800421389997036 0.9963103123950465\n",
      "epoch: 000101  loss: -0.19551\n",
      "start graph generation\n",
      "finish graph generation\n",
      "0.11666666666666667 0.09722222222222222 0.7811455694775593 0.9963103123950467\n",
      "epoch: 000201  loss: -0.19213\n",
      "start graph generation\n",
      "finish graph generation\n",
      "0.1 0.08333333333333334 0.7803179966191676 0.9963103123950467\n",
      "epoch: 000301  loss: -0.15189\n",
      "start graph generation\n",
      "finish graph generation\n",
      "0.05 0.041666666666666664 0.7811455694775593 0.9963103123950467\n",
      "epoch: 000400  loss: -0.25132\n",
      "start graph generation\n",
      "finish graph generation\n",
      "0.09999999999999999 0.08333333333333334 0.7803179966191676 0.9963103123950465\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>graph-unmasking/gen-loss</td><td>▄▁▃█▃</td></tr><tr><td>graph-unmasking/loss</td><td>█▃▃▄▁</td></tr><tr><td>mean degree</td><td>▅█▆▁▆</td></tr><tr><td>mean degree var</td><td>▅█▆▁▆</td></tr><tr><td>num_parameters</td><td>▁</td></tr><tr><td>stats/cluster</td><td>▁▁▁▁▁</td></tr><tr><td>stats/cluster_train</td><td>▁</td></tr><tr><td>stats/degree</td><td>▁█▃█▃</td></tr><tr><td>stats/degree_train</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>graph-unmasking/gen-loss</td><td>8.49333</td></tr><tr><td>graph-unmasking/loss</td><td>-0.25132</td></tr><tr><td>mean degree</td><td>0.1</td></tr><tr><td>mean degree var</td><td>0.08333</td></tr><tr><td>num_parameters</td><td>75277</td></tr><tr><td>stats/cluster</td><td>0.99631</td></tr><tr><td>stats/cluster_train</td><td>0.00953</td></tr><tr><td>stats/degree</td><td>0.78032</td></tr><tr><td>stats/degree_train</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">winter-sweep-5</strong> at: <a href='https://wandb.ai/nextaid/toad_double/runs/rq3ksc9g' target=\"_blank\">https://wandb.ai/nextaid/toad_double/runs/rq3ksc9g</a><br/>Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230531_100446-rq3ksc9g/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: u4lb2za2 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcandidate_selection_radius: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdouble_inference: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgraph_transform: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: bce\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: pna\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnoise_probability: 0.05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnormalization: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_post_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_pass: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttowers: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/gerritgrossmann/Documents/devel/MaskedGraphGen/wandb/run-20230531_101434-u4lb2za2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nextaid/toad_double/runs/u4lb2za2' target=\"_blank\">icy-sweep-6</a></strong> to <a href='https://wandb.ai/nextaid/toad_double' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/nextaid/toad_double/sweeps/j8frw6u2' target=\"_blank\">https://wandb.ai/nextaid/toad_double/sweeps/j8frw6u2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nextaid/toad_double' target=\"_blank\">https://wandb.ai/nextaid/toad_double</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/nextaid/toad_double/sweeps/j8frw6u2' target=\"_blank\">https://wandb.ai/nextaid/toad_double/sweeps/j8frw6u2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nextaid/toad_double/runs/u4lb2za2' target=\"_blank\">https://wandb.ai/nextaid/toad_double/runs/u4lb2za2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j8frw6u2 {'batch_size': 100, 'candidate_selection_radius': 5, 'double_inference': False, 'dropout': 0, 'graph_transform': True, 'hidden_dim': 64, 'hidden_layer': 4, 'learning_rate': 0.0001, 'loss': 'bce', 'model': 'pna', 'noise_probability': 0.05, 'normalization': False, 'pre_post_layers': 1, 'single_pass': True, 'towers': 1}\n",
      "Reference distance is:  0.0 0.009534636872396862\n",
      "epoch: 000001  loss: -0.04920\n",
      "start graph generation\n",
      "finish graph generation\n",
      "0.08333333333333333 0.06944444444444445 0.7800421389997036 0.9963103123950465\n",
      "epoch: 000101  loss: -0.21018\n",
      "start graph generation\n",
      "finish graph generation\n",
      "0.11666666666666667 0.09722222222222222 0.7811455694775593 0.9963103123950467\n",
      "epoch: 000201  loss: -0.37421\n",
      "start graph generation\n",
      "finish graph generation\n",
      "0.1 0.08333333333333334 0.7803179966191676 0.9963103123950467\n",
      "epoch: 000301  loss: -0.33981\n",
      "start graph generation\n",
      "finish graph generation\n",
      "0.05 0.041666666666666664 0.7811455694775593 0.9963103123950467\n",
      "epoch: 000400  loss: -0.37413\n",
      "start graph generation\n",
      "finish graph generation\n",
      "0.09999999999999999 0.08333333333333334 0.7803179966191676 0.9963103123950465\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>graph-unmasking/gen-loss</td><td>▄▁▃█▃</td></tr><tr><td>graph-unmasking/loss</td><td>█▅▁▂▁</td></tr><tr><td>mean degree</td><td>▅█▆▁▆</td></tr><tr><td>mean degree var</td><td>▅█▆▁▆</td></tr><tr><td>num_parameters</td><td>▁</td></tr><tr><td>stats/cluster</td><td>▁▁▁▁▁</td></tr><tr><td>stats/cluster_train</td><td>▁</td></tr><tr><td>stats/degree</td><td>▁█▃█▃</td></tr><tr><td>stats/degree_train</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>graph-unmasking/gen-loss</td><td>8.49333</td></tr><tr><td>graph-unmasking/loss</td><td>-0.37413</td></tr><tr><td>mean degree</td><td>0.1</td></tr><tr><td>mean degree var</td><td>0.08333</td></tr><tr><td>num_parameters</td><td>222406</td></tr><tr><td>stats/cluster</td><td>0.99631</td></tr><tr><td>stats/cluster_train</td><td>0.00953</td></tr><tr><td>stats/degree</td><td>0.78032</td></tr><tr><td>stats/degree_train</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">icy-sweep-6</strong> at: <a href='https://wandb.ai/nextaid/toad_double/runs/u4lb2za2' target=\"_blank\">https://wandb.ai/nextaid/toad_double/runs/u4lb2za2</a><br/>Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230531_101434-u4lb2za2/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 7ac5v5ea with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcandidate_selection_radius: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdouble_inference: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgraph_transform: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: bce\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: pna\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnoise_probability: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnormalization: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_post_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_pass: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttowers: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/gerritgrossmann/Documents/devel/MaskedGraphGen/wandb/run-20230531_103958-7ac5v5ea</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nextaid/toad_double/runs/7ac5v5ea' target=\"_blank\">fresh-sweep-7</a></strong> to <a href='https://wandb.ai/nextaid/toad_double' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/nextaid/toad_double/sweeps/j8frw6u2' target=\"_blank\">https://wandb.ai/nextaid/toad_double/sweeps/j8frw6u2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nextaid/toad_double' target=\"_blank\">https://wandb.ai/nextaid/toad_double</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/nextaid/toad_double/sweeps/j8frw6u2' target=\"_blank\">https://wandb.ai/nextaid/toad_double/sweeps/j8frw6u2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nextaid/toad_double/runs/7ac5v5ea' target=\"_blank\">https://wandb.ai/nextaid/toad_double/runs/7ac5v5ea</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j8frw6u2 {'batch_size': 100, 'candidate_selection_radius': 1, 'double_inference': False, 'dropout': 0, 'graph_transform': True, 'hidden_dim': 32, 'hidden_layer': 5, 'learning_rate': 0.0001, 'loss': 'bce', 'model': 'pna', 'noise_probability': 0, 'normalization': False, 'pre_post_layers': 1, 'single_pass': True, 'towers': 1}\n",
      "Reference distance is:  0.0 0.009534636872396862\n",
      "epoch: 000001  loss: 0.01579\n",
      "start graph generation\n",
      "finish graph generation\n",
      "5.35 2.1583333333333337 0.6109787658526273 0.3372121670230859\n",
      "epoch: 000101  loss: -0.17366\n",
      "start graph generation\n",
      "finish graph generation\n",
      "5.5 2.6166666666666667 0.6097433424454759 0.3372542798652401\n",
      "epoch: 000201  loss: -0.32926\n",
      "start graph generation\n",
      "finish graph generation\n",
      "5.499999999999999 2.066666666666667 0.629317941905372 0.3372799002820076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "os.environ[\"WANDB_MODE\"] = WANDB_MODE \n",
    "\n",
    "SWEEP_ID = wandb.sweep(sweep_config, project=PROJECT_NAME)\n",
    "wandb.agent(SWEEP_ID, project=PROJECT_NAME, function=start_agent_envelope, count=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "DHcAvy-w6Zlu"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sdfljldf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m jljkl \u001b[38;5;241m=\u001b[39m \u001b[43msdfljldf\u001b[49m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sdfljldf' is not defined"
     ]
    }
   ],
   "source": [
    "jljkl = sdfljldf/0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tg-wy3DnJRA9"
   },
   "source": [
    "# Load graph datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NWlIj_iUJUtp"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.system(\"git clone https://github.com/KarolisMart/SPECTRE.git\")\n",
    "\n",
    "\n",
    "from argparse import ArgumentParser\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "#import pytorch_lightning as pl\n",
    "import networkx as nx\n",
    "from torch.utils.data import random_split, DataLoader, Dataset\n",
    "from scipy.spatial import Delaunay\n",
    "#from torch_geometric.datasets import QM9\n",
    "#from rdkit import Chem\n",
    "#from torch_geometric.utils import dense_to_sparse, to_dense_adj, to_networkx\n",
    "\n",
    "#from util.eval_helper import degree_stats, orbit_stats_all, clustering_stats, spectral_stats, eigval_stats, compute_list_eigh, spectral_filter_stats\n",
    "#from util.molecular_eval import BasicMolecularMetrics\n",
    "\n",
    "\n",
    "class SpectreGraphDataset(Dataset):\n",
    "    def __init__(self, data_file):\n",
    "        \"\"\" This class can be used to load the comm20, sbm and planar datasets. \"\"\"\n",
    "        base_path = 'SPECTRE/data/'\n",
    "        filename = os.path.join(base_path, data_file)\n",
    "        self.adjs, self.eigvals, self.eigvecs, self.n_nodes, self.max_eigval, self.min_eigval, self.same_sample, self.n_max = torch.load(\n",
    "            filename)\n",
    "        print(f'Dataset {filename} loaded from file')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.adjs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        adj = self.adjs[idx]\n",
    "        n = adj.shape[-1]\n",
    "        X = torch.ones(n, 1, dtype=torch.float)\n",
    "        y = torch.zeros([1, 0]).float()\n",
    "        edge_index, _ = torch_geometric.utils.dense_to_sparse(adj)\n",
    "        edge_attr = torch.zeros(edge_index.shape[-1], 2, dtype=torch.float)\n",
    "        edge_attr[:, 1] = 1\n",
    "        num_nodes = n * torch.ones(1, dtype=torch.long)\n",
    "        data = torch_geometric.data.Data(x=X, edge_index=edge_index, edge_attr=edge_attr,\n",
    "                                         y=y, idx=idx, n_nodes=num_nodes)\n",
    "        return data\n",
    "\n",
    "\n",
    "class PlanarDataset(SpectreGraphDataset):\n",
    "    def __init__(self):\n",
    "        super().__init__('planar_64_200.pt')\n",
    "\n",
    "\n",
    "PlanarDataset()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t9QJ8aL44va_"
   },
   "outputs": [],
   "source": [
    "\n",
    "adjs, eigvals, eigvecs, n_nodes, max_eigval, min_eigval, same_sample, n_max = torch.load('SPECTRE/data/planar_64_200.pt')\n",
    "adjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_rZedjy0wJxy"
   },
   "outputs": [],
   "source": [
    "graphs = adjs\n",
    "test_len = int(round(len(graphs) * 0.2))\n",
    "train_len = int(round((len(graphs) - test_len) * 0.8))\n",
    "val_len = len(graphs) - train_len - test_len\n",
    "print(f'Dataset sizes: train {train_len}, val {val_len}, test {test_len}')\n",
    "splits = random_split(graphs, [train_len, val_len, test_len], generator=torch.Generator().manual_seed(1234))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AK2hS79yrqST"
   },
   "source": [
    "### next try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D_GqY9tyuKpA"
   },
   "outputs": [],
   "source": [
    "os.system(\"pip install omegaconf\")\n",
    "os.system(\"pip install pytorch_lightning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jJJ8ICD9vgCQ"
   },
   "outputs": [],
   "source": [
    "os.system(\"pip install overrides\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XGc8eQCbrrd0"
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "os.system(\"git clone https://github.com/cvignac/DiGress.git\")\n",
    "os.system(\"cp -r DiGress/src src/\")\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import random_split, Dataset\n",
    "import torch_geometric.utils\n",
    "\n",
    "from src.datasets.abstract_dataset import AbstractDataModule, AbstractDatasetInfos\n",
    "\n",
    "\n",
    "class SpectreGraphDataset(Dataset):\n",
    "    def __init__(self, data_file):\n",
    "        \"\"\" This class can be used to load the comm20, sbm and planar datasets. \"\"\"\n",
    "        base_path = os.path.join(os.path.dirname(os.path.realpath(__file__)), os.pardir, os.pardir, 'data')\n",
    "        filename = os.path.join(base_path, data_file)\n",
    "        self.adjs, self.eigvals, self.eigvecs, self.n_nodes, self.max_eigval, self.min_eigval, self.same_sample, self.n_max = torch.load(\n",
    "            filename)\n",
    "        print(f'Dataset {filename} loaded from file')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.adjs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        adj = self.adjs[idx]\n",
    "        n = adj.shape[-1]\n",
    "        X = torch.ones(n, 1, dtype=torch.float)\n",
    "        y = torch.zeros([1, 0]).float()\n",
    "        edge_index, _ = torch_geometric.utils.dense_to_sparse(adj)\n",
    "        edge_attr = torch.zeros(edge_index.shape[-1], 2, dtype=torch.float)\n",
    "        edge_attr[:, 1] = 1\n",
    "        num_nodes = n * torch.ones(1, dtype=torch.long)\n",
    "        data = torch_geometric.data.Data(x=X, edge_index=edge_index, edge_attr=edge_attr,\n",
    "                                         y=y, idx=idx, n_nodes=num_nodes)\n",
    "        return data\n",
    "\n",
    "class SpectreGraphDataModule(AbstractDataModule):\n",
    "    def __init__(self, cfg, n_graphs=200):\n",
    "        super().__init__(cfg)\n",
    "        self.n_graphs = n_graphs\n",
    "        self.prepare_data()\n",
    "        self.inner = self.train_dataloader()\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.inner[item]\n",
    "\n",
    "    def prepare_data(self, graphs):\n",
    "        test_len = int(round(len(graphs) * 0.2))\n",
    "        train_len = int(round((len(graphs) - test_len) * 0.8))\n",
    "        val_len = len(graphs) - train_len - test_len\n",
    "        print(f'Dataset sizes: train {train_len}, val {val_len}, test {test_len}')\n",
    "        splits = random_split(graphs, [train_len, val_len, test_len], generator=torch.Generator().manual_seed(1234))\n",
    "\n",
    "        datasets = {'train': splits[0], 'val': splits[1], 'test': splits[2]}\n",
    "        super().prepare_data(datasets)\n",
    "\n",
    "class Comm20Dataset(SpectreGraphDataset):\n",
    "    def __init__(self):\n",
    "        super().__init__('community_12_21_100.pt')\n",
    "\n",
    "\n",
    "class SBMDataset(SpectreGraphDataset):\n",
    "    def __init__(self):\n",
    "        super().__init__('sbm_200.pt')\n",
    "\n",
    "\n",
    "class PlanarDataset(SpectreGraphDataset):\n",
    "    def __init__(self):\n",
    "        super().__init__('planar_64_200.pt')\n",
    "\n",
    "dataset = PlanarDataset()\n",
    "dataset.prepare_data\n",
    "dataset.datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JbPFtDS8x810"
   },
   "source": [
    "# Quality Measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9oSqDFX4x_7C"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pCDeFcFFyVRQ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.system(\"pip install pyemd\")\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9s_ZCqiiyVfj"
   },
   "outputs": [],
   "source": [
    "import pyemd\n",
    "import numpy as np\n",
    "import concurrent.futures\n",
    "from functools import partial\n",
    "from scipy.linalg import toeplitz\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "PRINT_TIME = False\n",
    "\n",
    "def degree_worker(G):\n",
    "    return np.array(nx.degree_histogram(G))\n",
    "\n",
    "def degree_stats(graph_ref_list, graph_pred_list, is_parallel=True, compute_emd=False):\n",
    "    ''' Compute the distance between the degree distributions of two unordered sets of graphs.\n",
    "        Args:\n",
    "            graph_ref_list, graph_target_list: two lists of networkx graphs to be evaluated\n",
    "        '''\n",
    "    sample_ref = []\n",
    "    sample_pred = []\n",
    "    # in case an empty graph is generated\n",
    "    graph_pred_list_remove_empty = [\n",
    "        G for G in graph_pred_list if not G.number_of_nodes() == 0\n",
    "    ]\n",
    "\n",
    "    prev = datetime.now()\n",
    "    if is_parallel:\n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            for deg_hist in executor.map(degree_worker, graph_ref_list):\n",
    "                sample_ref.append(deg_hist)\n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            for deg_hist in executor.map(degree_worker, graph_pred_list_remove_empty):\n",
    "                sample_pred.append(deg_hist)\n",
    "    else:\n",
    "        for i in range(len(graph_ref_list)):\n",
    "            degree_temp = np.array(nx.degree_histogram(graph_ref_list[i]))\n",
    "            sample_ref.append(degree_temp)\n",
    "        for i in range(len(graph_pred_list_remove_empty)):\n",
    "            degree_temp = np.array(\n",
    "                nx.degree_histogram(graph_pred_list_remove_empty[i]))\n",
    "            sample_pred.append(degree_temp)\n",
    "\n",
    "    # mmd_dist = compute_mmd(sample_ref, sample_pred, kernel=gaussian_emd)\n",
    "    # mmd_dist = compute_mmd(sample_ref, sample_pred, kernel=emd)\n",
    "    if compute_emd:\n",
    "        # EMD option uses the same computation as GraphRNN, the alternative is MMD as computed by GRAN\n",
    "        # mmd_dist = compute_mmd(sample_ref, sample_pred, kernel=emd)\n",
    "        mmd_dist = compute_mmd(sample_ref, sample_pred, kernel=gaussian_emd)\n",
    "    else:\n",
    "        mmd_dist = compute_mmd(sample_ref, sample_pred, kernel=gaussian_tv)\n",
    "    # mmd_dist = compute_mmd(sample_ref, sample_pred, kernel=gaussian)\n",
    "\n",
    "    elapsed = datetime.now() - prev\n",
    "    if PRINT_TIME:\n",
    "        print('Time computing degree mmd: ', elapsed)\n",
    "    return mmd_dist\n",
    "\n",
    "\n",
    "\n",
    "def clustering_worker(param):\n",
    "    G, bins = param\n",
    "    clustering_coeffs_list = list(nx.clustering(G).values())\n",
    "    hist, _ = np.histogram(\n",
    "        clustering_coeffs_list, bins=bins, range=(0.0, 1.0), density=False)\n",
    "    return hist\n",
    "\n",
    "\n",
    "def clustering_stats(graph_ref_list,\n",
    "                     graph_pred_list,\n",
    "                     bins=100,\n",
    "                     is_parallel=True, compute_emd=False):\n",
    "    sample_ref = []\n",
    "    sample_pred = []\n",
    "    graph_pred_list_remove_empty = [\n",
    "        G for G in graph_pred_list if not G.number_of_nodes() == 0\n",
    "    ]\n",
    "\n",
    "    prev = datetime.now()\n",
    "    if is_parallel:\n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            for clustering_hist in executor.map(clustering_worker,\n",
    "                                                [(G, bins) for G in graph_ref_list]):\n",
    "                sample_ref.append(clustering_hist)\n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            for clustering_hist in executor.map(\n",
    "                    clustering_worker, [(G, bins) for G in graph_pred_list_remove_empty]):\n",
    "                sample_pred.append(clustering_hist)\n",
    "\n",
    "        # check non-zero elements in hist\n",
    "        # total = 0\n",
    "        # for i in range(len(sample_pred)):\n",
    "        #    nz = np.nonzero(sample_pred[i])[0].shape[0]\n",
    "        #    total += nz\n",
    "        # print(total)\n",
    "    else:\n",
    "        for i in range(len(graph_ref_list)):\n",
    "            clustering_coeffs_list = list(nx.clustering(graph_ref_list[i]).values())\n",
    "            hist, _ = np.histogram(\n",
    "                clustering_coeffs_list, bins=bins, range=(0.0, 1.0), density=False)\n",
    "            sample_ref.append(hist)\n",
    "\n",
    "        for i in range(len(graph_pred_list_remove_empty)):\n",
    "            clustering_coeffs_list = list(\n",
    "                nx.clustering(graph_pred_list_remove_empty[i]).values())\n",
    "            hist, _ = np.histogram(\n",
    "                clustering_coeffs_list, bins=bins, range=(0.0, 1.0), density=False)\n",
    "            sample_pred.append(hist)\n",
    "\n",
    "    if compute_emd:\n",
    "        # EMD option uses the same computation as GraphRNN, the alternative is MMD as computed by GRAN\n",
    "        # mmd_dist = compute_mmd(sample_ref, sample_pred, kernel=emd, sigma=1.0 / 10)\n",
    "        mmd_dist = compute_mmd(sample_ref, sample_pred, kernel=gaussian_emd, sigma=1.0 / 10, distance_scaling=bins)\n",
    "    else:\n",
    "        mmd_dist = compute_mmd(sample_ref, sample_pred, kernel=gaussian_tv, sigma=1.0 / 10)\n",
    "\n",
    "    elapsed = datetime.now() - prev\n",
    "    if PRINT_TIME:\n",
    "        print('Time computing clustering mmd: ', elapsed)\n",
    "    return mmd_dist\n",
    "\n",
    "\n",
    "\n",
    "# maps motif/orbit name string to its corresponding list of indices from orca output\n",
    "motif_to_indices = {\n",
    "    '3path': [1, 2],\n",
    "    '4cycle': [8],\n",
    "}\n",
    "COUNT_START_STR = 'orbit counts:'\n",
    "\n",
    "\n",
    "def edge_list_reindexed(G):\n",
    "    idx = 0\n",
    "    id2idx = dict()\n",
    "    for u in G.nodes():\n",
    "        id2idx[str(u)] = idx\n",
    "        idx += 1\n",
    "\n",
    "    edges = []\n",
    "    for (u, v) in G.edges():\n",
    "        edges.append((id2idx[str(u)], id2idx[str(v)]))\n",
    "    return edges\n",
    "\n",
    "def orca(graph):\n",
    "    # tmp_fname = f'analysis/orca/tmp_{\"\".join(secrets.choice(ascii_uppercase + digits) for i in range(8))}.txt'\n",
    "    tmp_fname = f'orca/tmp_{\"\".join(secrets.choice(ascii_uppercase + digits) for i in range(8))}.txt'\n",
    "    tmp_fname = os.path.join(os.path.dirname(os.path.realpath(__file__)), tmp_fname)\n",
    "    # print(tmp_fname, flush=True)\n",
    "    f = open(tmp_fname, 'w')\n",
    "    f.write(\n",
    "        str(graph.number_of_nodes()) + ' ' + str(graph.number_of_edges()) + '\\n')\n",
    "    for (u, v) in edge_list_reindexed(graph):\n",
    "        f.write(str(u) + ' ' + str(v) + '\\n')\n",
    "    f.close()\n",
    "    output = sp.check_output(\n",
    "        [str(os.path.join(os.path.dirname(os.path.realpath(__file__)), 'orca/orca')), 'node', '4', tmp_fname, 'std'])\n",
    "    output = output.decode('utf8').strip()\n",
    "    idx = output.find(COUNT_START_STR) + len(COUNT_START_STR) + 2\n",
    "    output = output[idx:]\n",
    "    node_orbit_counts = np.array([\n",
    "        list(map(int,\n",
    "                 node_cnts.strip().split(' ')))\n",
    "        for node_cnts in output.strip('\\n').split('\\n')\n",
    "    ])\n",
    "\n",
    "    try:\n",
    "        os.remove(tmp_fname)\n",
    "    except OSError:\n",
    "        pass\n",
    "\n",
    "    return node_orbit_counts\n",
    "\n",
    "\n",
    "def orbit_stats_all(graph_ref_list, graph_pred_list, compute_emd=False):\n",
    "    total_counts_ref = []\n",
    "    total_counts_pred = []\n",
    "\n",
    "    graph_pred_list_remove_empty = [\n",
    "        G for G in graph_pred_list if not G.number_of_nodes() == 0\n",
    "    ]\n",
    "\n",
    "    for G in graph_ref_list:\n",
    "        orbit_counts = orca(G)\n",
    "        orbit_counts_graph = np.sum(orbit_counts, axis=0) / G.number_of_nodes()\n",
    "        total_counts_ref.append(orbit_counts_graph)\n",
    "\n",
    "    for G in graph_pred_list:\n",
    "        orbit_counts = orca(G)\n",
    "        orbit_counts_graph = np.sum(orbit_counts, axis=0) / G.number_of_nodes()\n",
    "        total_counts_pred.append(orbit_counts_graph)\n",
    "\n",
    "    total_counts_ref = np.array(total_counts_ref)\n",
    "    total_counts_pred = np.array(total_counts_pred)\n",
    "\n",
    "    # mmd_dist = compute_mmd(\n",
    "    #     total_counts_ref,\n",
    "    #     total_counts_pred,\n",
    "    #     kernel=gaussian,\n",
    "    #     is_hist=False,\n",
    "    #     sigma=30.0)\n",
    "\n",
    "    # mmd_dist = compute_mmd(\n",
    "    #         total_counts_ref,\n",
    "    #         total_counts_pred,\n",
    "    #         kernel=gaussian_tv,\n",
    "    #         is_hist=False,\n",
    "    #         sigma=30.0)  \n",
    "\n",
    "    if compute_emd:\n",
    "        # mmd_dist = compute_mmd(total_counts_ref, total_counts_pred, kernel=emd, sigma=30.0)\n",
    "        # EMD option uses the same computation as GraphRNN, the alternative is MMD as computed by GRAN\n",
    "        mmd_dist = compute_mmd(total_counts_ref, total_counts_pred, kernel=gaussian, is_hist=False, sigma=30.0)\n",
    "    else:\n",
    "        mmd_dist = compute_mmd(total_counts_ref, total_counts_pred, kernel=gaussian_tv, is_hist=False, sigma=30.0)\n",
    "    return mmd_dist\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def gaussian(x, y, sigma=1.0):\n",
    "    support_size = max(len(x), len(y))\n",
    "    # convert histogram values x and y to float, and make them equal len\n",
    "    x = x.astype(float)\n",
    "    y = y.astype(float)\n",
    "    if len(x) < len(y):\n",
    "        x = np.hstack((x, [0.0] * (support_size - len(x))))\n",
    "    elif len(y) < len(x):\n",
    "        y = np.hstack((y, [0.0] * (support_size - len(y))))\n",
    "\n",
    "    dist = np.linalg.norm(x - y, 2)\n",
    "    return np.exp(-dist * dist / (2 * sigma * sigma))\n",
    "\n",
    "\n",
    "def gaussian_tv(x, y, sigma=1.0):  \n",
    "    support_size = max(len(x), len(y))\n",
    "    # convert histogram values x and y to float, and make them equal len\n",
    "    x = x.astype(float)\n",
    "    y = y.astype(float)\n",
    "    if len(x) < len(y):\n",
    "        x = np.hstack((x, [0.0] * (support_size - len(x))))\n",
    "    elif len(y) < len(x):\n",
    "        y = np.hstack((y, [0.0] * (support_size - len(y))))\n",
    "\n",
    "    dist = np.abs(x - y).sum() / 2.0\n",
    "    return np.exp(-dist * dist / (2 * sigma * sigma))\n",
    "\n",
    "\n",
    "def kernel_parallel_unpacked(x, samples2, kernel):\n",
    "    d = 0\n",
    "    for s2 in samples2:\n",
    "        d += kernel(x, s2)\n",
    "    return d\n",
    "\n",
    "\n",
    "def kernel_parallel_worker(t):\n",
    "    return kernel_parallel_unpacked(*t)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def disc(samples1, samples2, kernel, is_parallel=True, *args, **kwargs):\n",
    "    ''' Discrepancy between 2 samples '''\n",
    "    d = 0\n",
    "\n",
    "    if not is_parallel:\n",
    "        for s1 in samples1:\n",
    "            for s2 in samples2:\n",
    "                d += kernel(s1, s2, *args, **kwargs)\n",
    "    else:\n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            for dist in executor.map(kernel_parallel_worker, [\n",
    "                    (s1, samples2, partial(kernel, *args, **kwargs)) for s1 in samples1\n",
    "            ]):\n",
    "                d += dist\n",
    "    if len(samples1) * len(samples2) > 0:\n",
    "        d /= len(samples1) * len(samples2)\n",
    "    else:\n",
    "        d = 1e+6\n",
    "    #print('error')\n",
    "    return d\n",
    "\n",
    "\n",
    "def compute_mmd(samples1, samples2, kernel, is_hist=True, *args, **kwargs):\n",
    "    ''' MMD between two samples '''\n",
    "    # normalize histograms into pmf\n",
    "    if is_hist:\n",
    "        samples1 = [s1 / (np.sum(s1) + 1e-6) for s1 in samples1]\n",
    "        samples2 = [s2 / (np.sum(s2) + 1e-6) for s2 in samples2]\n",
    "    print(samples1)\n",
    "    return disc(samples1, samples1, kernel, *args, **kwargs) + disc(samples2, samples2, kernel, *args, **kwargs) - \\\n",
    "                2 * disc(samples1, samples2, kernel, *args, **kwargs)\n",
    "\n",
    "\n",
    "def compute_emd(samples1, samples2, kernel, is_hist=True, *args, **kwargs):\n",
    "    ''' EMD between average of two samples '''\n",
    "    # normalize histograms into pmf\n",
    "    if is_hist:\n",
    "        samples1 = [np.mean(samples1)]\n",
    "        samples2 = [np.mean(samples2)]\n",
    "    return disc(samples1, samples2, kernel, *args,\n",
    "                            **kwargs), [samples1[0], samples2[0]]\n",
    "\n",
    "\n",
    "\n",
    "def compute_mmd_stats(graphs_ref_nx, graphs_pred_nx):\n",
    "    return degree_stats(graphs_ref_nx, graphs_pred_nx), clustering_stats(graphs_ref_nx, graphs_pred_nx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pscy53ZLz9Se"
   },
   "outputs": [],
   "source": [
    "samples1 = [np.array([1,2,3.0]),  np.array([1,20,4.0])]\n",
    "samples2 = [np.array([1,2,3.5]),  np.array([1,20,4.5])]\n",
    "\n",
    "compute_mmd(samples1, samples2, kernel=gaussian_tv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LTAYm3qa2rr_"
   },
   "outputs": [],
   "source": [
    "samples1 = [np.array([1,200,3.0]),  np.array([1,20,4.0])]\n",
    "samples2 = [np.array([1,2,3.01]),  np.array([1,20,4.01])]\n",
    "\n",
    "compute_mmd(samples1, samples2, kernel=gaussian_tv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zpfa0Ldw0Pkm"
   },
   "outputs": [],
   "source": [
    "graph_ref_list = [nx.erdos_renyi_graph(15, 0.5) for _ in range(15) ]\n",
    "graph_pred_list = [nx.erdos_renyi_graph(15, 0.5) for _ in range(15) ]\n",
    "\n",
    "degree_stats(graph_ref_list, graph_pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DVv3mnMY-fal"
   },
   "outputs": [],
   "source": [
    "graph_ref_list = [nx.erdos_renyi_graph(15, 0.5) for _ in range(15) ]\n",
    "graph_pred_list = [nx.erdos_renyi_graph(15, 0.9) for _ in range(15) ]\n",
    "\n",
    "degree_stats(graph_ref_list, graph_pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4ScNBY6Z-vqM"
   },
   "outputs": [],
   "source": [
    "graph_ref_list = [nx.erdos_renyi_graph(15, 0.1) for _ in range(15) ]\n",
    "graph_pred_list = [nx.erdos_renyi_graph(15, 0.5) for _ in range(15) ]\n",
    "\n",
    "clustering_stats(graph_ref_list, graph_pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7O9ZYYVk4rWL"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMR74OtRj8zkHMB/tLBN7/H",
   "include_colab_link": true,
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
