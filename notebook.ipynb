{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gerritgr/MaskedGraphGen/blob/main/notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulnOzsCCmA8g"
      },
      "source": [
        "\n",
        "# <img src=\"https://mario.wiki.gallery/images/thumb/8/89/MPS_Toad_Artwork.png/170px-MPS_Toad_Artwork.png\" alt=\"Dataset Summary\" width=\"3%\">  Batched Toad  <img src=\"https://mario.wiki.gallery/images/thumb/8/89/MPS_Toad_Artwork.png/170px-MPS_Toad_Artwork.png\" alt=\"Dataset Summary\" width=\"3%\"> \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCWLJT5DLH78"
      },
      "source": [
        "Todos:\n",
        "- weightes sampling\n",
        "- multi-channel\n",
        "- uncertainty\n",
        "- fancy pooling\n",
        "- better ensable like skip one during training or learn weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-k6-4CDmEwH"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Csn1_ff8mJCE"
      },
      "outputs": [],
      "source": [
        "import sys, os\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "if IN_COLAB:\n",
        "  os.system(\"pip install wandb -Uq\")\n",
        "  #!pip install torch==1.8.0+cu111 torchvision==0.9.0+cu111 torchaudio==0.8.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "  #os.system(\"pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv torch_geometric -f https://data.pyg.org/whl/torch-1.13.0+cu117.html\")\n",
        "  os.system(\"pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\")\n",
        "  os.system(\"pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\")\n",
        "  os.system(\"pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\")\n",
        "\n",
        "\n",
        "PATH_TO_NOTEBOOK = \"Batched Toad 3.ipynb\"\n",
        "PROJECT_NAME = \"toad_dockerrand\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_wand_api_key():\n",
        "  api_key = \"\"\n",
        "  # use   echo \"your_api_key_here\" > ~/api_key.txt   to write the api key to the home file dir    \n",
        "  if api_key is not \"\":\n",
        "    return api_key\n",
        "  home_dir = os.path.expanduser('~')\n",
        "  file_path = os.path.join(home_dir, 'api_key.txt')\n",
        "  with open(file_path, 'r') as file:\n",
        "      api_key = file.read().strip()\n",
        "  return api_key\n"
      ],
      "metadata": {
        "id": "cN9PW__MvfFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUcQ44Bj42GY"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nKbKpbiSmMfW"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['figure.dpi'] = 100 # Set this to 300 to get better image quality\n",
        "from PIL import Image # We use PIL to load images\n",
        "import seaborn as sns\n",
        "import imageio # to generate .gifs\n",
        "\n",
        "# always good to have\n",
        "import glob, random, os, traceback\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import math\n",
        "\n",
        "# the typical pytorch imports\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "from torch.optim import Adam\n",
        "from torch.nn import Linear as Lin\n",
        "from torch.nn import Sequential as Seq\n",
        "from torch.nn import Linear\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# PyG\n",
        "import torch_geometric\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.utils import erdos_renyi_graph, to_networkx, from_networkx\n",
        "from torch_geometric.nn import GINConv\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.nn import global_mean_pool, global_add_pool\n",
        "from torch_geometric.loader import DataLoader\n",
        "\n",
        "#Video\n",
        "from PIL import Image, ImageDraw\n",
        "#import cv2\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAyrOuvomPAE"
      },
      "source": [
        "## Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZaElc28pmSzf"
      },
      "outputs": [],
      "source": [
        "NUM_NODES = 12   \n",
        "DEGREE = 3\n",
        "NUM_EPOCHS = 2000\n",
        "\n",
        "NUM_SAMPLES = 1000\n",
        "NUM_GRAPHS_GENERATE = 10\n",
        "\n",
        "NO_EDGE_INDICATOR = 3.0\n",
        "EDGE_INDICATOR = 1.0 \n",
        "DUMMY = 0.0 # this node is an actual node not a placeholder for an edge\n",
        "MASK = 2.0\n",
        "NUM_CLASSES = 4  #todo change to 5 an\n",
        "\n",
        "EPSILON = 0.000000001\n",
        "\n",
        "BATCH_SIZE_TEST = 100\n",
        "#TIME_EMBEDDING_DIM = 1\n",
        "\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "#DEVICE = torch.device('cpu')\n",
        "DEVICE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWpdimGn3fDH"
      },
      "source": [
        "### Seeds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eCtxrGI4mVz2"
      },
      "outputs": [],
      "source": [
        "# from stack overflow\n",
        "def str_to_float(s, encoding=\"utf-8\"):\n",
        "  from zlib import crc32\n",
        "  def bytes_to_float(b):\n",
        "    return float(crc32(b) & 0xffffffff) / 2**32\n",
        "  return bytes_to_float(s.encode(encoding))\n",
        "\n",
        "    \n",
        "def set_seeds(seed=42):\n",
        "  if not \"int\" in str(type(seed)):\n",
        "    seed = int(str_to_float(str(seed))*1000 % 100000000)\n",
        "  np.random.seed(seed)\n",
        "  torch.random.manual_seed(seed)\n",
        "  random.seed(seed)\n",
        "  torch.cuda.manual_seed_all(seed)\n",
        "  os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "\n",
        "set_seeds()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32hyXlJG8360"
      },
      "source": [
        "## Weights and Biases Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i_pixfTW84rq"
      },
      "outputs": [],
      "source": [
        "import wandb\n",
        "wandb.login(key=get_wand_api_key())\n",
        "\n",
        "sweep_config = {\n",
        "    \"name\": \"graph-unmasking\",\n",
        "    \"method\": \"random\",\n",
        "    \"metric\": {\n",
        "        \"name\": \"graph-unmasking/gen-loss\",\n",
        "        \"goal\": \"minimize\",\n",
        "    },\n",
        "    \"parameters\": {\n",
        "        \"batch_size\": {\"values\": [25, 50, 100]},  # write only\n",
        "        \"hidden_dim\": {\"values\": [8,16,32]},  \n",
        "        \"hidden_layer\": {\"values\": [3,4,5,6]},\n",
        "        \"learning_rate\": {\"values\": [0.00005,0.0001,0.0005]},\n",
        "        \"dropout\": {\"values\": [0.0, 0.1]},\n",
        "        \"normalization\": {\"values\": [True, False]},\n",
        "        \"model\": {\"values\": [ \"pnamulti\", \"pna\",\"pna2\", \"attention\",\"transformer\", \"unet\"]}, \n",
        "        \"candidate_selection_radius\": {\"values\": [1,5]},\n",
        "        \"loss\": {\"values\": [\"bce\"]},   # \"loss\": {\"values\": [\"l2\",\"l1\", \"bce\"]}, \n",
        "        \"single_pass\": {\"values\": [True, False]},  \n",
        "        \"towers\": {\"values\": [1, 2,5]}, \n",
        "    },\n",
        "}\n",
        "\n",
        "import pprint\n",
        "pprint.pprint(sweep_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQyrEbzkmMCL"
      },
      "source": [
        "## Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9_zto3HQmp5v"
      },
      "outputs": [],
      "source": [
        "def lift_nx_to_pyg(g_nx):\n",
        "  # g_nx has to have node_labels 0 ... number_of_nodes-1\n",
        "  num_nodes = g_nx.number_of_nodes()\n",
        "  g_complete_nx = nx.complete_graph(num_nodes)\n",
        "\n",
        "  edges_new = list()\n",
        "  node_value_dict = dict()\n",
        "  for v1, v2 in g_complete_nx.edges():\n",
        "    v3 = (v1+1)*10000+(v2+1)*100000000000\n",
        "    edges_new.append((v1, v3))\n",
        "    edges_new.append((v2, v3))\n",
        "    node_value_dict[v1] = DUMMY\n",
        "    node_value_dict[v2] = DUMMY\n",
        "    node_value_dict[v3] = EDGE_INDICATOR if g_nx.has_edge(v1,v2) else NO_EDGE_INDICATOR\n",
        "\n",
        "  graph_new = nx.from_edgelist(edges_new)\n",
        "  for node, x_value in node_value_dict.items():\n",
        "    graph_new.nodes[node]['x'] = x_value\n",
        "\n",
        "  graph_new = nx.convert_node_labels_to_integers(graph_new, ordering='sorted')\n",
        "\n",
        "  g = from_networkx(graph_new, group_node_attrs=['x'])\n",
        "  return g\n",
        "\n",
        "\n",
        "def reduce_nx_graph(g_old):\n",
        "  g_new = nx.Graph()\n",
        "  for v_i in g_old.nodes():\n",
        "    if g_old.nodes[v_i]['x'] == DUMMY:\n",
        "      g_new.add_node(v_i)\n",
        "      g_new.nodes[v_i]['x'] = DUMMY\n",
        "\n",
        "  for v_i in g_old.nodes():\n",
        "    if g_old.nodes[v_i]['x'] == EDGE_INDICATOR:\n",
        "      neigh_list = list(g_old.neighbors(v_i))\n",
        "      assert(len(neigh_list) == 2)\n",
        "      g_new.add_edge(neigh_list[0], neigh_list[1])\n",
        "\n",
        "  return g_new\n",
        "\n",
        "def draw_pyg(g_pyg, ax = None, filename = None):\n",
        "  if ax is None:\n",
        "    plt.clf()\n",
        "  g_nx = to_networkx(g_pyg, node_attrs=['x'], to_undirected=True,)\n",
        "\n",
        "  g_nx = reduce_nx_graph(g_nx)\n",
        "\n",
        "  node_labels = {i: g_nx.nodes[i]['x'] for i in g_nx.nodes}\n",
        "  pos = nx.spring_layout(g_nx, seed=1234)\n",
        "  nx.draw(g_nx, with_labels = True, labels=node_labels, ax=ax, pos=pos)\n",
        "  if filename is not None:\n",
        "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
        "  return g_nx\n",
        "\n",
        "\n",
        "def shuffle_tensor(x):\n",
        "  x = x.clone()\n",
        "  x_shape = x.shape\n",
        "  x = x.flatten()\n",
        "  x = x[torch.randperm(x.numel())]\n",
        "  return x.reshape(x.shape)\n",
        "\n",
        "\n",
        "def note_features_to_one_hot(x):\n",
        "  # create indicator vector for NUM_CLASSES classes, values outside are set to all zeros (first to special class that then gets truncated)\n",
        "  x_cut = torch.where((x < -0.1) | (x > NUM_CLASSES-0.5), torch.tensor(NUM_CLASSES, device = DEVICE, dtype=torch.float), x)\n",
        "  x_one_hot = torch.zeros(x.shape[0], NUM_CLASSES+1, device = DEVICE)\n",
        "  x_one_hot.scatter_(1, x_cut.round().long().view(-1).unsqueeze(1), 1)\n",
        "  x_one_hot = x_one_hot[:,0:NUM_CLASSES]\n",
        "  return x_one_hot\n",
        "\n",
        "def global_mask_pool(x, x_in, batch):\n",
        "  mask_indicator = torch.lt(torch.sum(x_in, dim=1), 0.5).view(-1, 1)\n",
        "  x = x * mask_indicator\n",
        "  x = global_add_pool(x, batch)\n",
        "  return x "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bJ3hIT0pmBXp"
      },
      "outputs": [],
      "source": [
        "edge_index = torch.tensor([[0, 1, 2, 3, 1, 2, 3, 1],\n",
        "                           [1, 2, 3, 1, 0, 1, 2, 3]], dtype=torch.long).to(DEVICE)\n",
        "x = torch.tensor([[-1], [0], [1], [1]], dtype=torch.float).to(DEVICE)\n",
        "\n",
        "data = Data(x=x, edge_index=edge_index)\n",
        "\n",
        "g = torch_geometric.utils.to_networkx(data, to_undirected=True, node_attrs=['x'])\n",
        "nx.draw(g, pos=nx.spring_layout(g),  with_labels = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AiLapF9HnilF"
      },
      "outputs": [],
      "source": [
        "data = lift_nx_to_pyg(g)\n",
        "data, data.x, data.edge_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cgkOkx4amnfY"
      },
      "outputs": [],
      "source": [
        "draw_pyg(data, filename='examplegraph.png')\n",
        "if IN_COLAB:\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iaElQYAbWu8M"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mCpXui1mW9mp"
      },
      "outputs": [],
      "source": [
        "class ShuffleList:\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "        self.index = 0\n",
        "\n",
        "    def __iter__(self):\n",
        "        random.shuffle(self.data)\n",
        "        self.index = 0\n",
        "        return self\n",
        "\n",
        "    def __next__(self):\n",
        "        if self.index < len(self.data):\n",
        "            value = self.data[self.index]\n",
        "            self.index += 1\n",
        "            return value\n",
        "        else:\n",
        "            raise StopIteration\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.data[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IgbW4Z0tWuN1"
      },
      "outputs": [],
      "source": [
        "def build_dataset(num_nodes=NUM_NODES, num_samples=NUM_SAMPLES, degree=DEGREE):\n",
        "  graph_dataset = list() \n",
        "  seed = 1234\n",
        "\n",
        "  for _ in range(num_samples):\n",
        "    while True:\n",
        "      seed += 1\n",
        "      graph = nx.random_regular_graph(d=degree, n=num_nodes, seed=seed)\n",
        "      if nx.is_connected(graph):\n",
        "        graph.x = torch.ones(num_nodes).t()\n",
        "        graph_dataset.append(lift_nx_to_pyg(graph))\n",
        "        break\n",
        "\n",
        "  return ShuffleList(graph_dataset)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xKqFT6D7XHE7"
      },
      "outputs": [],
      "source": [
        "dataset = build_dataset()\n",
        "data = dataset[0]\n",
        "draw_pyg(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U2FUnVjG4Cwh"
      },
      "outputs": [],
      "source": [
        "# TODO dataloader\n",
        "from torch_geometric.loader import DataLoader\n",
        "train_loader = DataLoader(dataset, batch_size=BATCH_SIZE_TEST, shuffle=True)\n",
        "for step, data in enumerate(train_loader):\n",
        "  print(f'Step {step + 1}:')\n",
        "  print('=======')\n",
        "  print(f'Number of graphs in the current batch: {data.num_graphs}')\n",
        "  print(data)\n",
        "  print()\n",
        "  print(data.x.flatten(), data.edge_index, data.batch)\n",
        "  break\n",
        "\n",
        "\n",
        "# for gen of training sample:\n",
        "# 1) mask 0 ... (all -1) (inclusivly) \n",
        "# 2) swich exactly 1 of the unmasked"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqztDRIj0UdF"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kV_DnkKhs9P-"
      },
      "source": [
        "#### AttentionNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eoLXRG6utBBU"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.nn import GATv2Conv, GraphNorm, BatchNorm\n",
        "\n",
        "class AttentionNet(torch.nn.Module):\n",
        "  def __init__(self, hidden_dim=32, layer_num=6, dropout=0.1, normalization=False, single_pass_pooling=False):\n",
        "    super(AttentionNet, self).__init__()\n",
        "\n",
        "    self.mlp_list = nn.ModuleList()\n",
        "    self.conv_list = nn.ModuleList()\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "    self.dropout = dropout\n",
        "    self.graph_norms = nn.ModuleList()\n",
        "    self.normalization = normalization\n",
        "    self.single_pass_pooling = single_pass_pooling\n",
        "    assert(hidden_dim % 2 == 0)\n",
        "    input_channels = NUM_CLASSES\n",
        "\n",
        "    for i in range(layer_num):\n",
        "      in_dim = hidden_dim if i > 0 else input_channels \n",
        "      out_dim = hidden_dim if i < layer_num-1 else 1 \n",
        "      self.conv_list.append(GATv2Conv(in_channels=in_dim, out_channels=hidden_dim // 2, heads=2))\n",
        "      self.graph_norms.append(BatchNorm(hidden_dim))\n",
        "      self.mlp_list.append(Seq(Lin(hidden_dim, hidden_dim), nn.ReLU(), Lin(hidden_dim, hidden_dim), nn.ReLU(), Lin(hidden_dim, out_dim)))\n",
        "\n",
        "  def forward(self, x_in, edge_index, batch):\n",
        "    x = note_features_to_one_hot(x_in)\n",
        "    for i in range(len(self.conv_list)):\n",
        "      x = self.conv_list[i](x, edge_index)\n",
        "      x = F.relu(x)\n",
        "      if self.normalization:\n",
        "        x = self.graph_norms[i](x)\n",
        "      x = self.mlp_list[i](x)\n",
        "      #if i == 0:\n",
        "      #  x = self.dropout(x)\n",
        "\n",
        "    if self.single_pass_pooling:\n",
        "      x = global_mask_pool(x, x_in, batch)\n",
        "    else:\n",
        "      x = global_mean_pool(x, batch)\n",
        "    x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "    x = self.sigmoid(x) + EPSILON\n",
        "    return x.flatten()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iTUh3uVOtEMO"
      },
      "outputs": [],
      "source": [
        "model = AttentionNet(single_pass_pooling=True)\n",
        "model.to(DEVICE)\n",
        "print(model) \n",
        "for step, data in enumerate(train_loader):\n",
        "  data = data.to(DEVICE)\n",
        "  print(model(data.x, data.edge_index, data.batch))\n",
        "  break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaQ7f2E4dCqd"
      },
      "source": [
        "#### TransformerNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nS3CzlgcdEAK"
      },
      "outputs": [],
      "source": [
        "#relu = nn.Relu() ## todo: changed to relu here\n",
        "from torch_geometric.nn import TransformerConv\n",
        "\n",
        "class TransformerNet(torch.nn.Module):\n",
        "  def __init__(self, hidden_dim=32, layer_num=6, dropout=0.1, normalization=False, single_pass_pooling = False):\n",
        "    super(TransformerNet, self).__init__()\n",
        "\n",
        "    self.mlp_list = nn.ModuleList()\n",
        "    self.conv_list = nn.ModuleList()\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "    self.graph_norms = nn.ModuleList()\n",
        "    self.dropout = dropout\n",
        "    self.normalization = normalization\n",
        "    assert(hidden_dim % 2 == 0)\n",
        "    input_channels = NUM_CLASSES\n",
        "    self.single_pass_pooling = single_pass_pooling\n",
        "\n",
        "\n",
        "    for i in range(layer_num):\n",
        "      in_dim = hidden_dim if i > 0 else input_channels \n",
        "      out_dim = hidden_dim if i < layer_num-1 else 1 \n",
        "      self.conv_list.append(TransformerConv(in_channels=in_dim, out_channels=hidden_dim // 2, heads=2))\n",
        "      self.graph_norms.append(BatchNorm(hidden_dim))\n",
        "      self.mlp_list.append(Seq(Lin(hidden_dim, hidden_dim), nn.ReLU(), Lin(hidden_dim, hidden_dim), nn.ReLU(), Lin(hidden_dim, out_dim)))\n",
        "\n",
        "  def forward(self, x_in, edge_index, batch):\n",
        "    x = note_features_to_one_hot(x_in)\n",
        "    for i in range(len(self.conv_list)):\n",
        "      x = self.conv_list[i](x, edge_index)\n",
        "      if self.normalization:\n",
        "        x = self.graph_norms[i](x)\n",
        "      x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "      x = self.mlp_list[i](x)\n",
        "    \n",
        "    if self.single_pass_pooling:\n",
        "      x = global_mask_pool(x, x_in, batch)\n",
        "    else:\n",
        "      x = global_mean_pool(x, batch)\n",
        "\n",
        "    x = self.sigmoid(x) + EPSILON\n",
        "    return x.flatten()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "plkfTVUrXRO-"
      },
      "outputs": [],
      "source": [
        "model = TransformerNet()\n",
        "model.to(DEVICE)\n",
        "print(model) \n",
        "for step, data in enumerate(train_loader):\n",
        "  data = data.to(DEVICE)\n",
        "  print(model(data.x, data.edge_index, data.batch))\n",
        "  break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwghOZsDdEJz"
      },
      "source": [
        "#### Unet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LEwIcO4w0VaR"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.nn import GraphUNet\n",
        "\n",
        "class Unet(torch.nn.Module):\n",
        "  def __init__(self, hidden_channels=32, out_channels=1, depth=4, single_pass_pooling = False):\n",
        "    super(Unet, self).__init__()\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "    in_channels = NUM_CLASSES\n",
        "    self.single_pass_pooling = single_pass_pooling\n",
        "    self.unet = GraphUNet(in_channels=in_channels, hidden_channels=hidden_channels, out_channels=out_channels, depth=depth)\n",
        "\n",
        "  def forward(self, x_in, edge_index, batch):\n",
        "    x = note_features_to_one_hot(x_in)\n",
        "    x = self.unet(x, edge_index)\n",
        "\n",
        "    if self.single_pass_pooling:\n",
        "      x = global_mask_pool(x, x_in, batch)\n",
        "    else:\n",
        "      x = global_mean_pool(x, batch)\n",
        "\n",
        "    x = self.sigmoid(x) + 0.0000001 # add eps to avoid div. by zero\n",
        "    return x.flatten()\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YBYSWAp9XOLz"
      },
      "outputs": [],
      "source": [
        "\n",
        "model = Unet()\n",
        "model.to(DEVICE)\n",
        "print(model) \n",
        "for step, data in enumerate(train_loader):\n",
        "  data.to(DEVICE)\n",
        "  print(model(data.x, data.edge_index, data.batch))\n",
        "  break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ir4sFS6YS5UY"
      },
      "source": [
        "#### PNA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U_8SApKdS3wo"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.nn import PNA\n",
        "from torch_geometric.utils import degree\n",
        "\n",
        "#train_dataset = build_dataset()\n",
        "\n",
        "def dataset_to_degree_bin(train_dataset):\n",
        "  # Compute the maximum in-degree in the training data.\n",
        "  max_degree = -1\n",
        "  for data in train_dataset:\n",
        "      d = degree(data.edge_index[1], num_nodes=data.num_nodes, dtype=torch.long)\n",
        "      max_degree = max(max_degree, int(d.max()))\n",
        "\n",
        "  deg = torch.zeros(max_degree + 1, dtype=torch.long)\n",
        "  for data in train_dataset:\n",
        "      d = degree(data.edge_index[1], num_nodes=data.num_nodes, dtype=torch.long)\n",
        "      deg += torch.bincount(d, minlength=deg.numel())\n",
        "  return deg\n",
        "\n",
        "class PNAnet(torch.nn.Module):\n",
        "  def __init__(self, train_dataset_example, hidden_channels=32, out_channels=1, depth=4, dropout=0.0, towers=2, single_pass_pooling=False):\n",
        "    super(PNAnet, self).__init__()\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    # Calculate x as the difference between mult_y and hidden_dim\n",
        "    hidden_channels = towers * ((hidden_channels // towers) + 1)\n",
        "    out_channels = towers * ((out_channels // towers) + 1)\n",
        "\n",
        "    in_channels = NUM_CLASSES\n",
        "    deg = dataset_to_degree_bin(train_dataset_example)\n",
        "    aggregators = ['mean', 'min', 'max', 'std']\n",
        "    scalers = ['identity', 'amplification', 'attenuation']\n",
        "    self.pnanet = PNA(in_channels=in_channels, hidden_channels=hidden_channels, out_channels=out_channels, num_layers=depth, aggregators=aggregators, scalers=scalers, deg=deg, dropout=dropout, towers=towers)\n",
        "    self.single_pass_pooling = single_pass_pooling\n",
        "\n",
        "  def forward(self, x_in, edge_index, batch):\n",
        "    x = note_features_to_one_hot(x_in)\n",
        "    x = self.pnanet(x, edge_index)\n",
        "\n",
        "    if self.single_pass_pooling:\n",
        "      x = global_mask_pool(x, x_in, batch)\n",
        "    else:\n",
        "      x = global_mean_pool(x, batch)\n",
        "\n",
        "    x = x.sum(dim=1)\n",
        "    x = self.sigmoid(x) + EPSILON # add eps to avoid div. by zero\n",
        "    return x.flatten()\n",
        "\n",
        "class PNAmulti(torch.nn.Module):\n",
        "  def __init__(self, train_dataset_example, hidden_channels=32, out_channels=1, depth=4, dropout=0.0, towers=1, model_num=5, single_pass_pooling=False):\n",
        "    super(PNAmulti, self).__init__()\n",
        "    self.model_num = model_num\n",
        "    self.pna_list = nn.ModuleList()\n",
        "    for _ in range(model_num):\n",
        "      pna_model = PNAnet(train_dataset_example, hidden_channels=hidden_channels, out_channels=out_channels, depth=depth, dropout=dropout, towers=towers, single_pass_pooling=single_pass_pooling)\n",
        "      self.pna_list.append(pna_model)\n",
        "\n",
        "  def forward(self, x, edge_index, batch):\n",
        "    x_agg = None\n",
        "    for pna_model in self.pna_list:\n",
        "      if x_agg is None:\n",
        "        x_agg = pna_model( x, edge_index, batch) / self.model_num\n",
        "      else:\n",
        "        x_agg = x_agg + pna_model( x, edge_index, batch) / self.model_num\n",
        "    return x_agg\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TTvXwuajPPOJ"
      },
      "outputs": [],
      "source": [
        "model = PNAmulti(build_dataset())\n",
        "model.to(DEVICE)\n",
        "print(model) \n",
        "for step, data in enumerate(train_loader):\n",
        "  data.to(DEVICE)\n",
        "  print(model(data.x, data.edge_index, data.batch))\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hSyYUfY1X6Os"
      },
      "outputs": [],
      "source": [
        "model = PNAnet(build_dataset())\n",
        "model.to(DEVICE)\n",
        "print(model) \n",
        "for step, data in enumerate(train_loader):\n",
        "  data.to(DEVICE)\n",
        "  print(model(data.x, data.edge_index, data.batch))\n",
        "  break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jB6WbKuwVdix"
      },
      "source": [
        "#### PNA2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Mvgyb_hVgpv"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.nn import PNAConv\n",
        "\n",
        "class PNA2net(torch.nn.Module):\n",
        "  def __init__(self, train_dataset_example, hidden_dim=32, layer_num=4, dropout=0.0, normalization=False, tower_num=5, single_pass_pooling=False):\n",
        "    super().__init__()\n",
        "\n",
        "    aggregators = ['mean', 'min', 'max', 'std', 'var', 'sum']\n",
        "    scalers = ['identity', 'amplification', 'attenuation']\n",
        "    deg = dataset_to_degree_bin(train_dataset_example)\n",
        "\n",
        "    # Calculate x as the difference between mult_y and hidden_dim\n",
        "    hidden_dim = tower_num * ((hidden_dim // tower_num) + 1)\n",
        "\n",
        "    self.conv_list = nn.ModuleList()\n",
        "    self.batchnorm_list = nn.ModuleList()\n",
        "    self.mlp_list = nn.ModuleList()\n",
        "\n",
        "    self.dropout = dropout\n",
        "    self.normalization = normalization\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "    self.single_pass_pooling = single_pass_pooling\n",
        "\n",
        "    input_channels = NUM_CLASSES\n",
        "  \n",
        "\n",
        "    for i in range(layer_num):\n",
        "      in_dim = hidden_dim if i > 0 else input_channels \n",
        "      out_dim = hidden_dim if i < layer_num-1 else 1 \n",
        "      self.conv_list.append(PNAConv(in_channels=in_dim, out_channels=hidden_dim, aggregators=aggregators, scalers=scalers, deg=deg, towers=tower_num, pre_layers=1, post_layers=1, divide_input=False))\n",
        "      self.batchnorm_list.append(BatchNorm(hidden_dim))\n",
        "      self.mlp_list.append(Seq(nn.ReLU(), Lin(hidden_dim+NUM_CLASSES+in_dim, hidden_dim+NUM_CLASSES+in_dim), nn.ReLU(), Lin(hidden_dim+NUM_CLASSES+in_dim, hidden_dim+NUM_CLASSES+in_dim), nn.ReLU(), Lin(hidden_dim+NUM_CLASSES+in_dim, out_dim)))\n",
        "          \n",
        "  def forward(self, x_in, edge_index, batch):\n",
        "    x_onehot = note_features_to_one_hot(x_in)\n",
        "    x = x_onehot.clone()\n",
        "    for i in range(len(self.conv_list)):\n",
        "      x_in = x.clone()\n",
        "      x = self.conv_list[i](x, edge_index)\n",
        "      if self.normalization:\n",
        "        x = self.batchnorm_list[i](x)\n",
        "      x_concat = torch.concat([x, x_onehot, x_in], dim=1)\n",
        "      x = self.mlp_list[i](x_concat)\n",
        "      if i < len(self.conv_list)-1:\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "\n",
        "    if self.single_pass_pooling:\n",
        "      x = global_mask_pool(x, x_in, batch)\n",
        "    else:\n",
        "      x = global_mean_pool(x, batch)\n",
        "      \n",
        "    x = self.sigmoid(x) + EPSILON\n",
        "    return x.flatten()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rgjqgcfhY1gC"
      },
      "outputs": [],
      "source": [
        "model = PNA2net(build_dataset())\n",
        "model.to(DEVICE)\n",
        "print(model) \n",
        "for step, data in enumerate(train_loader):\n",
        "  data.to(DEVICE)\n",
        "  print(model(data.x, data.edge_index, data.batch))\n",
        "  break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tph0rjhNS6iS"
      },
      "source": [
        "### Build Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gDKYLoMV6z6J"
      },
      "outputs": [],
      "source": [
        "def build_model(config, dataset):\n",
        "  hidden_dim = config.hidden_dim\n",
        "  single_pass_pooling = config.single_pass\n",
        "  if config.model == \"unet\":\n",
        "    model =  Unet(hidden_channels = hidden_dim,  out_channels = 1, depth=config.hidden_layer, single_pass_pooling=single_pass_pooling)\n",
        "  elif config.model == \"attention\":\n",
        "     model = AttentionNet(hidden_dim=hidden_dim, layer_num=config.hidden_layer, dropout=config.dropout, normalization=config.normalization, single_pass_pooling=single_pass_pooling)\n",
        "  elif config.model == \"transformer\":\n",
        "    model = TransformerNet(hidden_dim=hidden_dim, layer_num=config.hidden_layer, dropout=config.dropout, normalization=config.normalization, single_pass_pooling=single_pass_pooling)\n",
        "  elif config.model == \"pna\":\n",
        "    model = PNAnet(dataset, hidden_channels=hidden_dim, depth=config.hidden_layer, dropout=config.dropout, towers=config.towers, single_pass_pooling=single_pass_pooling)\n",
        "  elif config.model == \"pnamulti\":\n",
        "    model = PNAmulti(dataset, hidden_channels=hidden_dim, depth=config.hidden_layer, dropout=config.dropout, towers=config.towers, single_pass_pooling=single_pass_pooling)\n",
        "  elif config.model == \"pna2\":\n",
        "    model = PNA2net(dataset, hidden_dim=hidden_dim, layer_num=config.hidden_layer, dropout=config.dropout, normalization=config.normalization, single_pass_pooling=single_pass_pooling)\n",
        "  else:\n",
        "    ValueError(\"illegal net\")\n",
        "  return model.to(DEVICE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GDOIysiiIGT"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FsofkLkkP3GK"
      },
      "outputs": [],
      "source": [
        "def find_best_choice(model, g, test_choices, x, x_shape):\n",
        "  p_0_list = list()\n",
        "  p_1_list = list()\n",
        "  x_noedge_list = list()\n",
        "  x_edge_list = list()\n",
        "  mask_indicator_list = list()\n",
        "\n",
        "  for i, mask_indicator in enumerate(test_choices):\n",
        "    x_noedge, x_edge = x.clone(), x.clone()\n",
        "    x_noedge[mask_indicator] = NO_EDGE_INDICATOR\n",
        "    x_edge[mask_indicator] = EDGE_INDICATOR\n",
        "    batch = torch.zeros(x_shape[0], dtype=torch.long).to(DEVICE)\n",
        "    p_0 = model(x_noedge.view(x_shape), g.edge_index, batch=batch).item()\n",
        "    p_1 = model(x_edge.view(x_shape), g.edge_index, batch=batch).item()\n",
        "\n",
        "    p_0_list.append(p_0/(p_0+p_1))\n",
        "    p_1_list.append(p_1/(p_0+p_1))\n",
        "    x_noedge_list.append(x_noedge)\n",
        "    x_edge_list.append(x_edge)\n",
        "    mask_indicator_list.append(mask_indicator)\n",
        "\n",
        "  best_i = np.argmax(p_1_list)\n",
        "  return p_0_list[best_i], p_1_list[best_i], x_noedge_list[best_i],  x_edge_list[best_i], mask_indicator_list[best_i]\n",
        "\n",
        "\n",
        "def generate_graph_multi(model, g, choice_num=5):\n",
        "  x = g.x\n",
        "  x_shape = x.shape\n",
        "  x = x.flatten()\n",
        "  indices_of_edges = (x != DUMMY).nonzero(as_tuple=False).flatten()\n",
        "  num_edges = indices_of_edges.numel()\n",
        "  x[indices_of_edges] = MASK\n",
        "  indices_of_edges = indices_of_edges.flatten().tolist()\n",
        "\n",
        "  for _ in range(num_edges):\n",
        "    random.shuffle(indices_of_edges)\n",
        "    choice_num_i = min(choice_num, len(indices_of_edges)) \n",
        "    test_choices = indices_of_edges[0:choice_num_i]\n",
        "    p_0, p_1, x_noedge, x_edge, mask_indicator = find_best_choice(model, g, test_choices, x, x_shape)\n",
        "    random_selection_index = int(np.random.choice([0, 1], size=1, p=[p_0, p_1]))\n",
        "    x = (x_noedge, x_edge)[random_selection_index]\n",
        "    indices_of_edges.remove(mask_indicator)\n",
        "\n",
        "  g.x = x.reshape(x_shape)\n",
        "  return g"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DQay_Zy35bHr"
      },
      "outputs": [],
      "source": [
        "def generate_graph_singlepass(model, g):\n",
        "  x = g.x\n",
        "  x_shape = x.shape\n",
        "  x = x.flatten()\n",
        "  indices_of_edges = (x != DUMMY).nonzero(as_tuple=False).flatten()\n",
        "  num_edges = indices_of_edges.numel()\n",
        "  x[indices_of_edges] = MASK\n",
        "  indices_of_edges = indices_of_edges.flatten().tolist()\n",
        "  random.shuffle(indices_of_edges)\n",
        "  batch = torch.zeros(x_shape[0], dtype=torch.long).to(DEVICE)\n",
        "\n",
        "  for edge_index in indices_of_edges:\n",
        "    x[edge_index] = -1.0\n",
        "    edge_prob = model(x.view(x_shape), g.edge_index, batch=batch).item()\n",
        "    assert(edge_prob > 0.0 and edge_prob < 1.0)\n",
        "    if random.random() < edge_prob:\n",
        "      x[edge_index] = EDGE_INDICATOR\n",
        "    else:\n",
        "      x[edge_index] = NO_EDGE_INDICATOR\n",
        "\n",
        "  g.x = x.reshape(x_shape)\n",
        "  return g\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_cN5gKKUiJTR"
      },
      "outputs": [],
      "source": [
        "@torch.inference_mode()\n",
        "def generate_graphs(num, epoch_i, model, g_like, config):\n",
        "  mean_degree_list = list()\n",
        "  var_degree_list = list()\n",
        "  for j in range(num):\n",
        "    if config.single_pass:\n",
        "      g = generate_graph_singlepass(model, g_like)\n",
        "    else:\n",
        "      g = generate_graph_multi(model, g_like, choice_num = config.candidate_selection_radius)\n",
        "    nx_orig_graph = draw_pyg(g, filename=f\"generated_graph_epoch{str(epoch_i).zfill(5)}_sample{str(j).zfill(5)}.jpg\")\n",
        "    degree_list = [nx_orig_graph.degree(i) for i in nx_orig_graph.nodes()]\n",
        "    mean_degree_list.append(np.mean(degree_list))\n",
        "    var_degree_list.append(np.var(degree_list))\n",
        "  return np.mean(mean_degree_list), np.mean(var_degree_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKxurLjrXnCo"
      },
      "source": [
        "## Generat Samples for Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nALlwSTtXmhx"
      },
      "outputs": [],
      "source": [
        "def gen_random_training_sample_unused(x):\n",
        "  x_masked = x.clone().reshape(-1)\n",
        "  indices_of_edges = (x_masked != DUMMY).nonzero(as_tuple=False).flatten()\n",
        "  num_edges = indices_of_edges.numel()\n",
        "  num_masked = torch.randint(1, num_edges+1, size=(1,), device=DEVICE)\n",
        "  #num_masked = sample_num_masked_geometric(1, num_edges+1)\n",
        "\n",
        "  shuffled_indices_of_edges = indices_of_edges[torch.randperm(indices_of_edges.numel())]\n",
        "  indices_of_edges_to_mask = shuffled_indices_of_edges[:num_masked]\n",
        "  \n",
        "  gt_value = x_masked[indices_of_edges_to_mask[0]].item() # we will change the first value back\n",
        "  x_masked[indices_of_edges_to_mask] = MASK\n",
        "\n",
        "\n",
        "  x_masked_0 = x_masked.clone()\n",
        "  x_masked_0[indices_of_edges_to_mask[0]] = NO_EDGE_INDICATOR\n",
        "  x_masked_0 = x_masked_0.reshape(x.shape)\n",
        "\n",
        "  x_masked_1 = x_masked.clone()\n",
        "  x_masked_1[indices_of_edges_to_mask[0]] = EDGE_INDICATOR\n",
        "  x_masked_1 = x_masked_1.reshape(x.shape)\n",
        "\n",
        "  if gt_value == NO_EDGE_INDICATOR:\n",
        "    return x_masked_0, x_masked_1\n",
        "  elif gt_value == EDGE_INDICATOR:\n",
        "    return x_masked_1, x_masked_0 \n",
        "  assert(False)\n",
        "\n",
        "  return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G-gIs8GVYm5l"
      },
      "outputs": [],
      "source": [
        "def sample_mask_and_flip(batch, x):\n",
        "  num_graphs = batch.view(-1)[-1]\n",
        "  x_id_mask = list()\n",
        "  x_id_flip = list()\n",
        "\n",
        "  for graph_id in range(num_graphs+1):\n",
        "    #num_nodes = (batch == graph_id).sum()\n",
        "    #indices_of_edges = (x != DUMMY and batch == graph_id).nonzero(as_tuple=False)\n",
        "    edge_indicator = x.view(-1) != DUMMY\n",
        "    batch_indicator = batch.view(-1) == graph_id \n",
        "    indices_of_edges = torch.nonzero(batch_indicator & edge_indicator)\n",
        "    indices_of_edges = indices_of_edges.flatten().tolist()\n",
        "    random.shuffle(indices_of_edges)\n",
        "    x_id_flip.append(indices_of_edges[-1])\n",
        "    num_masked = random.choice(range(len(indices_of_edges)))\n",
        "    x_id_mask = x_id_mask + indices_of_edges[:num_masked]\n",
        "\n",
        "  mask_and_flip_indicator = torch.zeros(batch.numel(), dtype=torch.long).to(DEVICE)\n",
        "  mask_and_flip_indicator[x_id_mask] = 1\n",
        "  mask_and_flip_indicator[x_id_flip] = 2\n",
        "\n",
        "  return mask_and_flip_indicator\n",
        "\n",
        "def mask_x_based_on_indicator(x, mask_and_flip_indicator):\n",
        "  x_new = x.clone()\n",
        "  to_mask = mask_and_flip_indicator == 1\n",
        "  x_new.view(-1)[to_mask] = MASK\n",
        "  return x_new\n",
        "\n",
        "\n",
        "# this is done inplace!\n",
        "def flip_x_based_on_indicator(x, mask_and_flip_indicator):\n",
        "  to_flip = (mask_and_flip_indicator == 2)#.to(DEVICE)\n",
        "  x = x.clone()  #sadly in-place operation not allowed here\n",
        "\n",
        "  #x[to_flip] = -x[to_flip]\n",
        "\n",
        "  x[to_flip] = torch.where(x[to_flip] == EDGE_INDICATOR, torch.tensor(NO_EDGE_INDICATOR).to(DEVICE), torch.tensor(EDGE_INDICATOR).to(DEVICE))\n",
        "\n",
        "  return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1La4pbjWakyz"
      },
      "outputs": [],
      "source": [
        "for step, data in enumerate(train_loader):\n",
        "  data.to(DEVICE)\n",
        "  mask_and_flip_indicator = sample_mask_and_flip(data.batch, data.x)\n",
        "  break\n",
        "\n",
        "\n",
        "x = (mask_x_based_on_indicator(data.x, mask_and_flip_indicator))\n",
        "xz = x.clone()\n",
        "xx = (flip_x_based_on_indicator(x, mask_and_flip_indicator))\n",
        "\n",
        "(xz == xx).flatten()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TulPGAH8R0Eo"
      },
      "source": [
        "## Compute Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "flDsYTRKR1ZB"
      },
      "outputs": [],
      "source": [
        "bce_loss = nn.BCELoss()\n",
        "def reduce_loss(loss_for_graph, config):\n",
        "  # loss_for_graph should be > 0\n",
        "  if config.loss == \"l1\":\n",
        "    return loss_for_graph.sum() \n",
        "  elif config.loss == \"l2\":\n",
        "    return F.mse_loss(loss_for_graph, torch.zeros_like(loss_for_graph))\n",
        "  elif config.loss == \"bce\":\n",
        "    return bce_loss(loss_for_graph, torch.zeros_like(loss_for_graph))\n",
        "  else:\n",
        "    raise ValueError(\"Illegal loss value\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVx9HGc89VFe"
      },
      "source": [
        "## Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4M0XZ5Vpk5Z"
      },
      "outputs": [],
      "source": [
        "def prepare_x_for_single_pass(mask_and_flip_indicator, x):\n",
        "  x_new = x.clone()\n",
        "  to_mask = mask_and_flip_indicator == 1\n",
        "  x_new.view(-1)[to_mask] = MASK\n",
        "  choice_indicator = mask_and_flip_indicator == 2\n",
        "  x_new.view(-1)[choice_indicator] = -1 # this will be set to zero in the one hot encoding step\n",
        "  gt = x.clone().flatten()[choice_indicator]\n",
        "  gt = torch.where(gt == EDGE_INDICATOR, torch.tensor(1.0, device = DEVICE), torch.zeros_like(gt))\n",
        "  return x_new, gt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gj5td9zue7HT"
      },
      "outputs": [],
      "source": [
        "def single_pass_prediction(data, model):\n",
        "  mask_and_flip_indicator = sample_mask_and_flip(data.batch, data.x)\n",
        "  x_in, out_gt = prepare_x_for_single_pass(mask_and_flip_indicator, data.x)\n",
        "  out_prediction = model(x_in, data.edge_index, data.batch) # between 0 ,1 \n",
        "\n",
        "  #print(\"out gt: \", out_gt.flatten(), \"   out pred:   \", out_prediction.flatten())\n",
        "\n",
        "  loss_for_graph =  torch.abs(out_prediction.flatten() - out_gt.flatten()) # between 0 and 1\n",
        "  return loss_for_graph "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sUfUS3OYfNxu"
      },
      "outputs": [],
      "source": [
        "def multi_pass_prediction(data, model):\n",
        "  mask_and_flip_indicator = sample_mask_and_flip(data.batch, data.x) # this then should also return gt \n",
        "  x = mask_x_based_on_indicator(data.x, mask_and_flip_indicator)\n",
        "  out_correct = model(x, data.edge_index, data.batch)  # is supposed to be 1 everywhere\n",
        "  x = flip_x_based_on_indicator(x, mask_and_flip_indicator)  # important to use x here and not data.x\n",
        "  out_incorrect = model(x, data.edge_index, data.batch) # is supposed to be 0 everywhere\n",
        "  loss_for_graph =  out_incorrect - out_correct # between -1 and 1\n",
        "  loss_for_graph = (loss_for_graph + 1.0) / 2.0   # between 0 and 1,\n",
        "  return loss_for_graph "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-_84ieMIoYh5"
      },
      "outputs": [],
      "source": [
        "def feed_data_to_model(data, model, config):\n",
        "  if config.single_pass == True:\n",
        "    return single_pass_prediction(data, model)\n",
        "  return multi_pass_prediction(data, model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8RF9E-wfDXW"
      },
      "source": [
        "### Start Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lDBAh9XPiO-a"
      },
      "outputs": [],
      "source": [
        "def start_agent(config):\n",
        "  graph_dataset = build_dataset()\n",
        "  model = build_model(config, graph_dataset)\n",
        "  wandb.log({\"num_parameters\": sum(p.numel() for p in model.parameters())})\n",
        "\n",
        "  optimizer = Adam(model.parameters(), lr = config.learning_rate) \n",
        "  train_loader = DataLoader(graph_dataset, batch_size=config.batch_size, shuffle=True)\n",
        "\n",
        "  for epoch_i in range(NUM_EPOCHS):\n",
        "    loss_list = list()\n",
        "    for step, data in enumerate(train_loader):\n",
        "      data.to(DEVICE)\n",
        "      model.train()\n",
        "      model.zero_grad()\n",
        "\n",
        "      loss_for_graph = feed_data_to_model(data, model, config) # between 0 and 1, probabilty of the incorrect choice\n",
        "      loss = reduce_loss(loss_for_graph, config)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      loss =  ((loss_for_graph.mean()).item()  -0.5 ) * 2.0 # between - 0.5 and 0.5 -> between - 1 and 1\n",
        "      loss_list.append(loss)\n",
        "      #wandb.log({\"epoch\": epoch_i+1, \"loss\": np.mean(loss_list)})\n",
        "\n",
        "    print('epoch: {:06}  loss: {:.5f}'.format(epoch_i+1 ,np.mean(loss_list)))\n",
        "    # early stopping\n",
        "    if np.mean(loss_list) > -0.000001 and (epoch_i > 199 and epoch_i % 100 == 0):\n",
        "      return\n",
        "\n",
        "    if epoch_i % 20 == 0 or epoch_i == NUM_EPOCHS-1:\n",
        "      dummy_graph = graph_dataset[0].clone().to(DEVICE)\n",
        "      deg_mean, deg_var = generate_graphs(NUM_GRAPHS_GENERATE, epoch_i, model, dummy_graph, config)\n",
        "      generator_loss = (DEGREE-deg_mean)**2 + deg_var\n",
        "      wandb.log({\"graph-unmasking/gen-loss\": generator_loss, \"mean degree\": deg_mean, \"mean degree var\":deg_var, \"graph-unmasking/loss\": np.mean(loss_list)})\n",
        "      print(deg_mean, deg_var)\n",
        "    torch.save(model.state_dict(), \"model.weights\")\n",
        "    wandb.log_artifact(\"model.weights\", name=f'nn_weights_{SWEEP_ID}', type='weights') \n",
        "\n",
        "\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qPcPralV7IF0"
      },
      "outputs": [],
      "source": [
        "def start_agent_envelope():\n",
        "  try:\n",
        "    with wandb.init():\n",
        "      config = wandb.config\n",
        "      set_seeds(SWEEP_ID)\n",
        "      print(SWEEP_ID, config)\n",
        "      if not IN_COLAB:\n",
        "        for python_file in sorted(glob.glob('*.ipynb')):\n",
        "          wandb.log_artifact(python_file, name=f\"src_ipynb_{SWEEP_ID}\", type=\"my_dataset\")\n",
        "        for python_file in sorted(glob.glob('*.py')):\n",
        "          wandb.log_artifact(python_file, name=f\"src_py_{SWEEP_ID}\", type=\"my_dataset\")\n",
        "      return start_agent(config)\n",
        "  except Exception:\n",
        "    print(traceback.format_exc())\n",
        "    wandb.log({\"graph-unmasking/gen-loss\": -1,  \"epoch\": -1, \"graph-unmasking/loss\": -1})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OHuZY5f_4NrN"
      },
      "outputs": [],
      "source": [
        "os.environ[\"WANDB_MODE\"] = \"online\" #\"dryrun\"\n",
        "\n",
        "SWEEP_ID = wandb.sweep(sweep_config, project=PROJECT_NAME)\n",
        "wandb.agent(SWEEP_ID, project=PROJECT_NAME, function=start_agent_envelope, count=500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DHcAvy-w6Zlu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyM+gvhOxJmLAivUp4GPros9",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}