{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/gerritgr/MaskedGraphGen/blob/main/notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ulnOzsCCmA8g"
   },
   "source": [
    "\n",
    "# <img src=\"https://mario.wiki.gallery/images/thumb/8/89/MPS_Toad_Artwork.png/170px-MPS_Toad_Artwork.png\" alt=\"Dataset Summary\" width=\"3%\">  Batched Toad  <img src=\"https://mario.wiki.gallery/images/thumb/8/89/MPS_Toad_Artwork.png/170px-MPS_Toad_Artwork.png\" alt=\"Dataset Summary\" width=\"3%\"> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rCWLJT5DLH78"
   },
   "source": [
    "Todos:\n",
    "- weightes sampling\n",
    "- multi-channel\n",
    "- uncertainty\n",
    "- better ensable like skip one during training or learn weights\n",
    "- to make network better: virutal node, degree input, spectral input, edge \n",
    "features\n",
    "- fix order, e.g. based on degree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x-k6-4CDmEwH"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "Csn1_ff8mJCE"
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "if IN_COLAB:\n",
    "  os.system(\"pip install wandb -Uq\")\n",
    "  #!pip install torch==1.8.0+cu111 torchvision==0.9.0+cu111 torchaudio==0.8.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "  #os.system(\"pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv torch_geometric -f https://data.pyg.org/whl/torch-1.13.0+cu117.html\")\n",
    "  os.system(\"pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\")\n",
    "  os.system(\"pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\")\n",
    "  os.system(\"pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\")\n",
    "  os.system(\"pip install pyemd\")\n",
    "\n",
    "\n",
    "PATH_TO_NOTEBOOK = \"Batched Toad 3.ipynb\"\n",
    "PROJECT_NAME = \"toad_double\"\n",
    "KEY = \"e306abc657482e172a5ccc8d7c0b81bc4d297dd4\"\n",
    "WANDB_MODE = \"dryrun\"   # \"online\" or \"dryrun\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "cN9PW__MvfFk"
   },
   "outputs": [],
   "source": [
    "def get_wand_api_key():\n",
    "  api_key = KEY\n",
    "  # use   echo \"your_api_key_here\" > ~/api_key.txt   to write the api key to the home file dir    \n",
    "  if api_key != \"\":\n",
    "    return api_key\n",
    "  home_dir = os.path.expanduser('~')\n",
    "  file_path = os.path.join(home_dir, 'api_key.txt')\n",
    "  with open(file_path, 'r') as file:\n",
    "      api_key = file.read().strip()\n",
    "  return api_key\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mUcQ44Bj42GY"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "nKbKpbiSmMfW"
   },
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.dpi'] = 100 # Set this to 300 to get better image quality\n",
    "from PIL import Image # We use PIL to load images\n",
    "import seaborn as sns\n",
    "import imageio # to generate .gifs\n",
    "\n",
    "# always good to have\n",
    "import glob, random, os, traceback\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import math\n",
    "\n",
    "# the typical pytorch imports\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torch.nn import Linear as Lin\n",
    "from torch.nn import Sequential as Seq\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# PyG\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import erdos_renyi_graph, to_networkx, from_networkx\n",
    "from torch_geometric.nn import GINConv\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import global_mean_pool, global_add_pool\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "#Video\n",
    "from PIL import Image, ImageDraw\n",
    "#import cv2\n",
    "from IPython.display import HTML\n",
    "from base64 import b64encode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SAyrOuvomPAE"
   },
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZaElc28pmSzf",
    "outputId": "93b40587-aa74-40ea-b2a5-7e8b889f47a2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_NODES = 12 #12   \n",
    "DEGREE = 3 #3\n",
    "NUM_EPOCHS = 1000\n",
    "\n",
    "NUM_SAMPLES = 1000\n",
    "NUM_GRAPHS_GENERATE = 10 # 40 in compare set, but they use 10 in spectre\n",
    "\n",
    "GENERATE_X_EPOCHS = 100\n",
    "\n",
    "NO_EDGE_INDICATOR = 3.0\n",
    "EDGE_INDICATOR = 1.0 \n",
    "DUMMY = 0.0 # this node is an actual node not a placeholder for an edge\n",
    "MASK = 2.0\n",
    "NUM_CLASSES = 4  #todo change to 5 an\n",
    "\n",
    "EPSILON = 0.000000001\n",
    "\n",
    "NODE_FEATURE_EXTEND = 3\n",
    "\n",
    "# do i need this\n",
    "#BATCH_SIZE_TEST = 10\n",
    "\n",
    "#TIME_EMBEDDING_DIM = 1\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#DEVICE = torch.device('cpu')\n",
    "DEVICE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qWpdimGn3fDH"
   },
   "source": [
    "### Seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "eCtxrGI4mVz2"
   },
   "outputs": [],
   "source": [
    "# from stack overflow\n",
    "def str_to_float(s, encoding=\"utf-8\"):\n",
    "  from zlib import crc32\n",
    "  def bytes_to_float(b):\n",
    "    return float(crc32(b) & 0xffffffff) / 2**32\n",
    "  return bytes_to_float(s.encode(encoding))\n",
    "\n",
    "    \n",
    "def set_seeds(seed=42):\n",
    "  if not \"int\" in str(type(seed)):\n",
    "    seed = int(str_to_float(str(seed))*1000 % 100000000)\n",
    "  np.random.seed(seed)\n",
    "  torch.random.manual_seed(seed)\n",
    "  random.seed(seed)\n",
    "  torch.cuda.manual_seed_all(seed)\n",
    "  os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "  torch.backends.cudnn.deterministic = True\n",
    "\n",
    "set_seeds()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "32hyXlJG8360"
   },
   "source": [
    "## Weights and Biases Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i_pixfTW84rq",
    "outputId": "2d61a2f9-8b76-4999-b2a9-22f371c013d8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'method': 'random',\n",
      " 'metric': {'goal': 'minimize', 'name': 'graph-unmasking/gen-loss'},\n",
      " 'name': 'graph-unmasking',\n",
      " 'parameters': {'batch_size': {'values': [100]},\n",
      "                'candidate_selection_radius': {'values': [5]},\n",
      "                'double_inference': {'values': [True, False]},\n",
      "                'dropout': {'values': [0.0]},\n",
      "                'graph_transform': {'values': [True, False]},\n",
      "                'hidden_dim': {'values': [16, 32, 64]},\n",
      "                'hidden_layer': {'values': [4, 5, 6]},\n",
      "                'learning_rate': {'values': [1e-05, 0.0001]},\n",
      "                'loss': {'values': ['bce']},\n",
      "                'model': {'values': ['pna']},\n",
      "                'noise_probability': {'values': [0.0, 0.05, 0.1]},\n",
      "                'normalization': {'values': [True, False]},\n",
      "                'pre_post_layers': {'values': [1]},\n",
      "                'single_pass': {'values': [True]},\n",
      "                'towers': {'values': [1, 2]}}}\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login(key=get_wand_api_key())\n",
    "\n",
    "sweep_config = {\n",
    "    \"name\": \"graph-unmasking\",\n",
    "    \"method\": \"random\",\n",
    "    \"metric\": {\n",
    "        \"name\": \"graph-unmasking/gen-loss\",\n",
    "        \"goal\": \"minimize\",\n",
    "    },\n",
    "    \"parameters\": {\n",
    "        \"batch_size\": {\"values\": [100]},  # write only\n",
    "        \"hidden_dim\": {\"values\": [16,32, 64]},  \n",
    "        \"hidden_layer\": {\"values\": [4,5,6]},\n",
    "        \"learning_rate\": {\"values\": [0.00001,0.0001]},\n",
    "        \"dropout\": {\"values\": [0.0]},\n",
    "        \"normalization\": {\"values\": [True, False]},\n",
    "        \"model\": {\"values\": [\"pna\"]},  # [ \"pnamulti\", \"pna\",\"pna2\", \"attention\",\"transformer\", \"unet\"]}, \n",
    "        \"candidate_selection_radius\": {\"values\": [1, 5]},\n",
    "        \"loss\": {\"values\": [\"bce\"]},   # \"loss\": {\"values\": [\"l2\",\"l1\", \"bce\"]}, \n",
    "        \"single_pass\": {\"values\": [True]},  \n",
    "        \"towers\": {\"values\": [1, 2]},   \n",
    "        \"noise_probability\": {\"values\": [0.0, 0.05, 0.1]},\n",
    "        \"graph_transform\": {\"values\": [True, False]},    \n",
    "        \"pre_post_layers\": {\"values\": [1]},   \n",
    "        \"double_inference\": {\"values\": [True, False]}, \n",
    "    },\n",
    "}\n",
    "\n",
    "import pprint\n",
    "pprint.pprint(sweep_config)\n",
    "torch.set_printoptions(threshold=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dQyrEbzkmMCL"
   },
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "9_zto3HQmp5v"
   },
   "outputs": [],
   "source": [
    "def lift_nx_to_pyg(g_nx):\n",
    "  import torch_geometric.transforms as T\n",
    "  transform = T.Compose([T.ToUndirected()])\n",
    "\n",
    "  # g_nx has to have node_labels 0 ... number_of_nodes-1\n",
    "  num_nodes = g_nx.number_of_nodes()\n",
    "  g_complete_nx = nx.complete_graph(num_nodes)\n",
    "\n",
    "  edges_new = list()\n",
    "  node_value_dict = dict()\n",
    "  for v1, v2 in g_complete_nx.edges():\n",
    "    v3 = (v1+1)*10000+(v2+1)*100000000000\n",
    "    edges_new.append((v1, v3))\n",
    "    edges_new.append((v2, v3))\n",
    "    node_value_dict[v1] = DUMMY\n",
    "    node_value_dict[v2] = DUMMY\n",
    "    node_value_dict[v3] = EDGE_INDICATOR if g_nx.has_edge(v1,v2) else NO_EDGE_INDICATOR\n",
    "\n",
    "  graph_new = nx.from_edgelist(edges_new)\n",
    "  for node, x_value in node_value_dict.items():\n",
    "    graph_new.nodes[node]['x'] = x_value\n",
    "\n",
    "  graph_new = nx.convert_node_labels_to_integers(graph_new, ordering='sorted')\n",
    "\n",
    "  g = from_networkx(graph_new, group_node_attrs=['x'])\n",
    "  g = transform(g)  # probably unnecs.\n",
    "  return g\n",
    "\n",
    "\n",
    "def reduce_nx_graph(g_old):\n",
    "  g_new = nx.Graph()\n",
    "  for v_i in g_old.nodes():\n",
    "    if g_old.nodes[v_i]['x'] == DUMMY:\n",
    "      g_new.add_node(v_i)\n",
    "      g_new.nodes[v_i]['x'] = DUMMY\n",
    "\n",
    "  for v_i in g_old.nodes():\n",
    "    if g_old.nodes[v_i]['x'] == EDGE_INDICATOR:\n",
    "      neigh_list = list(g_old.neighbors(v_i))\n",
    "      assert(len(neigh_list) == 2)\n",
    "      g_new.add_edge(neigh_list[0], neigh_list[1])\n",
    "\n",
    "  return g_new\n",
    "\n",
    "def pyg_graph_to_nx(g_pyg):\n",
    "  g_nx = to_networkx(g_pyg, node_attrs=['x'], to_undirected=True,)\n",
    "  g_nx = reduce_nx_graph(g_nx)\n",
    "  return g_nx\n",
    "\n",
    "def draw_pyg(g_pyg, ax = None, filename = None):\n",
    "  if ax is None:\n",
    "    plt.clf()\n",
    "\n",
    "  g_nx = pyg_graph_to_nx(g_pyg)\n",
    "\n",
    "  node_labels = {i: g_nx.nodes[i]['x'] for i in g_nx.nodes}\n",
    "  pos = nx.spring_layout(g_nx, seed=1234)\n",
    "  try:\n",
    "    nx.draw(g_nx, with_labels = True, labels=node_labels, ax=ax, pos=pos)\n",
    "  except:\n",
    "    pass\n",
    "  if filename is not None:\n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "  return g_nx\n",
    "\n",
    "\n",
    "def shuffle_tensor(x):\n",
    "  x = x.clone()\n",
    "  x_shape = x.shape\n",
    "  x = x.flatten()\n",
    "  x = x[torch.randperm(x.numel())]\n",
    "  return x.reshape(x.shape)\n",
    "\n",
    "\n",
    "def note_features_to_one_hot(x):\n",
    "  # create indicator vector for NUM_CLASSES classes, values outside are set to all zeros (first to special class that then gets truncated)\n",
    "  x_cut = torch.where((x < -0.1) | (x > NUM_CLASSES-0.5), torch.tensor(NUM_CLASSES, device = DEVICE, dtype=torch.float), x)\n",
    "  x_one_hot = torch.zeros(x.shape[0], NUM_CLASSES+1, device = DEVICE)\n",
    "  x_one_hot.scatter_(1, x_cut.round().long().view(-1).unsqueeze(1), 1)\n",
    "  x_one_hot = x_one_hot[:,0:NUM_CLASSES]\n",
    "  return x_one_hot\n",
    "\n",
    "def global_mask_pool(x, x_in, batch):\n",
    "  mask_indicator = torch.lt(torch.sum(x_in, dim=1), 0.5).view(-1, 1)\n",
    "  x = x * mask_indicator\n",
    "  x = global_add_pool(x, batch)\n",
    "  return x \n",
    "\n",
    "\n",
    "def flip_edges_randomly(tensor, probability):\n",
    "  if probability < EPSILON:\n",
    "    return tensor\n",
    "\n",
    "  # Find the positions where the tensor has values 1.0 or 3.0\n",
    "  ones_positions = (tensor == EDGE_INDICATOR).to(DEVICE)\n",
    "  threes_positions = (tensor == NO_EDGE_INDICATOR).to(DEVICE)\n",
    "\n",
    "  # Generate a random binary mask for switching values\n",
    "  mask = torch.rand(tensor.shape, device=DEVICE) < probability\n",
    "\n",
    "  # Switch 1.0s to 3.0s using the random binary mask\n",
    "  tensor = torch.where(ones_positions & mask, torch.tensor(NO_EDGE_INDICATOR, device=DEVICE), tensor)\n",
    "\n",
    "  # Switch 3.0s to 1.0s using the inverted random binary mask\n",
    "  tensor = torch.where(threes_positions & mask, torch.tensor(EDGE_INDICATOR, device=DEVICE), tensor)\n",
    "\n",
    "  return tensor\n",
    "\n",
    "def extend_node_features(x, edge_index, batch):\n",
    "  assert(NODE_FEATURE_EXTEND == 3)\n",
    "\n",
    "  num_graphs = batch.max()+1\n",
    "  num_nodes = x.shape[0]\n",
    "  degree_feature = torch.zeros([num_nodes, NODE_FEATURE_EXTEND], device=DEVICE)\n",
    "  for i in range(edge_index.shape[1]):\n",
    "    src_node = edge_index[0,i]\n",
    "    target_node = edge_index[1,i]\n",
    "    # if src is real node and connection is edge indicator \n",
    "    if x[src_node, round(DUMMY)].item() > 0.5 and x[target_node, round(EDGE_INDICATOR)].item() > 0.5:\n",
    "      degree_feature[src_node,0] += 1.0\n",
    "    if x[src_node, round(DUMMY)].item() > 0.5 and x[target_node, round(MASK)].item() > 0.5:\n",
    "      degree_feature[src_node,1] += 1.0\n",
    "  for i in range(num_graphs):\n",
    "    num_mask_in_this_graph = torch.sum(x[batch == i,round(MASK)])\n",
    "    degree_feature[batch == i, 2] = num_mask_in_this_graph\n",
    "  x = torch.cat([x, degree_feature], dim=1)\n",
    "\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rEusLk_fd7hC",
    "outputId": "a378c5cb-eddf-450c-e156-4dc5ff9d4c64"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[4, 4], edge_index=[2, 8])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch_geometric.transforms as T\n",
    "transform = T.Compose([T.ToUndirected()])\n",
    "\n",
    "edge_index = torch.tensor([[0, 1, 2, 3, 1, 2, 3],\n",
    "                           [1, 2, 3, 1, 0, 1, 2]], dtype=torch.long).to(DEVICE)\n",
    "x = torch.tensor([[0,1,0,0], [1,0,0,1], [0,0,1,1], [0,1,0,0]], dtype=torch.float).to(DEVICE)\n",
    "\n",
    "data = Data(x=x, edge_index=edge_index)\n",
    "\n",
    "data = transform(data)\n",
    "data\n",
    "#extend_node_features(data.x, data.edge_index, batch=torch.zeros(data.x.shape[0], dtype=torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 516
    },
    "id": "bJ3hIT0pmBXp",
    "outputId": "e560fd6e-07fc-48f4-f758-8b7aef4850c7"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "edge_index = torch.tensor([[0, 1, 2, 3, 1, 2, 3, 1],\n",
    "                           [1, 2, 3, 1, 0, 1, 2, 3]], dtype=torch.long).to(DEVICE)\n",
    "x = torch.tensor([[-1], [0], [1], [1]], dtype=torch.float).to(DEVICE)\n",
    "\n",
    "data = Data(x=x, edge_index=edge_index)\n",
    "\n",
    "g = torch_geometric.utils.to_networkx(data, to_undirected=True, node_attrs=['x'])\n",
    "try:\n",
    "  nx.draw(g, pos=nx.spring_layout(g),  with_labels = True)\n",
    "except:\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AiLapF9HnilF",
    "outputId": "839b03a1-c60c-471e-aab3-6a510e9bd49f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Data(edge_index=[2, 24], x=[10, 1]),\n",
       " tensor([[0.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [3.],\n",
       "         [0.],\n",
       "         [3.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.]]),\n",
       " tensor([[0, 0, 0, 1, 1, 2, 2, 2, 3, 3, 4, 4, 4, 5, 5, 6, 6, 6, 7, 7, 8, 8, 9, 9],\n",
       "         [1, 3, 5, 0, 2, 1, 7, 8, 0, 4, 3, 7, 9, 0, 6, 5, 8, 9, 2, 4, 2, 6, 4, 6]]))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = lift_nx_to_pyg(g)\n",
    "data, data.x, data.edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 516
    },
    "id": "cgkOkx4amnfY",
    "outputId": "849946a8-af1e-4e85-95f4-920d9a86be26"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_pyg(data, filename='examplegraph.png')\n",
    "if IN_COLAB:\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iaElQYAbWu8M"
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FwdGZitSyjKi"
   },
   "source": [
    "### d-Regular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "mCpXui1mW9mp"
   },
   "outputs": [],
   "source": [
    "class ShuffleList:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.index = 0\n",
    "\n",
    "    def __iter__(self):\n",
    "        random.shuffle(self.data)\n",
    "        self.index = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.index < len(self.data):\n",
    "            value = self.data[self.index]\n",
    "            self.index += 1\n",
    "            return value\n",
    "        else:\n",
    "            raise StopIteration\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "IgbW4Z0tWuN1"
   },
   "outputs": [],
   "source": [
    "def build_dataset(num_nodes=NUM_NODES, num_samples=NUM_SAMPLES, degree=DEGREE, seed=1234):\n",
    "  graph_dataset = list() \n",
    "\n",
    "  for _ in range(num_samples):\n",
    "    while True:\n",
    "      seed += 1\n",
    "      graph = nx.random_regular_graph(d=degree, n=num_nodes, seed=seed)\n",
    "      if nx.is_connected(graph):\n",
    "        graph.x = torch.ones(num_nodes).t()\n",
    "        graph_dataset.append(lift_nx_to_pyg(graph))\n",
    "        break\n",
    "\n",
    "  graph_dataset_train = graph_dataset[:int(len(graph_dataset)*0.8)]\n",
    "  graph_dataset_test = graph_dataset[int(len(graph_dataset)*0.8):]\n",
    "  return ShuffleList(graph_dataset_train), ShuffleList(graph_dataset_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "3QWWQlO36fzH"
   },
   "outputs": [],
   "source": [
    "#def build_test_set_nx(seed):\n",
    "#  graph_dataset = build_dataset(num_samples=10, seed=seed)\n",
    "#  graph_dataset_nx = list()\n",
    "#  for i, g in enumerate(graph_dataset):\n",
    "#    nx_orig_graph = draw_pyg(g, filename=f\"test_graph_sample{str(i).zfill(5)}.jpg\")\n",
    "#    graph_dataset_nx.append(nx_orig_graph)\n",
    "#  return graph_dataset_nx\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 533
    },
    "id": "xKqFT6D7XHE7",
    "outputId": "394e07f2-265b-452e-e6ee-3e0356e65e6c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<networkx.classes.graph.Graph at 0x2be17bbb0>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset, _  = build_dataset()\n",
    "data = dataset[0]\n",
    "draw_pyg(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 264], x=[78, 1])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U2FUnVjG4Cwh",
    "outputId": "21044bdc-2c5c-4816-9804-267531ed3c57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1:\n",
      "=======\n",
      "Number of graphs in the current batch: 10\n",
      "DataBatch(edge_index=[2, 2640], x=[780, 1], batch=[780], ptr=[11])\n",
      "\n",
      "tensor([0., 1., 0., 1., 0., 3., 0., 1., 0., 3., 0., 3., 0., 3., 0., 3., 0., 3.,\n",
      "        0., 3., 0., 3., 0., 1., 3., 3., 3., 3., 3., 3., 3., 3., 1., 3., 3., 3.,\n",
      "        3., 3., 3., 3., 1., 3., 3., 1., 3., 3., 3., 1., 1., 3., 1., 3., 3., 1.,\n",
      "        3., 3., 3., 3., 3., 1., 3., 3., 3., 1., 3., 1., 3., 1., 1., 3., 3., 1.,\n",
      "        3., 3., 3., 1., 3., 3., 0., 3., 0., 3., 0., 1., 0., 1., 0., 3., 0., 3.,\n",
      "        0., 3., 0., 3., 0., 3., 0., 1., 0., 3., 0., 3., 3., 3., 3., 1., 3., 1.,\n",
      "        3., 3., 1., 3., 3., 1., 1., 3., 3., 3., 3., 1., 3., 3., 3., 3., 1., 1.,\n",
      "        3., 3., 3., 3., 1., 1., 3., 3., 3., 3., 3., 3., 1., 1., 3., 1., 3., 3.,\n",
      "        3., 3., 3., 3., 3., 1., 3., 3., 3., 1., 3., 3., 0., 3., 0., 3., 0., 3.,\n",
      "        0., 3., 0., 3., 0., 1., 0., 1., 0., 3., 0., 3., 0., 3., 0., 1., 0., 3.,\n",
      "        3., 1., 1., 3., 3., 3., 3., 3., 1., 3., 3., 3., 3., 3., 1., 1., 3., 1.,\n",
      "        3., 3., 1., 3., 3., 1., 1., 3., 1., 3., 3., 3., 3., 1., 3., 3., 1., 3.,\n",
      "        3., 3., 3., 3., 3., 1., 3., 3., 1., 3., 3., 3., 3., 1., 3., 3., 3., 3.,\n",
      "        0., 3., 0., 1., 0., 3., 0., 3., 0., 3., 0., 1., 0., 3., 0., 3., 0., 3.,\n",
      "        0., 1., 0., 3., 0., 3., 3., 3., 1., 3., 3., 1., 3., 3., 1., 3., 3., 1.,\n",
      "        3., 3., 3., 3., 1., 3., 3., 1., 3., 3., 1., 1., 3., 3., 3., 1., 1., 3.,\n",
      "        3., 3., 1., 3., 3., 3., 3., 3., 3., 3., 3., 1., 3., 3., 3., 1., 1., 3.,\n",
      "        3., 3., 1., 3., 3., 3., 0., 1., 0., 1., 0., 3., 0., 3., 0., 3., 0., 3.,\n",
      "        0., 3., 0., 1., 0., 3., 0., 3., 0., 3., 0., 3., 1., 1., 3., 3., 3., 3.,\n",
      "        3., 3., 3., 1., 3., 3., 3., 3., 3., 3., 3., 1., 3., 1., 3., 3., 3., 3.,\n",
      "        3., 3., 3., 3., 3., 1., 1., 3., 3., 3., 1., 3., 3., 1., 3., 1., 1., 3.,\n",
      "        1., 3., 3., 1., 3., 3., 3., 3., 3., 3., 1., 1., 0., 1., 0., 3., 0., 1.,\n",
      "        0., 3., 0., 3., 0., 3., 0., 3., 0., 3., 0., 1., 0., 3., 0., 3., 0., 3.,\n",
      "        3., 3., 3., 3., 3., 1., 1., 3., 3., 3., 3., 3., 3., 1., 3., 1., 3., 1.,\n",
      "        1., 3., 3., 3., 3., 3., 3., 1., 3., 1., 3., 3., 3., 1., 3., 3., 1., 3.,\n",
      "        3., 1., 1., 3., 1., 3., 1., 3., 1., 3., 3., 3., 3., 3., 3., 3., 3., 3.,\n",
      "        0., 3., 0., 1., 0., 3., 0., 3., 0., 1., 0., 1., 0., 3., 0., 3., 0., 3.,\n",
      "        0., 3., 0., 3., 0., 3., 3., 3., 3., 3., 1., 1., 3., 3., 1., 3., 3., 3.,\n",
      "        3., 3., 3., 3., 1., 1., 1., 3., 3., 3., 3., 1., 1., 3., 3., 1., 3., 3.,\n",
      "        1., 3., 3., 1., 1., 3., 3., 3., 3., 3., 3., 3., 3., 3., 1., 3., 3., 3.,\n",
      "        3., 3., 1., 1., 3., 3., 0., 3., 0., 1., 0., 3., 0., 3., 0., 3., 0., 3.,\n",
      "        0., 3., 0., 3., 0., 1., 0., 3., 0., 1., 0., 3., 3., 3., 3., 3., 3., 3.,\n",
      "        1., 1., 1., 1., 1., 3., 3., 3., 3., 3., 3., 3., 1., 3., 1., 3., 3., 3.,\n",
      "        3., 3., 3., 3., 1., 3., 3., 3., 3., 1., 3., 1., 3., 3., 1., 3., 1., 3.,\n",
      "        3., 3., 3., 1., 1., 3., 3., 1., 3., 3., 3., 3., 0., 3., 0., 1., 0., 1.,\n",
      "        0., 3., 0., 3., 0., 1., 0., 3., 0., 3., 0., 3., 0., 3., 0., 3., 0., 1.,\n",
      "        3., 3., 3., 3., 3., 1., 3., 1., 3., 3., 3., 3., 3., 1., 3., 3., 3., 3.,\n",
      "        1., 3., 3., 3., 1., 3., 3., 3., 1., 3., 3., 3., 1., 3., 3., 3., 3., 3.,\n",
      "        1., 3., 1., 1., 1., 3., 3., 3., 3., 3., 3., 1., 3., 3., 3., 1., 3., 1.,\n",
      "        0., 3., 0., 3., 0., 1., 0., 1., 0., 1., 0., 3., 0., 3., 0., 3., 0., 3.,\n",
      "        0., 3., 0., 3., 0., 1., 1., 3., 3., 3., 3., 3., 3., 3., 1., 3., 3., 3.,\n",
      "        3., 1., 3., 1., 3., 3., 3., 3., 1., 3., 3., 3., 3., 3., 3., 1., 3., 3.,\n",
      "        3., 3., 1., 3., 1., 3., 3., 1., 3., 3., 1., 3., 3., 3., 3., 1., 3., 3.,\n",
      "        3., 1., 1., 1., 3., 3.]) tensor([[  0,   0,   0,  ..., 778, 779, 779],\n",
      "        [  1,   3,   5,  ..., 724, 722, 724]]) tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7,\n",
      "        7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
      "        7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
      "        7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
      "        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
      "        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
      "        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
      "        8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
      "        9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
      "        9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
      "        9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9])\n"
     ]
    }
   ],
   "source": [
    "# TODO dataloader\n",
    "from torch_geometric.loader import DataLoader\n",
    "train_loader = DataLoader(dataset, batch_size=10, shuffle=True)\n",
    "for step, data in enumerate(train_loader):\n",
    "  print(f'Step {step + 1}:')\n",
    "  print('=======')\n",
    "  print(f'Number of graphs in the current batch: {data.num_graphs}')\n",
    "  print(data)\n",
    "  print()\n",
    "  print(data.x.flatten(), data.edge_index, data.batch)\n",
    "  break\n",
    "\n",
    "\n",
    "# for gen of training sample:\n",
    "# 1) mask 0 ... (all -1) (inclusivly) \n",
    "# 2) swich exactly 1 of the unmasked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AS8w-Xw0ynzU"
   },
   "source": [
    "### Planar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nlDyM555ypd8",
    "outputId": "5e2d2606-b605-4dbc-9fe0-f53679663f15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset sizes: train 128, val 32, test 40\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<__main__.ShuffleList at 0x2d033de20>, <__main__.ShuffleList at 0x2d033d370>)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from torch.utils.data import random_split, Dataset\n",
    "import torch_geometric.utils\n",
    "\n",
    "def load_dataset_planar():\n",
    "  nx_set = list()\n",
    "  num_nodes = 64\n",
    "  graph_dataset = list() \n",
    "  if not os.path.exists(\"SPECTRE\"):\n",
    "    os.system(\"git clone https://github.com/KarolisMart/SPECTRE.git\")\n",
    "  adjs, eigvals, eigvecs, n_nodes, max_eigval, min_eigval, same_sample, n_max = torch.load('SPECTRE/data/planar_64_200.pt')\n",
    "  for adj in adjs:\n",
    "    # from adj matrix to nx\n",
    "    graph = nx.from_numpy_array(adj.numpy())\n",
    "    # from nx to pyg\n",
    "    graph.x = torch.ones(num_nodes).t()\n",
    "    graph_dataset.append(lift_nx_to_pyg(graph))\n",
    "\n",
    "  #graph_dataset_train = graph_dataset[:int(len(graph_dataset)*0.8)]\n",
    "  #graph_dataset_test = graph_dataset[int(len(graph_dataset)*0.8):]\n",
    "  #return ShuffleList(graph_dataset_train), ShuffleList(graph_dataset_test)\n",
    "\n",
    "  test_len = int(round(len(graph_dataset) * 0.2))\n",
    "  train_len = int(round((len(graph_dataset) - test_len) * 0.8))\n",
    "  val_len = len(graph_dataset) - train_len - test_len\n",
    "  print(f'Dataset sizes: train {train_len}, val {val_len}, test {test_len}')\n",
    "  splits = random_split(graph_dataset, [train_len, val_len, test_len], generator=torch.Generator().manual_seed(1234))\n",
    "  datasets = {'train': splits[0], 'val': splits[1], 'test': splits[2]}\n",
    "  return ShuffleList(list(datasets['train'])), ShuffleList(list(datasets['test']))\n",
    "\n",
    "\n",
    "load_dataset_planar()  # get baseline by comparing 128 with 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lvjLUJSMUb_E",
    "outputId": "eca6abe4-e963-4351-f674-d455b270c2de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset sizes: train 128, val 32, test 40\n"
     ]
    }
   ],
   "source": [
    "graph_dataset, _ = load_dataset_planar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5OIcsvOpU9AC",
    "outputId": "b342f4ab-7be5-4074-8bf1-8aad297761e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Data(edge_index=[2, 8064], x=[2080, 1]),\n",
       " Data(edge_index=[2, 8064], x=[2080, 1]))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_dataset[0],graph_dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "obBv2OMEWaKA"
   },
   "outputs": [],
   "source": [
    "#draw_pyg(graph_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "78c_wYnEiPAx"
   },
   "source": [
    "### Block\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T2Wp0Za7iSzn",
    "outputId": "bab4242a-1963-4de7-a4b6-b6ff07858958"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nodes  172\n",
      "number of nodes  92\n",
      "number of nodes  61\n",
      "number of nodes  64\n",
      "number of nodes  115\n",
      "number of nodes  101\n",
      "number of nodes  90\n",
      "number of nodes  123\n",
      "number of nodes  168\n",
      "number of nodes  61\n",
      "number of nodes  130\n",
      "number of nodes  62\n",
      "number of nodes  163\n",
      "number of nodes  58\n",
      "number of nodes  71\n",
      "number of nodes  156\n",
      "number of nodes  77\n",
      "number of nodes  169\n",
      "number of nodes  141\n",
      "number of nodes  103\n",
      "number of nodes  89\n",
      "number of nodes  81\n",
      "number of nodes  88\n",
      "number of nodes  164\n",
      "number of nodes  88\n",
      "number of nodes  117\n",
      "number of nodes  128\n",
      "number of nodes  69\n",
      "number of nodes  64\n",
      "number of nodes  58\n",
      "number of nodes  152\n",
      "number of nodes  97\n",
      "number of nodes  166\n",
      "number of nodes  101\n",
      "number of nodes  106\n",
      "number of nodes  57\n",
      "number of nodes  76\n",
      "number of nodes  115\n",
      "number of nodes  52\n",
      "number of nodes  112\n",
      "number of nodes  64\n",
      "number of nodes  63\n",
      "number of nodes  169\n",
      "number of nodes  54\n",
      "number of nodes  90\n",
      "number of nodes  129\n",
      "number of nodes  105\n",
      "number of nodes  53\n",
      "number of nodes  53\n",
      "number of nodes  55\n",
      "number of nodes  53\n",
      "number of nodes  88\n",
      "number of nodes  65\n",
      "number of nodes  127\n",
      "number of nodes  77\n",
      "number of nodes  94\n",
      "number of nodes  57\n",
      "number of nodes  139\n",
      "number of nodes  56\n",
      "number of nodes  148\n",
      "number of nodes  79\n",
      "number of nodes  58\n",
      "number of nodes  94\n",
      "number of nodes  112\n",
      "number of nodes  99\n",
      "number of nodes  89\n",
      "number of nodes  75\n",
      "number of nodes  137\n",
      "number of nodes  63\n",
      "number of nodes  115\n",
      "number of nodes  159\n",
      "number of nodes  74\n",
      "number of nodes  72\n",
      "number of nodes  129\n",
      "number of nodes  124\n",
      "number of nodes  72\n",
      "number of nodes  99\n",
      "number of nodes  166\n",
      "number of nodes  164\n",
      "number of nodes  160\n",
      "number of nodes  80\n",
      "number of nodes  61\n",
      "number of nodes  138\n",
      "number of nodes  78\n",
      "number of nodes  83\n",
      "number of nodes  167\n",
      "number of nodes  147\n",
      "number of nodes  70\n",
      "number of nodes  99\n",
      "number of nodes  91\n",
      "number of nodes  60\n",
      "number of nodes  135\n",
      "number of nodes  73\n",
      "number of nodes  139\n",
      "number of nodes  97\n",
      "number of nodes  84\n",
      "number of nodes  113\n",
      "number of nodes  73\n",
      "number of nodes  157\n",
      "number of nodes  102\n",
      "number of nodes  123\n",
      "number of nodes  125\n",
      "number of nodes  127\n",
      "number of nodes  79\n",
      "number of nodes  106\n",
      "number of nodes  81\n",
      "number of nodes  122\n",
      "number of nodes  71\n",
      "number of nodes  120\n",
      "number of nodes  76\n",
      "number of nodes  85\n",
      "number of nodes  98\n",
      "number of nodes  55\n",
      "number of nodes  142\n",
      "number of nodes  168\n",
      "number of nodes  161\n",
      "number of nodes  52\n",
      "number of nodes  92\n",
      "number of nodes  163\n",
      "number of nodes  187\n",
      "number of nodes  90\n",
      "number of nodes  144\n",
      "number of nodes  59\n",
      "number of nodes  157\n",
      "number of nodes  129\n",
      "number of nodes  44\n",
      "number of nodes  163\n",
      "number of nodes  162\n",
      "number of nodes  64\n",
      "number of nodes  157\n",
      "number of nodes  93\n",
      "number of nodes  143\n",
      "number of nodes  61\n",
      "number of nodes  80\n",
      "number of nodes  91\n",
      "number of nodes  91\n",
      "number of nodes  127\n",
      "number of nodes  87\n",
      "number of nodes  82\n",
      "number of nodes  102\n",
      "number of nodes  67\n",
      "number of nodes  164\n",
      "number of nodes  97\n",
      "number of nodes  92\n",
      "number of nodes  140\n",
      "number of nodes  104\n",
      "epoch: 000070  loss: -0.25569\n",
      "number of nodes  165\n",
      "number of nodes  62\n",
      "number of nodes  69\n",
      "number of nodes  156\n",
      "number of nodes  61\n",
      "number of nodes  85\n",
      "number of nodes  55\n",
      "number of nodes  59\n",
      "number of nodes  144\n",
      "number of nodes  132\n",
      "number of nodes  141\n",
      "number of nodes  56\n",
      "number of nodes  169\n",
      "number of nodes  125\n",
      "number of nodes  158\n",
      "number of nodes  58\n",
      "number of nodes  61\n",
      "number of nodes  141\n",
      "number of nodes  60\n",
      "number of nodes  102\n",
      "number of nodes  134\n",
      "number of nodes  69\n",
      "number of nodes  94\n",
      "number of nodes  174\n",
      "number of nodes  64\n",
      "number of nodes  116\n",
      "number of nodes  141\n",
      "number of nodes  63\n",
      "number of nodes  75\n",
      "number of nodes  149\n",
      "number of nodes  152\n",
      "number of nodes  110\n",
      "number of nodes  107\n",
      "number of nodes  100\n",
      "number of nodes  84\n",
      "number of nodes  116\n",
      "number of nodes  105\n",
      "number of nodes  109\n",
      "number of nodes  141\n",
      "number of nodes  64\n",
      "number of nodes  67\n",
      "number of nodes  125\n",
      "number of nodes  69\n",
      "number of nodes  103\n",
      "number of nodes  174\n",
      "number of nodes  139\n",
      "number of nodes  180\n",
      "number of nodes  49\n",
      "number of nodes  55\n",
      "number of nodes  119\n",
      "number of nodes  76\n",
      "number of nodes  139\n",
      "number of nodes  85\n",
      "number of nodes  90\n",
      "Dataset sizes: train 128, val 32, test 40\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<__main__.ShuffleList at 0x17f1b90a0>, <__main__.ShuffleList at 0x17f1b9580>)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_dataset_block():\n",
    "  nx_set = list()\n",
    "  num_nodes = 64\n",
    "  graph_dataset = list() \n",
    "  if not os.path.exists(\"SPECTRE\"):\n",
    "    os.system(\"git clone https://github.com/KarolisMart/SPECTRE.git\")\n",
    "  adjs, eigvals, eigvecs, n_nodes, max_eigval, min_eigval, same_sample, n_max = torch.load('SPECTRE/data/sbm_200.pt')\n",
    "  for adj in adjs:\n",
    "    # from adj matrix to nx\n",
    "    graph = nx.from_numpy_array(adj.numpy())\n",
    "    print('number of nodes ', graph.number_of_nodes())\n",
    "    # from nx to pyg\n",
    "    graph.x = torch.ones(num_nodes).t()\n",
    "    graph_dataset.append(lift_nx_to_pyg(graph))\n",
    "\n",
    "  #graph_dataset_train = graph_dataset[:int(len(graph_dataset)*0.8)]\n",
    "  #graph_dataset_test = graph_dataset[int(len(graph_dataset)*0.8):]\n",
    "  #return ShuffleList(graph_dataset_train), ShuffleList(graph_dataset_test)\n",
    "\n",
    "  test_len = int(round(len(graph_dataset) * 0.2))\n",
    "  train_len = int(round((len(graph_dataset) - test_len) * 0.8))\n",
    "  val_len = len(graph_dataset) - train_len - test_len\n",
    "  print(f'Dataset sizes: train {train_len}, val {val_len}, test {test_len}')\n",
    "  splits = random_split(graph_dataset, [train_len, val_len, test_len], generator=torch.Generator().manual_seed(1234))\n",
    "  datasets = {'train': splits[0], 'val': splits[1], 'test': splits[2]}\n",
    "  return ShuffleList(list(datasets['train'])), ShuffleList(list(datasets['test']))\n",
    "\n",
    "\n",
    "load_dataset_block()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LlPP_ASmqHrQ",
    "outputId": "53905ab3-d656-45c3-da51-e3361fc27e64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nodes  172\n",
      "number of nodes  92\n",
      "number of nodes  61\n",
      "number of nodes  64\n",
      "number of nodes  115\n",
      "number of nodes  101\n",
      "number of nodes  90\n",
      "number of nodes  123\n",
      "number of nodes  168\n",
      "number of nodes  61\n",
      "number of nodes  130\n",
      "number of nodes  62\n",
      "number of nodes  163\n",
      "number of nodes  58\n",
      "number of nodes  71\n",
      "number of nodes  156\n",
      "number of nodes  77\n",
      "number of nodes  169\n",
      "number of nodes  141\n",
      "number of nodes  103\n",
      "number of nodes  89\n",
      "number of nodes  81\n",
      "number of nodes  88\n",
      "number of nodes  164\n",
      "number of nodes  88\n",
      "number of nodes  117\n",
      "number of nodes  128\n",
      "number of nodes  69\n",
      "number of nodes  64\n",
      "number of nodes  58\n",
      "number of nodes  152\n",
      "number of nodes  97\n",
      "number of nodes  166\n",
      "number of nodes  101\n",
      "number of nodes  106\n",
      "number of nodes  57\n",
      "number of nodes  76\n",
      "number of nodes  115\n",
      "number of nodes  52\n",
      "number of nodes  112\n",
      "number of nodes  64\n",
      "number of nodes  63\n",
      "number of nodes  169\n",
      "number of nodes  54\n",
      "number of nodes  90\n",
      "number of nodes  129\n",
      "number of nodes  105\n",
      "number of nodes  53\n",
      "number of nodes  53\n",
      "number of nodes  55\n",
      "number of nodes  53\n",
      "number of nodes  88\n",
      "number of nodes  65\n",
      "number of nodes  127\n",
      "number of nodes  77\n",
      "number of nodes  94\n",
      "number of nodes  57\n",
      "number of nodes  139\n",
      "number of nodes  56\n",
      "number of nodes  148\n",
      "number of nodes  79\n",
      "number of nodes  58\n",
      "number of nodes  94\n",
      "number of nodes  112\n",
      "number of nodes  99\n",
      "number of nodes  89\n",
      "number of nodes  75\n",
      "number of nodes  137\n",
      "number of nodes  63\n",
      "number of nodes  115\n",
      "number of nodes  159\n",
      "number of nodes  74\n",
      "number of nodes  72\n",
      "number of nodes  129\n",
      "number of nodes  124\n",
      "number of nodes  72\n",
      "number of nodes  99\n",
      "number of nodes  166\n",
      "number of nodes  164\n",
      "number of nodes  160\n",
      "number of nodes  80\n",
      "number of nodes  61\n",
      "number of nodes  138\n",
      "number of nodes  78\n",
      "number of nodes  83\n",
      "number of nodes  167\n",
      "number of nodes  147\n",
      "number of nodes  70\n",
      "number of nodes  99\n",
      "number of nodes  91\n",
      "number of nodes  60\n",
      "number of nodes  135\n",
      "number of nodes  73\n",
      "number of nodes  139\n",
      "number of nodes  97\n",
      "number of nodes  84\n",
      "number of nodes  113\n",
      "number of nodes  73\n",
      "number of nodes  157\n",
      "number of nodes  102\n",
      "number of nodes  123\n",
      "number of nodes  125\n",
      "number of nodes  127\n",
      "number of nodes  79\n",
      "number of nodes  106\n",
      "number of nodes  81\n",
      "number of nodes  122\n",
      "number of nodes  71\n",
      "number of nodes  120\n",
      "number of nodes  76\n",
      "number of nodes  85\n",
      "number of nodes  98\n",
      "number of nodes  55\n",
      "number of nodes  142\n",
      "number of nodes  168\n",
      "number of nodes  161\n",
      "number of nodes  52\n",
      "number of nodes  92\n",
      "number of nodes  163\n",
      "number of nodes  187\n",
      "number of nodes  90\n",
      "number of nodes  144\n",
      "number of nodes  59\n",
      "number of nodes  157\n",
      "number of nodes  129\n",
      "number of nodes  44\n",
      "number of nodes  163\n",
      "number of nodes  162\n",
      "number of nodes  64\n",
      "number of nodes  157\n",
      "number of nodes  93\n",
      "number of nodes  143\n",
      "number of nodes  61\n",
      "number of nodes  80\n",
      "number of nodes  91\n",
      "number of nodes  91\n",
      "number of nodes  127\n",
      "number of nodes  87\n",
      "number of nodes  82\n",
      "number of nodes  102\n",
      "number of nodes  67\n",
      "number of nodes  164\n",
      "number of nodes  97\n",
      "number of nodes  92\n",
      "number of nodes  140\n",
      "number of nodes  104\n",
      "number of nodes  165\n",
      "number of nodes  62\n",
      "number of nodes  69\n",
      "number of nodes  156\n",
      "number of nodes  61\n",
      "number of nodes  85\n",
      "number of nodes  55\n",
      "number of nodes  59\n",
      "number of nodes  144\n",
      "number of nodes  132\n",
      "number of nodes  141\n",
      "number of nodes  56\n",
      "number of nodes  169\n",
      "number of nodes  125\n",
      "number of nodes  158\n",
      "number of nodes  58\n",
      "number of nodes  61\n",
      "number of nodes  141\n",
      "number of nodes  60\n",
      "number of nodes  102\n",
      "number of nodes  134\n",
      "number of nodes  69\n",
      "number of nodes  94\n",
      "number of nodes  174\n",
      "number of nodes  64\n",
      "number of nodes  116\n",
      "number of nodes  141\n",
      "number of nodes  63\n",
      "number of nodes  75\n",
      "number of nodes  149\n",
      "number of nodes  152\n",
      "number of nodes  110\n",
      "number of nodes  107\n",
      "number of nodes  100\n",
      "number of nodes  84\n",
      "number of nodes  116\n",
      "number of nodes  105\n",
      "number of nodes  109\n",
      "number of nodes  141\n",
      "number of nodes  64\n",
      "number of nodes  67\n",
      "number of nodes  125\n",
      "number of nodes  69\n",
      "number of nodes  103\n",
      "number of nodes  174\n",
      "number of nodes  139\n",
      "number of nodes  180\n",
      "number of nodes  49\n",
      "number of nodes  55\n",
      "number of nodes  119\n",
      "number of nodes  76\n",
      "number of nodes  139\n",
      "number of nodes  85\n",
      "number of nodes  90\n",
      "Dataset sizes: train 128, val 32, test 40\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.ShuffleList at 0x17fdbe640>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,_ = load_dataset_block()\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "97PuI5WRyX9n",
    "outputId": "c5e4ea88-eba3-471c-e1ad-a1153961c641"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 44104], x=[11175, 1])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VL2Kr3jD-WwW"
   },
   "source": [
    "## Loss & Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "4bFAJnqX-ZO_"
   },
   "outputs": [],
   "source": [
    "import pyemd\n",
    "import numpy as np\n",
    "import concurrent.futures\n",
    "from functools import partial\n",
    "from scipy.linalg import toeplitz\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "PRINT_TIME = False\n",
    "\n",
    "def degree_worker(G):\n",
    "    return np.array(nx.degree_histogram(G))\n",
    "\n",
    "def degree_stats(graph_ref_list, graph_pred_list, is_parallel=True, compute_emd=False):\n",
    "    ''' Compute the distance between the degree distributions of two unordered sets of graphs.\n",
    "        Args:\n",
    "            graph_ref_list, graph_target_list: two lists of networkx graphs to be evaluated\n",
    "        '''\n",
    "    sample_ref = []\n",
    "    sample_pred = []\n",
    "    # in case an empty graph is generated\n",
    "    graph_pred_list_remove_empty = [\n",
    "        G for G in graph_pred_list if not G.number_of_nodes() == 0\n",
    "    ]\n",
    "\n",
    "    prev = datetime.now()\n",
    "    if is_parallel:\n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            for deg_hist in executor.map(degree_worker, graph_ref_list):\n",
    "                sample_ref.append(deg_hist)\n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            for deg_hist in executor.map(degree_worker, graph_pred_list_remove_empty):\n",
    "                sample_pred.append(deg_hist)\n",
    "    else:\n",
    "        for i in range(len(graph_ref_list)):\n",
    "            degree_temp = np.array(nx.degree_histogram(graph_ref_list[i]))\n",
    "            sample_ref.append(degree_temp)\n",
    "        for i in range(len(graph_pred_list_remove_empty)):\n",
    "            degree_temp = np.array(\n",
    "                nx.degree_histogram(graph_pred_list_remove_empty[i]))\n",
    "            sample_pred.append(degree_temp)\n",
    "\n",
    "    # mmd_dist = compute_mmd(sample_ref, sample_pred, kernel=gaussian_emd)\n",
    "    # mmd_dist = compute_mmd(sample_ref, sample_pred, kernel=emd)\n",
    "    if compute_emd:\n",
    "        # EMD option uses the same computation as GraphRNN, the alternative is MMD as computed by GRAN\n",
    "        # mmd_dist = compute_mmd(sample_ref, sample_pred, kernel=emd)\n",
    "        mmd_dist = compute_mmd(sample_ref, sample_pred, kernel=gaussian_emd)\n",
    "    else:\n",
    "        mmd_dist = compute_mmd(sample_ref, sample_pred, kernel=gaussian_tv)\n",
    "    # mmd_dist = compute_mmd(sample_ref, sample_pred, kernel=gaussian)\n",
    "\n",
    "    elapsed = datetime.now() - prev\n",
    "    if PRINT_TIME:\n",
    "        print('Time computing degree mmd: ', elapsed)\n",
    "    return mmd_dist\n",
    "\n",
    "\n",
    "\n",
    "def clustering_worker(param):\n",
    "    G, bins = param\n",
    "    clustering_coeffs_list = list(nx.clustering(G).values())\n",
    "    hist, _ = np.histogram(\n",
    "        clustering_coeffs_list, bins=bins, range=(0.0, 1.0), density=False)\n",
    "    return hist\n",
    "\n",
    "\n",
    "def clustering_stats(graph_ref_list,\n",
    "                     graph_pred_list,\n",
    "                     bins=100,\n",
    "                     is_parallel=True, compute_emd=False):\n",
    "    sample_ref = []\n",
    "    sample_pred = []\n",
    "    graph_pred_list_remove_empty = [\n",
    "        G for G in graph_pred_list if not G.number_of_nodes() == 0\n",
    "    ]\n",
    "\n",
    "    prev = datetime.now()\n",
    "    if is_parallel:\n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            for clustering_hist in executor.map(clustering_worker,\n",
    "                                                [(G, bins) for G in graph_ref_list]):\n",
    "                sample_ref.append(clustering_hist)\n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            for clustering_hist in executor.map(\n",
    "                    clustering_worker, [(G, bins) for G in graph_pred_list_remove_empty]):\n",
    "                sample_pred.append(clustering_hist)\n",
    "\n",
    "        # check non-zero elements in hist\n",
    "        # total = 0\n",
    "        # for i in range(len(sample_pred)):\n",
    "        #    nz = np.nonzero(sample_pred[i])[0].shape[0]\n",
    "        #    total += nz\n",
    "        # print(total)\n",
    "    else:\n",
    "        for i in range(len(graph_ref_list)):\n",
    "            clustering_coeffs_list = list(nx.clustering(graph_ref_list[i]).values())\n",
    "            hist, _ = np.histogram(\n",
    "                clustering_coeffs_list, bins=bins, range=(0.0, 1.0), density=False)\n",
    "            sample_ref.append(hist)\n",
    "\n",
    "        for i in range(len(graph_pred_list_remove_empty)):\n",
    "            clustering_coeffs_list = list(\n",
    "                nx.clustering(graph_pred_list_remove_empty[i]).values())\n",
    "            hist, _ = np.histogram(\n",
    "                clustering_coeffs_list, bins=bins, range=(0.0, 1.0), density=False)\n",
    "            sample_pred.append(hist)\n",
    "\n",
    "    if compute_emd:\n",
    "        # EMD option uses the same computation as GraphRNN, the alternative is MMD as computed by GRAN\n",
    "        # mmd_dist = compute_mmd(sample_ref, sample_pred, kernel=emd, sigma=1.0 / 10)\n",
    "        mmd_dist = compute_mmd(sample_ref, sample_pred, kernel=gaussian_emd, sigma=1.0 / 10, distance_scaling=bins)\n",
    "    else:\n",
    "        mmd_dist = compute_mmd(sample_ref, sample_pred, kernel=gaussian_tv, sigma=1.0 / 10)\n",
    "\n",
    "    elapsed = datetime.now() - prev\n",
    "    if PRINT_TIME:\n",
    "        print('Time computing clustering mmd: ', elapsed)\n",
    "    return mmd_dist\n",
    "\n",
    "\n",
    "\n",
    "# maps motif/orbit name string to its corresponding list of indices from orca output\n",
    "motif_to_indices = {\n",
    "    '3path': [1, 2],\n",
    "    '4cycle': [8],\n",
    "}\n",
    "COUNT_START_STR = 'orbit counts:'\n",
    "\n",
    "\n",
    "def edge_list_reindexed(G):\n",
    "    idx = 0\n",
    "    id2idx = dict()\n",
    "    for u in G.nodes():\n",
    "        id2idx[str(u)] = idx\n",
    "        idx += 1\n",
    "\n",
    "    edges = []\n",
    "    for (u, v) in G.edges():\n",
    "        edges.append((id2idx[str(u)], id2idx[str(v)]))\n",
    "    return edges\n",
    "\n",
    "def orca(graph):\n",
    "    # tmp_fname = f'analysis/orca/tmp_{\"\".join(secrets.choice(ascii_uppercase + digits) for i in range(8))}.txt'\n",
    "    tmp_fname = f'orca/tmp_{\"\".join(secrets.choice(ascii_uppercase + digits) for i in range(8))}.txt'\n",
    "    tmp_fname = os.path.join(os.path.dirname(os.path.realpath(__file__)), tmp_fname)\n",
    "    # print(tmp_fname, flush=True)\n",
    "    f = open(tmp_fname, 'w')\n",
    "    f.write(\n",
    "        str(graph.number_of_nodes()) + ' ' + str(graph.number_of_edges()) + '\\n')\n",
    "    for (u, v) in edge_list_reindexed(graph):\n",
    "        f.write(str(u) + ' ' + str(v) + '\\n')\n",
    "    f.close()\n",
    "    output = sp.check_output(\n",
    "        [str(os.path.join(os.path.dirname(os.path.realpath(__file__)), 'orca/orca')), 'node', '4', tmp_fname, 'std'])\n",
    "    output = output.decode('utf8').strip()\n",
    "    idx = output.find(COUNT_START_STR) + len(COUNT_START_STR) + 2\n",
    "    output = output[idx:]\n",
    "    node_orbit_counts = np.array([\n",
    "        list(map(int,\n",
    "                 node_cnts.strip().split(' ')))\n",
    "        for node_cnts in output.strip('\\n').split('\\n')\n",
    "    ])\n",
    "\n",
    "    try:\n",
    "        os.remove(tmp_fname)\n",
    "    except OSError:\n",
    "        pass\n",
    "\n",
    "    return node_orbit_counts\n",
    "\n",
    "\n",
    "def orbit_stats_all(graph_ref_list, graph_pred_list, compute_emd=False):\n",
    "    total_counts_ref = []\n",
    "    total_counts_pred = []\n",
    "\n",
    "    graph_pred_list_remove_empty = [\n",
    "        G for G in graph_pred_list if not G.number_of_nodes() == 0\n",
    "    ]\n",
    "\n",
    "    for G in graph_ref_list:\n",
    "        orbit_counts = orca(G)\n",
    "        orbit_counts_graph = np.sum(orbit_counts, axis=0) / G.number_of_nodes()\n",
    "        total_counts_ref.append(orbit_counts_graph)\n",
    "\n",
    "    for G in graph_pred_list:\n",
    "        orbit_counts = orca(G)\n",
    "        orbit_counts_graph = np.sum(orbit_counts, axis=0) / G.number_of_nodes()\n",
    "        total_counts_pred.append(orbit_counts_graph)\n",
    "\n",
    "    total_counts_ref = np.array(total_counts_ref)\n",
    "    total_counts_pred = np.array(total_counts_pred)\n",
    "\n",
    "    # mmd_dist = compute_mmd(\n",
    "    #     total_counts_ref,\n",
    "    #     total_counts_pred,\n",
    "    #     kernel=gaussian,\n",
    "    #     is_hist=False,\n",
    "    #     sigma=30.0)\n",
    "\n",
    "    # mmd_dist = compute_mmd(\n",
    "    #         total_counts_ref,\n",
    "    #         total_counts_pred,\n",
    "    #         kernel=gaussian_tv,\n",
    "    #         is_hist=False,\n",
    "    #         sigma=30.0)  \n",
    "\n",
    "    if compute_emd:\n",
    "        # mmd_dist = compute_mmd(total_counts_ref, total_counts_pred, kernel=emd, sigma=30.0)\n",
    "        # EMD option uses the same computation as GraphRNN, the alternative is MMD as computed by GRAN\n",
    "        mmd_dist = compute_mmd(total_counts_ref, total_counts_pred, kernel=gaussian, is_hist=False, sigma=30.0)\n",
    "    else:\n",
    "        mmd_dist = compute_mmd(total_counts_ref, total_counts_pred, kernel=gaussian_tv, is_hist=False, sigma=30.0)\n",
    "    return mmd_dist\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def gaussian(x, y, sigma=1.0):\n",
    "    support_size = max(len(x), len(y))\n",
    "    # convert histogram values x and y to float, and make them equal len\n",
    "    x = x.astype(float)\n",
    "    y = y.astype(float)\n",
    "    if len(x) < len(y):\n",
    "        x = np.hstack((x, [0.0] * (support_size - len(x))))\n",
    "    elif len(y) < len(x):\n",
    "        y = np.hstack((y, [0.0] * (support_size - len(y))))\n",
    "\n",
    "    dist = np.linalg.norm(x - y, 2)\n",
    "    return np.exp(-dist * dist / (2 * sigma * sigma))\n",
    "\n",
    "\n",
    "def gaussian_tv(x, y, sigma=1.0):  \n",
    "    support_size = max(len(x), len(y))\n",
    "    # convert histogram values x and y to float, and make them equal len\n",
    "    x = x.astype(float)\n",
    "    y = y.astype(float)\n",
    "    if len(x) < len(y):\n",
    "        x = np.hstack((x, [0.0] * (support_size - len(x))))\n",
    "    elif len(y) < len(x):\n",
    "        y = np.hstack((y, [0.0] * (support_size - len(y))))\n",
    "\n",
    "    dist = np.abs(x - y).sum() / 2.0\n",
    "    return np.exp(-dist * dist / (2 * sigma * sigma))\n",
    "\n",
    "\n",
    "def kernel_parallel_unpacked(x, samples2, kernel):\n",
    "    d = 0\n",
    "    for s2 in samples2:\n",
    "        d += kernel(x, s2)\n",
    "    return d\n",
    "\n",
    "\n",
    "def kernel_parallel_worker(t):\n",
    "    return kernel_parallel_unpacked(*t)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def disc(samples1, samples2, kernel, is_parallel=True, *args, **kwargs):\n",
    "    ''' Discrepancy between 2 samples '''\n",
    "    d = 0\n",
    "\n",
    "    if not is_parallel:\n",
    "        for s1 in samples1:\n",
    "            for s2 in samples2:\n",
    "                d += kernel(s1, s2, *args, **kwargs)\n",
    "    else:\n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            for dist in executor.map(kernel_parallel_worker, [\n",
    "                    (s1, samples2, partial(kernel, *args, **kwargs)) for s1 in samples1\n",
    "            ]):\n",
    "                d += dist\n",
    "    if len(samples1) * len(samples2) > 0:\n",
    "        d /= len(samples1) * len(samples2)\n",
    "    else:\n",
    "        d = 1e+6\n",
    "    #print('error')\n",
    "    return d\n",
    "\n",
    "\n",
    "def compute_mmd(samples1, samples2, kernel, is_hist=True, *args, **kwargs):\n",
    "    ''' MMD between two samples '''\n",
    "    # normalize histograms into pmf\n",
    "    if is_hist:\n",
    "        samples1 = [s1 / (np.sum(s1) + 1e-6) for s1 in samples1]\n",
    "        samples2 = [s2 / (np.sum(s2) + 1e-6) for s2 in samples2]\n",
    "    #print(samples1)\n",
    "    return disc(samples1, samples1, kernel, *args, **kwargs) + disc(samples2, samples2, kernel, *args, **kwargs) - \\\n",
    "                2 * disc(samples1, samples2, kernel, *args, **kwargs)\n",
    "\n",
    "\n",
    "def compute_emd(samples1, samples2, kernel, is_hist=True, *args, **kwargs):\n",
    "    ''' EMD between average of two samples '''\n",
    "    # normalize histograms into pmf\n",
    "    if is_hist:\n",
    "        samples1 = [np.mean(samples1)]\n",
    "        samples2 = [np.mean(samples2)]\n",
    "    return disc(samples1, samples2, kernel, *args,\n",
    "                            **kwargs), [samples1[0], samples2[0]]\n",
    "\n",
    "\n",
    "\n",
    "def compute_mmd_stats(graphs_ref_nx, graphs_pred_nx):\n",
    "  if 'networkx' not in str(type(graphs_ref_nx[0])):\n",
    "    graphs_ref_nx = [pyg_graph_to_nx(g) for g in graphs_ref_nx]\n",
    "  if 'networkx' not in str(type(graphs_pred_nx[0])):\n",
    "    graphs_pred_nx = [pyg_graph_to_nx(g) for g in graphs_pred_nx]\n",
    "  return degree_stats(graphs_ref_nx, graphs_pred_nx), clustering_stats(graphs_ref_nx, graphs_pred_nx)\n",
    "\n",
    "\n",
    "def compute_expected_optimal_loss(graph_dataset_train, graph_dataset_test):\n",
    "  graph_dataset_train_nx = [pyg_graph_to_nx(g) for g in graph_dataset_train]\n",
    "  graph_dataset_test_nx = [pyg_graph_to_nx(g) for g in graph_dataset_test]\n",
    "  return compute_mmd_stats(graph_dataset_train_nx, graph_dataset_test_nx)\n",
    "\n",
    "#def compute_expected_optimal_loss(graphs_ref_nx):\n",
    "#  graphs_ref_nx2 = build_test_set_nx(1337)\n",
    "#  return compute_mmd_stats(graphs_ref_nx, graphs_ref_nx2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dqztDRIj0UdF"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kV_DnkKhs9P-"
   },
   "source": [
    "#### AttentionNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "eoLXRG6utBBU"
   },
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GATv2Conv, GraphNorm, BatchNorm\n",
    "\n",
    "class AttentionNet(torch.nn.Module):\n",
    "  def __init__(self, hidden_dim=32, layer_num=6, dropout=0.1, normalization=False, single_pass_pooling=False):\n",
    "    super(AttentionNet, self).__init__()\n",
    "\n",
    "    self.mlp_list = nn.ModuleList()\n",
    "    self.conv_list = nn.ModuleList()\n",
    "    self.sigmoid = nn.Sigmoid()\n",
    "    self.dropout = dropout\n",
    "    self.graph_norms = nn.ModuleList()\n",
    "    self.normalization = normalization\n",
    "    self.single_pass_pooling = single_pass_pooling\n",
    "    assert(hidden_dim % 2 == 0)\n",
    "    input_channels = NUM_CLASSES\n",
    "\n",
    "    for i in range(layer_num):\n",
    "      in_dim = hidden_dim if i > 0 else input_channels \n",
    "      out_dim = hidden_dim if i < layer_num-1 else 1 \n",
    "      self.conv_list.append(GATv2Conv(in_channels=in_dim, out_channels=hidden_dim // 2, heads=2))\n",
    "      self.graph_norms.append(BatchNorm(hidden_dim))\n",
    "      self.mlp_list.append(Seq(Lin(hidden_dim, hidden_dim), nn.ReLU(), Lin(hidden_dim, hidden_dim), nn.ReLU(), Lin(hidden_dim, out_dim)))\n",
    "\n",
    "  def forward(self, x_in, edge_index, batch):\n",
    "    x = note_features_to_one_hot(x_in)\n",
    "    for i in range(len(self.conv_list)):\n",
    "      x = self.conv_list[i](x, edge_index)\n",
    "      x = F.relu(x)\n",
    "      if self.normalization:\n",
    "        x = self.graph_norms[i](x)\n",
    "      x = self.mlp_list[i](x)\n",
    "      #if i == 0:\n",
    "      #  x = self.dropout(x)\n",
    "\n",
    "    if self.single_pass_pooling:\n",
    "      x = global_mask_pool(x, x_in, batch)\n",
    "    else:\n",
    "      x = global_mean_pool(x, batch)\n",
    "    x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "    x = self.sigmoid(x) + EPSILON\n",
    "    return x.flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iTUh3uVOtEMO",
    "outputId": "65bca9cf-0b24-4c80-d5bf-e3281ee745e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AttentionNet(\n",
      "  (mlp_list): ModuleList(\n",
      "    (0-4): 5 x Sequential(\n",
      "      (0): Linear(in_features=32, out_features=32, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=32, out_features=32, bias=True)\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): Linear(in_features=32, out_features=32, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=32, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (conv_list): ModuleList(\n",
      "    (0): GATv2Conv(4, 16, heads=2)\n",
      "    (1-5): 5 x GATv2Conv(32, 16, heads=2)\n",
      "  )\n",
      "  (sigmoid): Sigmoid()\n",
      "  (graph_norms): ModuleList(\n",
      "    (0-5): 6 x BatchNorm(32)\n",
      "  )\n",
      ")\n",
      "tensor([0.9037, 0.9037, 0.9037, 0.9037, 0.9037, 0.9037, 0.9037, 0.5000, 0.9037,\n",
      "        0.9037], grad_fn=<ReshapeAliasBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = AttentionNet(single_pass_pooling=True)\n",
    "model.to(DEVICE)\n",
    "print(model) \n",
    "for step, data in enumerate(train_loader):\n",
    "  data = data.to(DEVICE)\n",
    "  print(model(data.x, data.edge_index, data.batch))\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SaQ7f2E4dCqd"
   },
   "source": [
    "#### TransformerNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "nS3CzlgcdEAK"
   },
   "outputs": [],
   "source": [
    "#relu = nn.Relu() ## todo: changed to relu here\n",
    "from torch_geometric.nn import TransformerConv\n",
    "\n",
    "class TransformerNet(torch.nn.Module):\n",
    "  def __init__(self, hidden_dim=32, layer_num=6, dropout=0.1, normalization=False, single_pass_pooling = False):\n",
    "    super(TransformerNet, self).__init__()\n",
    "\n",
    "    self.mlp_list = nn.ModuleList()\n",
    "    self.conv_list = nn.ModuleList()\n",
    "    self.sigmoid = nn.Sigmoid()\n",
    "    self.graph_norms = nn.ModuleList()\n",
    "    self.dropout = dropout\n",
    "    self.normalization = normalization\n",
    "    assert(hidden_dim % 2 == 0)\n",
    "    input_channels = NUM_CLASSES\n",
    "    self.single_pass_pooling = single_pass_pooling\n",
    "\n",
    "\n",
    "    for i in range(layer_num):\n",
    "      in_dim = hidden_dim if i > 0 else input_channels \n",
    "      out_dim = hidden_dim if i < layer_num-1 else 1 \n",
    "      self.conv_list.append(TransformerConv(in_channels=in_dim, out_channels=hidden_dim // 2, heads=2))\n",
    "      self.graph_norms.append(BatchNorm(hidden_dim))\n",
    "      self.mlp_list.append(Seq(Lin(hidden_dim, hidden_dim), nn.ReLU(), Lin(hidden_dim, hidden_dim), nn.ReLU(), Lin(hidden_dim, out_dim)))\n",
    "\n",
    "  def forward(self, x_in, edge_index, batch):\n",
    "    x = note_features_to_one_hot(x_in)\n",
    "    for i in range(len(self.conv_list)):\n",
    "      x = self.conv_list[i](x, edge_index)\n",
    "      if self.normalization:\n",
    "        x = self.graph_norms[i](x)\n",
    "      x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "      x = self.mlp_list[i](x)\n",
    "    \n",
    "    if self.single_pass_pooling:\n",
    "      x = global_mask_pool(x, x_in, batch)\n",
    "    else:\n",
    "      x = global_mean_pool(x, batch)\n",
    "\n",
    "    x = self.sigmoid(x) + EPSILON\n",
    "    return x.flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "plkfTVUrXRO-",
    "outputId": "a55bbb21-48d3-456f-a39d-b39b9252a9b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TransformerNet(\n",
      "  (mlp_list): ModuleList(\n",
      "    (0-4): 5 x Sequential(\n",
      "      (0): Linear(in_features=32, out_features=32, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=32, out_features=32, bias=True)\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): Linear(in_features=32, out_features=32, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=32, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (conv_list): ModuleList(\n",
      "    (0): TransformerConv(4, 16, heads=2)\n",
      "    (1-5): 5 x TransformerConv(32, 16, heads=2)\n",
      "  )\n",
      "  (sigmoid): Sigmoid()\n",
      "  (graph_norms): ModuleList(\n",
      "    (0-5): 6 x BatchNorm(32)\n",
      "  )\n",
      ")\n",
      "tensor([0.5099, 0.5099, 0.5100, 0.5100, 0.5102, 0.5101, 0.5100, 0.5102, 0.5101,\n",
      "        0.5099], grad_fn=<ReshapeAliasBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = TransformerNet()\n",
    "model.to(DEVICE)\n",
    "print(model) \n",
    "for step, data in enumerate(train_loader):\n",
    "  data = data.to(DEVICE)\n",
    "  print(model(data.x, data.edge_index, data.batch))\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UwghOZsDdEJz"
   },
   "source": [
    "#### Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "LEwIcO4w0VaR"
   },
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GraphUNet\n",
    "\n",
    "class Unet(torch.nn.Module):\n",
    "  def __init__(self, hidden_channels=32, out_channels=1, depth=4, single_pass_pooling = False):\n",
    "    super(Unet, self).__init__()\n",
    "    self.sigmoid = nn.Sigmoid()\n",
    "    in_channels = NUM_CLASSES\n",
    "    self.single_pass_pooling = single_pass_pooling\n",
    "    self.unet = GraphUNet(in_channels=in_channels, hidden_channels=hidden_channels, out_channels=out_channels, depth=depth)\n",
    "\n",
    "  def forward(self, x_in, edge_index, batch):\n",
    "    x = note_features_to_one_hot(x_in)\n",
    "    x = self.unet(x, edge_index)\n",
    "\n",
    "    if self.single_pass_pooling:\n",
    "      x = global_mask_pool(x, x_in, batch)\n",
    "    else:\n",
    "      x = global_mean_pool(x, batch)\n",
    "\n",
    "    x = self.sigmoid(x) + 0.0000001 # add eps to avoid div. by zero\n",
    "    return x.flatten()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YBYSWAp9XOLz",
    "outputId": "f5ef7b55-9c1c-47f0-972d-46334d938ba2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unet(\n",
      "  (sigmoid): Sigmoid()\n",
      "  (unet): GraphUNet(4, 32, 1, depth=4, pool_ratios=[0.5, 0.5, 0.5, 0.5])\n",
      ")\n",
      "tensor([0.5172, 0.5172, 0.5172, 0.5172, 0.5172, 0.5172, 0.5172, 0.5172, 0.5172,\n",
      "        0.5172], grad_fn=<ReshapeAliasBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Unet()\n",
    "model.to(DEVICE)\n",
    "print(model) \n",
    "for step, data in enumerate(train_loader):\n",
    "  data.to(DEVICE)\n",
    "  print(model(data.x, data.edge_index, data.batch))\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ir4sFS6YS5UY"
   },
   "source": [
    "#### PNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "ydDINWbaaSav"
   },
   "outputs": [],
   "source": [
    "def print_inputs(*args):\n",
    "    for arg in args:\n",
    "        print(arg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "U_8SApKdS3wo"
   },
   "outputs": [],
   "source": [
    "from torch_geometric.nn import PNA\n",
    "from torch_geometric.utils import degree\n",
    "\n",
    "#train_dataset = build_dataset()\n",
    "\n",
    "def dataset_to_degree_bin(train_dataset):\n",
    "  # Compute the maximum in-degree in the training data.\n",
    "  max_degree = -1\n",
    "  for data in train_dataset:\n",
    "      d = degree(data.edge_index[1], num_nodes=data.num_nodes, dtype=torch.long)\n",
    "      max_degree = max(max_degree, int(d.max()))\n",
    "\n",
    "  deg = torch.zeros(max_degree + 1, dtype=torch.long)\n",
    "  for data in train_dataset:\n",
    "      d = degree(data.edge_index[1], num_nodes=data.num_nodes, dtype=torch.long)\n",
    "      deg += torch.bincount(d, minlength=deg.numel())\n",
    "  return deg\n",
    "\n",
    "class PNAnet(torch.nn.Module):\n",
    "  def __init__(self, train_dataset_example, hidden_channels=32, depth=4, dropout=0.0, towers=2, single_pass_pooling=False, graph_transform=False, normalization=True, pre_post_layers=1):\n",
    "    super(PNAnet, self).__init__()\n",
    "    self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    # Calculate x as the difference between mult_y and hidden_dim\n",
    "    hidden_channels = towers * ((hidden_channels // towers) + 1)\n",
    "    #out_channels = towers * ((out_channels // towers) + 1)\n",
    "\n",
    "    in_channels = NUM_CLASSES\n",
    "    if graph_transform:\n",
    "      in_channels += NODE_FEATURE_EXTEND\n",
    "    deg = dataset_to_degree_bin(train_dataset_example)\n",
    "    aggregators = ['mean', 'min', 'max', 'std']\n",
    "    scalers = ['identity', 'amplification', 'attenuation']\n",
    "    self.normalization = BatchNorm(hidden_channels) if normalization else None\n",
    "    self.pnanet = PNA(in_channels=in_channels, hidden_channels=hidden_channels, out_channels=hidden_channels, num_layers=depth, aggregators=aggregators, scalers=scalers, deg=deg, dropout=dropout, towers=towers, norm=self.normalization, pre_layers=pre_post_layers, post_layers=pre_post_layers)\n",
    "    self.single_pass_pooling = single_pass_pooling\n",
    "    self.graph_transform = graph_transform\n",
    "\n",
    "    self.final_mlp = Seq(Lin(hidden_channels, hidden_channels), nn.ReLU(), Lin(hidden_channels, hidden_channels), nn.ReLU(), Lin(hidden_channels, 1))\n",
    "\n",
    "\n",
    "  def forward(self, x_in, edge_index, batch):\n",
    "    x = note_features_to_one_hot(x_in)\n",
    "    if self.graph_transform:\n",
    "      x = extend_node_features(x, edge_index, batch)\n",
    "    x = self.pnanet(x, edge_index)\n",
    "\n",
    "    if self.single_pass_pooling:\n",
    "      x = global_mask_pool(x, x_in, batch)\n",
    "    else:\n",
    "      x = global_mean_pool(x, batch)\n",
    "\n",
    "    #x = x.sum(dim=1)\n",
    "    x = self.final_mlp(x)\n",
    "    x = self.sigmoid(x) + EPSILON # add eps to avoid div. by zero\n",
    "    return x.flatten()\n",
    "\n",
    "class PNAmulti(torch.nn.Module):\n",
    "  def __init__(self, train_dataset_example, hidden_channels=32, graph_transform=False, depth=4, dropout=0.0, towers=1, model_num=5, single_pass_pooling=False, normalization=True, pre_post_layers=1):\n",
    "    super(PNAmulti, self).__init__()\n",
    "    self.model_num = model_num\n",
    "    self.pna_list = nn.ModuleList()\n",
    "    self.sigmoid = nn.Sigmoid()\n",
    "    weights = torch.ones(model_num)\n",
    "    self.weights = nn.Parameter(weights)  # nn.Parameter is a Tensor that's a module parameter.\n",
    "    for i in range(model_num):\n",
    "      # towers is i+1\n",
    "      pna_model = PNAnet(train_dataset_example, hidden_channels=hidden_channels, graph_transform=graph_transform, depth=depth, dropout=dropout, towers=i+1, single_pass_pooling=single_pass_pooling, normalization=normalization, pre_post_layers=pre_post_layers)\n",
    "      self.pna_list.append(pna_model)\n",
    "\n",
    "  def get_normalized_weights(self):\n",
    "    w_sigmoid = self.sigmoid(self.weights)\n",
    "    w = w_sigmoid/w_sigmoid.sum()\n",
    "    return w\n",
    "\n",
    "  def forward(self, x, edge_index, batch):\n",
    "    x_agg = None\n",
    "    i_not = random.choice(range(len(self.pna_list))) if self.training  and len(self.pna_list) > 1 else -1 # skip 1 during training\n",
    "    w = self.get_normalized_weights()\n",
    "    for i, pna_model in enumerate(self.pna_list):\n",
    "      if i == i_not:\n",
    "        continue\n",
    "      if x_agg is None:\n",
    "        x_agg = pna_model(x, edge_index, batch) * w[i]\n",
    "      else:\n",
    "        x_agg = x_agg + pna_model( x, edge_index, batch) * w[i]\n",
    "    return x_agg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TTvXwuajPPOJ",
    "outputId": "a919e1b7-cfc1-418e-bba0-c88274816465"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNAmulti(\n",
      "  (pna_list): ModuleList(\n",
      "    (0): PNAnet(\n",
      "      (sigmoid): Sigmoid()\n",
      "      (normalization): BatchNorm(33)\n",
      "      (pnanet): PNA(4, 33, num_layers=4)\n",
      "      (final_mlp): Sequential(\n",
      "        (0): Linear(in_features=33, out_features=33, bias=True)\n",
      "        (1): ReLU()\n",
      "        (2): Linear(in_features=33, out_features=33, bias=True)\n",
      "        (3): ReLU()\n",
      "        (4): Linear(in_features=33, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (1): PNAnet(\n",
      "      (sigmoid): Sigmoid()\n",
      "      (normalization): BatchNorm(34)\n",
      "      (pnanet): PNA(4, 34, num_layers=4)\n",
      "      (final_mlp): Sequential(\n",
      "        (0): Linear(in_features=34, out_features=34, bias=True)\n",
      "        (1): ReLU()\n",
      "        (2): Linear(in_features=34, out_features=34, bias=True)\n",
      "        (3): ReLU()\n",
      "        (4): Linear(in_features=34, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (2): PNAnet(\n",
      "      (sigmoid): Sigmoid()\n",
      "      (normalization): BatchNorm(33)\n",
      "      (pnanet): PNA(4, 33, num_layers=4)\n",
      "      (final_mlp): Sequential(\n",
      "        (0): Linear(in_features=33, out_features=33, bias=True)\n",
      "        (1): ReLU()\n",
      "        (2): Linear(in_features=33, out_features=33, bias=True)\n",
      "        (3): ReLU()\n",
      "        (4): Linear(in_features=33, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (3): PNAnet(\n",
      "      (sigmoid): Sigmoid()\n",
      "      (normalization): BatchNorm(36)\n",
      "      (pnanet): PNA(4, 36, num_layers=4)\n",
      "      (final_mlp): Sequential(\n",
      "        (0): Linear(in_features=36, out_features=36, bias=True)\n",
      "        (1): ReLU()\n",
      "        (2): Linear(in_features=36, out_features=36, bias=True)\n",
      "        (3): ReLU()\n",
      "        (4): Linear(in_features=36, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (4): PNAnet(\n",
      "      (sigmoid): Sigmoid()\n",
      "      (normalization): BatchNorm(35)\n",
      "      (pnanet): PNA(4, 35, num_layers=4)\n",
      "      (final_mlp): Sequential(\n",
      "        (0): Linear(in_features=35, out_features=35, bias=True)\n",
      "        (1): ReLU()\n",
      "        (2): Linear(in_features=35, out_features=35, bias=True)\n",
      "        (3): ReLU()\n",
      "        (4): Linear(in_features=35, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "tensor([0.4080, 0.4080, 0.4080, 0.4080, 0.4080, 0.4080, 0.4080, 0.4080, 0.4080,\n",
      "        0.4080], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = PNAmulti(build_dataset()[0])\n",
    "model.to(DEVICE)\n",
    "print(model) \n",
    "for step, data in enumerate(train_loader):\n",
    "  data.to(DEVICE)\n",
    "  print(model(data.x, data.edge_index, data.batch))\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hSyYUfY1X6Os",
    "outputId": "507c64d0-2f3e-442d-8f1f-fb5aece60a4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNAnet(\n",
      "  (sigmoid): Sigmoid()\n",
      "  (normalization): BatchNorm(34)\n",
      "  (pnanet): PNA(4, 34, num_layers=4)\n",
      "  (final_mlp): Sequential(\n",
      "    (0): Linear(in_features=34, out_features=34, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=34, out_features=34, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=34, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "tensor([0.5500, 0.5500, 0.5500, 0.5500, 0.5500, 0.5500, 0.5500, 0.5500, 0.5500,\n",
      "        0.5500], grad_fn=<ReshapeAliasBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = PNAnet(build_dataset()[0])\n",
    "model.to(DEVICE)\n",
    "print(model) \n",
    "for step, data in enumerate(train_loader):\n",
    "  data.to(DEVICE)\n",
    "  print(model(data.x, data.edge_index, data.batch))\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jB6WbKuwVdix"
   },
   "source": [
    "#### PNA2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "6Mvgyb_hVgpv"
   },
   "outputs": [],
   "source": [
    "from torch_geometric.nn import PNAConv\n",
    "\n",
    "class PNA2net(torch.nn.Module):\n",
    "  def __init__(self, train_dataset_example, hidden_dim=32, layer_num=4, dropout=0.0, normalization=False, tower_num=5, single_pass_pooling=False):\n",
    "    super().__init__()\n",
    "\n",
    "    aggregators = ['mean', 'min', 'max', 'std', 'var', 'sum']\n",
    "    scalers = ['identity', 'amplification', 'attenuation']\n",
    "    deg = dataset_to_degree_bin(train_dataset_example)\n",
    "\n",
    "    # Calculate x as the difference between mult_y and hidden_dim\n",
    "    hidden_dim = tower_num * ((hidden_dim // tower_num) + 1)\n",
    "\n",
    "    self.conv_list = nn.ModuleList()\n",
    "    self.batchnorm_list = nn.ModuleList()\n",
    "    self.mlp_list = nn.ModuleList()\n",
    "\n",
    "    self.dropout = dropout\n",
    "    self.normalization = normalization\n",
    "    self.sigmoid = nn.Sigmoid()\n",
    "    self.single_pass_pooling = single_pass_pooling\n",
    "\n",
    "    input_channels = NUM_CLASSES\n",
    "  \n",
    "\n",
    "    for i in range(layer_num):\n",
    "      in_dim = hidden_dim if i > 0 else input_channels \n",
    "      out_dim = hidden_dim if i < layer_num-1 else 1 \n",
    "      self.conv_list.append(PNAConv(in_channels=in_dim, out_channels=hidden_dim, aggregators=aggregators, scalers=scalers, deg=deg, towers=tower_num, pre_layers=1, post_layers=1, divide_input=False))\n",
    "      self.batchnorm_list.append(BatchNorm(hidden_dim))\n",
    "      self.mlp_list.append(Seq(nn.ReLU(), Lin(hidden_dim+NUM_CLASSES+in_dim, hidden_dim+NUM_CLASSES+in_dim), nn.ReLU(), Lin(hidden_dim+NUM_CLASSES+in_dim, hidden_dim+NUM_CLASSES+in_dim), nn.ReLU(), Lin(hidden_dim+NUM_CLASSES+in_dim, out_dim)))\n",
    "          \n",
    "  def forward(self, x_in, edge_index, batch):\n",
    "    x_onehot = note_features_to_one_hot(x_in)\n",
    "    x = x_onehot.clone()\n",
    "    for i in range(len(self.conv_list)):\n",
    "      x_in = x.clone()\n",
    "      x = self.conv_list[i](x, edge_index)\n",
    "      if self.normalization:\n",
    "        x = self.batchnorm_list[i](x)\n",
    "      x_concat = torch.concat([x, x_onehot, x_in], dim=1)\n",
    "      x = self.mlp_list[i](x_concat)\n",
    "      if i < len(self.conv_list)-1:\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "\n",
    "    if self.single_pass_pooling:\n",
    "      x = global_mask_pool(x, x_in, batch)\n",
    "    else:\n",
    "      x = global_mean_pool(x, batch)\n",
    "      \n",
    "    x = self.sigmoid(x) + EPSILON\n",
    "    return x.flatten()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rgjqgcfhY1gC",
    "outputId": "43446f0e-9b7e-4570-a660-f15f06c99bd1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNA2net(\n",
      "  (conv_list): ModuleList(\n",
      "    (0): PNAConv(4, 35, towers=5, edge_dim=None)\n",
      "    (1-3): 3 x PNAConv(35, 35, towers=5, edge_dim=None)\n",
      "  )\n",
      "  (batchnorm_list): ModuleList(\n",
      "    (0-3): 4 x BatchNorm(35)\n",
      "  )\n",
      "  (mlp_list): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): ReLU()\n",
      "      (1): Linear(in_features=43, out_features=43, bias=True)\n",
      "      (2): ReLU()\n",
      "      (3): Linear(in_features=43, out_features=43, bias=True)\n",
      "      (4): ReLU()\n",
      "      (5): Linear(in_features=43, out_features=35, bias=True)\n",
      "    )\n",
      "    (1-2): 2 x Sequential(\n",
      "      (0): ReLU()\n",
      "      (1): Linear(in_features=74, out_features=74, bias=True)\n",
      "      (2): ReLU()\n",
      "      (3): Linear(in_features=74, out_features=74, bias=True)\n",
      "      (4): ReLU()\n",
      "      (5): Linear(in_features=74, out_features=35, bias=True)\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): ReLU()\n",
      "      (1): Linear(in_features=74, out_features=74, bias=True)\n",
      "      (2): ReLU()\n",
      "      (3): Linear(in_features=74, out_features=74, bias=True)\n",
      "      (4): ReLU()\n",
      "      (5): Linear(in_features=74, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "tensor([0.4816, 0.4816, 0.4816, 0.4816, 0.4816, 0.4816, 0.4816, 0.4816, 0.4816,\n",
      "        0.4816], grad_fn=<ReshapeAliasBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = PNA2net(build_dataset()[0])\n",
    "model.to(DEVICE)\n",
    "print(model) \n",
    "for step, data in enumerate(train_loader):\n",
    "  data.to(DEVICE)\n",
    "  print(model(data.x, data.edge_index, data.batch))\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tph0rjhNS6iS"
   },
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_K0Yuz5FNVdy"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "gDKYLoMV6z6J"
   },
   "outputs": [],
   "source": [
    "def build_model(config, dataset):\n",
    "  hidden_dim = config.hidden_dim\n",
    "  single_pass_pooling = config.single_pass\n",
    "  if config.model == \"unet\":\n",
    "    model =  Unet(hidden_channels = hidden_dim,  out_channels = 1, depth=config.hidden_layer, single_pass_pooling=single_pass_pooling)\n",
    "  elif config.model == \"attention\":\n",
    "     model = AttentionNet(hidden_dim=hidden_dim, layer_num=config.hidden_layer, dropout=config.dropout, normalization=config.normalization, single_pass_pooling=single_pass_pooling)\n",
    "  elif config.model == \"transformer\":\n",
    "    model = TransformerNet(hidden_dim=hidden_dim, layer_num=config.hidden_layer, dropout=config.dropout, normalization=config.normalization, single_pass_pooling=single_pass_pooling)\n",
    "  elif config.model == \"pna\":\n",
    "    model = PNAnet(dataset, hidden_channels=hidden_dim, depth=config.hidden_layer, dropout=config.dropout, towers=config.towers, single_pass_pooling=single_pass_pooling, graph_transform=config.graph_transform, normalization=config.normalization, pre_post_layers=config.pre_post_layers)\n",
    "  elif config.model == \"pnamulti\":\n",
    "    model = PNAmulti(dataset, hidden_channels=hidden_dim, depth=config.hidden_layer, dropout=config.dropout, towers=config.towers, single_pass_pooling=single_pass_pooling, graph_transform=config.graph_transform, normalization=config.normalization, pre_post_layers=config.pre_post_layers)\n",
    "  elif config.model == \"pna2\":\n",
    "    model = PNA2net(dataset, hidden_dim=hidden_dim, layer_num=config.hidden_layer, dropout=config.dropout, normalization=config.normalization, single_pass_pooling=single_pass_pooling)\n",
    "  else:\n",
    "    ValueError(\"illegal net\")\n",
    "  return model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2GDOIysiiIGT"
   },
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "FsofkLkkP3GK"
   },
   "outputs": [],
   "source": [
    "def find_best_choice(model, g, test_choices, x, x_shape):\n",
    "  p_0_list = list()\n",
    "  p_1_list = list()\n",
    "  x_noedge_list = list()\n",
    "  x_edge_list = list()\n",
    "  mask_indicator_list = list()\n",
    "\n",
    "  for i, mask_indicator in enumerate(test_choices):\n",
    "    x_noedge, x_edge = x.clone(), x.clone()\n",
    "    x_noedge[mask_indicator] = NO_EDGE_INDICATOR\n",
    "    x_edge[mask_indicator] = EDGE_INDICATOR\n",
    "    batch = torch.zeros(x_shape[0], dtype=torch.long).to(DEVICE)\n",
    "    p_0 = model(x_noedge.view(x_shape), g.edge_index, batch=batch).item()\n",
    "    p_1 = model(x_edge.view(x_shape), g.edge_index, batch=batch).item()\n",
    "\n",
    "    p_0_list.append(p_0/(p_0+p_1))\n",
    "    p_1_list.append(p_1/(p_0+p_1))\n",
    "    x_noedge_list.append(x_noedge)\n",
    "    x_edge_list.append(x_edge)\n",
    "    mask_indicator_list.append(mask_indicator)\n",
    "\n",
    "  best_i = np.argmax(p_1_list)\n",
    "  return p_0_list[best_i], p_1_list[best_i], x_noedge_list[best_i],  x_edge_list[best_i], mask_indicator_list[best_i]\n",
    "\n",
    "\n",
    "def generate_graph_multi(model, g, choice_num=5):\n",
    "  x = g.x\n",
    "  x_shape = x.shape\n",
    "  x = x.flatten()\n",
    "  indices_of_edges = (x != DUMMY).nonzero(as_tuple=False).flatten()\n",
    "  num_edges = indices_of_edges.numel()\n",
    "  x[indices_of_edges] = MASK\n",
    "  indices_of_edges = indices_of_edges.flatten().tolist()\n",
    "\n",
    "  for _ in range(num_edges):\n",
    "    random.shuffle(indices_of_edges)\n",
    "    choice_num_i = min(choice_num, len(indices_of_edges)) \n",
    "    test_choices = indices_of_edges[0:choice_num_i]\n",
    "    p_0, p_1, x_noedge, x_edge, mask_indicator = find_best_choice(model, g, test_choices, x, x_shape)\n",
    "    random_selection_index = int(np.random.choice([0, 1], size=1, p=[p_0, p_1]))\n",
    "    x = (x_noedge, x_edge)[random_selection_index]\n",
    "    indices_of_edges.remove(mask_indicator)\n",
    "\n",
    "  g.x = x.reshape(x_shape)\n",
    "  return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 131
    },
    "id": "DQay_Zy35bHr",
    "outputId": "8b841102-0192-46a7-b1b4-b1ced222de41"
   },
   "outputs": [],
   "source": [
    "def test_candidates(candidates, x, g, batch, x_shape):\n",
    "  best_edge_index = None\n",
    "  best_edge_prob = None\n",
    "\n",
    "  for edge_index in candidates:\n",
    "    x[edge_index] = -1.0\n",
    "    edge_prob = model(x.view(x_shape), g.edge_index, batch=batch).item()\n",
    "    x[edge_index] = MASK\n",
    "    if best_edge_prob is None or max(edge_prob, 1.0-edge_prob) > best_edge_prob:\n",
    "      best_edge_index = edge_index\n",
    "      best_edge_prob = edge_prob\n",
    "\n",
    "  return best_edge_index, best_edge_prob\n",
    "\n",
    "def generate_graph_singlepass(model, g, choice_num = 1, config = None):\n",
    "  # does not have multi\n",
    "  x = g.x\n",
    "  x_shape = x.shape\n",
    "  x = x.flatten()\n",
    "  indices_of_edges = (x != DUMMY).nonzero(as_tuple=False).flatten()\n",
    "  num_edges = indices_of_edges.numel()\n",
    "  x[indices_of_edges] = MASK\n",
    "  indices_of_edges = indices_of_edges.flatten().tolist()\n",
    "  random.shuffle(indices_of_edges)\n",
    "  batch = torch.zeros(x_shape[0], dtype=torch.long).to(DEVICE)\n",
    "\n",
    "  if config is not None and config.double_inference == True:\n",
    "    indices_of_edges = list(indices_of_edges) + list(indices_of_edges)\n",
    "\n",
    "  for i in range(len(indices_of_edges)):  \n",
    "    i_dyn = min(choice_num, len(indices_of_edges) - i)\n",
    "    candidates = indices_of_edges[i:i+i_dyn]\n",
    "    #print(\"candidates \",candidates)\n",
    "    edge_index, edge_prob = test_candidates(candidates, x, g, batch, x_shape)\n",
    "\n",
    "    assert(edge_prob > 0.0 and edge_prob < 1.0)\n",
    "    if random.random() < edge_prob:\n",
    "      x[edge_index] = EDGE_INDICATOR\n",
    "    else:\n",
    "      x[edge_index] = NO_EDGE_INDICATOR\n",
    "\n",
    "  g.x = x.reshape(x_shape)\n",
    "  return g\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "_cN5gKKUiJTR"
   },
   "outputs": [],
   "source": [
    "@torch.inference_mode()\n",
    "def generate_graphs(num, epoch_i, model, g_like, config):\n",
    "  model.eval()\n",
    "  mean_degree_list = list()\n",
    "  var_degree_list = list()\n",
    "  nx_graph_list = list()\n",
    "  for j in range(num):\n",
    "    if config.single_pass:\n",
    "      g = generate_graph_singlepass(model, g_like, choice_num = config.candidate_selection_radius, config=config)\n",
    "    else:\n",
    "      g = generate_graph_multi(model, g_like, choice_num = config.candidate_selection_radius)\n",
    "    nx_orig_graph = draw_pyg(g, filename=f\"generated_graph_epoch{str(epoch_i).zfill(5)}_sample{str(j).zfill(5)}.jpg\")\n",
    "    degree_list = [nx_orig_graph.degree(i) for i in nx_orig_graph.nodes()]\n",
    "    mean_degree_list.append(np.mean(degree_list))\n",
    "    var_degree_list.append(np.var(degree_list))\n",
    "    nx_graph_list.append(nx_orig_graph)\n",
    "  return np.mean(mean_degree_list), np.mean(var_degree_list), nx_graph_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GKxurLjrXnCo"
   },
   "source": [
    "## Generat Samples for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "nALlwSTtXmhx"
   },
   "outputs": [],
   "source": [
    "def gen_random_training_sample_unused(x):\n",
    "  x_masked = x.clone().reshape(-1)\n",
    "  indices_of_edges = (x_masked != DUMMY).nonzero(as_tuple=False).flatten()\n",
    "  num_edges = indices_of_edges.numel()\n",
    "  num_masked = torch.randint(1, num_edges+1, size=(1,), device=DEVICE)\n",
    "  #num_masked = sample_num_masked_geometric(1, num_edges+1)\n",
    "\n",
    "  shuffled_indices_of_edges = indices_of_edges[torch.randperm(indices_of_edges.numel())]\n",
    "  indices_of_edges_to_mask = shuffled_indices_of_edges[:num_masked]\n",
    "  \n",
    "  gt_value = x_masked[indices_of_edges_to_mask[0]].item() # we will change the first value back\n",
    "  x_masked[indices_of_edges_to_mask] = MASK\n",
    "\n",
    "\n",
    "  x_masked_0 = x_masked.clone()\n",
    "  x_masked_0[indices_of_edges_to_mask[0]] = NO_EDGE_INDICATOR\n",
    "  x_masked_0 = x_masked_0.reshape(x.shape)\n",
    "\n",
    "  x_masked_1 = x_masked.clone()\n",
    "  x_masked_1[indices_of_edges_to_mask[0]] = EDGE_INDICATOR\n",
    "  x_masked_1 = x_masked_1.reshape(x.shape)\n",
    "\n",
    "  if gt_value == NO_EDGE_INDICATOR:\n",
    "    return x_masked_0, x_masked_1\n",
    "  elif gt_value == EDGE_INDICATOR:\n",
    "    return x_masked_1, x_masked_0 \n",
    "  assert(False)\n",
    "\n",
    "  return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "G-gIs8GVYm5l"
   },
   "outputs": [],
   "source": [
    "def sample_mask_and_flip(batch, x):\n",
    "  num_graphs = batch.view(-1)[-1]\n",
    "  x_id_mask = list()\n",
    "  x_id_flip = list()\n",
    "\n",
    "  for graph_id in range(num_graphs+1):\n",
    "    #num_nodes = (batch == graph_id).sum()\n",
    "    #indices_of_edges = (x != DUMMY and batch == graph_id).nonzero(as_tuple=False)\n",
    "    edge_indicator = x.view(-1) != DUMMY\n",
    "    batch_indicator = batch.view(-1) == graph_id \n",
    "    indices_of_edges = torch.nonzero(batch_indicator & edge_indicator)\n",
    "    indices_of_edges = indices_of_edges.flatten().tolist()\n",
    "    random.shuffle(indices_of_edges)\n",
    "    x_id_flip.append(indices_of_edges[-1])\n",
    "    num_masked = random.choice(range(len(indices_of_edges)))\n",
    "    x_id_mask = x_id_mask + indices_of_edges[:num_masked]\n",
    "\n",
    "  mask_and_flip_indicator = torch.zeros(batch.numel(), dtype=torch.long).to(DEVICE)\n",
    "  mask_and_flip_indicator[x_id_mask] = 1\n",
    "  mask_and_flip_indicator[x_id_flip] = 2\n",
    "\n",
    "  return mask_and_flip_indicator\n",
    "\n",
    "def mask_x_based_on_indicator(x, mask_and_flip_indicator):\n",
    "  x_new = x.clone()\n",
    "  to_mask = mask_and_flip_indicator == 1\n",
    "  x_new.view(-1)[to_mask] = MASK\n",
    "  return x_new\n",
    "\n",
    "\n",
    "# this is done inplace!\n",
    "def flip_x_based_on_indicator(x, mask_and_flip_indicator):\n",
    "  to_flip = (mask_and_flip_indicator == 2)#.to(DEVICE)\n",
    "  x = x.clone()  #sadly in-place operation not allowed here\n",
    "\n",
    "  #x[to_flip] = -x[to_flip]\n",
    "\n",
    "  x[to_flip] = torch.where(x[to_flip] == EDGE_INDICATOR, torch.tensor(NO_EDGE_INDICATOR).to(DEVICE), torch.tensor(EDGE_INDICATOR).to(DEVICE))\n",
    "\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "1La4pbjWakyz"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for step, data in enumerate(train_loader):\n",
    "  data.to(DEVICE)\n",
    "  mask_and_flip_indicator = sample_mask_and_flip(data.batch, data.x)\n",
    "  break\n",
    "\n",
    "\n",
    "x = (mask_x_based_on_indicator(data.x, mask_and_flip_indicator))\n",
    "xz = x.clone()\n",
    "xx = (flip_x_based_on_indicator(x, mask_and_flip_indicator))\n",
    "\n",
    "(xz == xx).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TulPGAH8R0Eo"
   },
   "source": [
    "## Compute Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "flDsYTRKR1ZB"
   },
   "outputs": [],
   "source": [
    "bce_loss = nn.BCELoss()\n",
    "def reduce_loss(loss_for_graph, config):\n",
    "  # loss_for_graph should be > 0\n",
    "  if config.loss == \"l1\":\n",
    "    return loss_for_graph.sum() \n",
    "  elif config.loss == \"l2\":\n",
    "    return F.mse_loss(loss_for_graph, torch.zeros_like(loss_for_graph))\n",
    "  elif config.loss == \"bce\":\n",
    "    return bce_loss(loss_for_graph, torch.zeros_like(loss_for_graph))\n",
    "  else:\n",
    "    raise ValueError(\"Illegal loss value\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SVx9HGc89VFe"
   },
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "K4M0XZ5Vpk5Z"
   },
   "outputs": [],
   "source": [
    "def prepare_x_for_single_pass(mask_and_flip_indicator, x):\n",
    "  x_new = x.clone()\n",
    "  to_mask = mask_and_flip_indicator == 1\n",
    "  x_new.view(-1)[to_mask] = MASK\n",
    "  choice_indicator = mask_and_flip_indicator == 2\n",
    "  x_new.view(-1)[choice_indicator] = -1 # this will be set to zero in the one hot encoding step\n",
    "  gt = x.clone().flatten()[choice_indicator]\n",
    "  gt = torch.where(gt == EDGE_INDICATOR, torch.tensor(1.0, device = DEVICE), torch.zeros_like(gt))\n",
    "  return x_new, gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "gj5td9zue7HT"
   },
   "outputs": [],
   "source": [
    "def single_pass_prediction(data, model, config):\n",
    "  mask_and_flip_indicator = sample_mask_and_flip(data.batch, data.x)\n",
    "  x_in, out_gt = prepare_x_for_single_pass(mask_and_flip_indicator, data.x)\n",
    "\n",
    "  if model.training: x_in = flip_edges_randomly(x_in, config.noise_probability)\n",
    "\n",
    "  out_prediction = model(x_in, data.edge_index, data.batch) # between 0 ,1 \n",
    "\n",
    "  #print(\"out gt: \", out_gt.flatten(), \"   out pred:   \", out_prediction.flatten())\n",
    "\n",
    "  loss_for_graph =  torch.abs(out_prediction.flatten() - out_gt.flatten()) # between 0 and 1\n",
    "  return loss_for_graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "sUfUS3OYfNxu"
   },
   "outputs": [],
   "source": [
    "def multi_pass_prediction(data, model, config):\n",
    "  mask_and_flip_indicator = sample_mask_and_flip(data.batch, data.x) # this then should also return gt \n",
    "  x = mask_x_based_on_indicator(data.x, mask_and_flip_indicator)\n",
    "\n",
    "  if model.training: x = flip_edges_randomly(x, config.noise_probability)\n",
    "\n",
    "  out_correct = model(x, data.edge_index, data.batch)  # is supposed to be 1 everywhere\n",
    "  x = flip_x_based_on_indicator(x, mask_and_flip_indicator)  # important to use x here and not data.x\n",
    "  out_incorrect = model(x, data.edge_index, data.batch) # is supposed to be 0 everywhere\n",
    "  loss_for_graph =  out_incorrect - out_correct # between -1 and 1\n",
    "  loss_for_graph = (loss_for_graph + 1.0) / 2.0   # between 0 and 1,\n",
    "  return loss_for_graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "id": "-_84ieMIoYh5"
   },
   "outputs": [],
   "source": [
    "def feed_data_to_model(data, model, config):\n",
    "  if config.single_pass == True:\n",
    "    return single_pass_prediction(data, model, config)\n",
    "  return multi_pass_prediction(data, model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 264], x=[78, 1])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_dataset_train, graph_dataset_test  = build_dataset()\n",
    "graph_dataset_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f8RF9E-wfDXW"
   },
   "source": [
    "### Start Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "id": "lDBAh9XPiO-a"
   },
   "outputs": [],
   "source": [
    "def start_agent(config):\n",
    "  graph_dataset_train, graph_dataset_test = build_dataset()\n",
    "  #graphs_ref_nx = build_test_set_nx(seed=42)\n",
    "  degree_loss, cluster_loss = compute_expected_optimal_loss(graph_dataset_train, graph_dataset_test)\n",
    "  print('Reference distance is: ', degree_loss, cluster_loss)\n",
    "  wandb.log({\"stats/degree_train\": degree_loss,  \"stats/cluster_train\": cluster_loss})\n",
    "\n",
    "  model = build_model(config, graph_dataset)\n",
    "  wandb.log({\"num_parameters\": sum(p.numel() for p in model.parameters())})\n",
    "\n",
    "  optimizer = Adam(model.parameters(), lr = config.learning_rate) \n",
    "  train_loader = DataLoader(graph_dataset_train, batch_size=config.batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "  for epoch_i in range(NUM_EPOCHS):\n",
    "    loss_list = list()\n",
    "    for step, data in enumerate(train_loader):\n",
    "      data.to(DEVICE)\n",
    "      model.train()\n",
    "      model.zero_grad()\n",
    "\n",
    "      loss_for_graph = feed_data_to_model(data, model, config) # between 0 and 1, probabilty of the incorrect choice\n",
    "      loss = reduce_loss(loss_for_graph, config)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      loss =  ((loss_for_graph.mean()).item()  -0.5 ) * 2.0 # between - 0.5 and 0.5 -> between - 1 and 1\n",
    "      loss_list.append(loss)\n",
    "      #wandb.log({\"epoch\": epoch_i+1, \"loss\": np.mean(loss_list)})\n",
    "\n",
    "    print('epoch: {:06}  loss: {:.5f}'.format(epoch_i+1 ,np.mean(loss_list)))\n",
    "    # early stopping\n",
    "    if np.mean(loss_list) > -0.000001 and (epoch_i > 199 and epoch_i % 100 == 0):\n",
    "      return\n",
    "\n",
    "    if epoch_i % GENERATE_X_EPOCHS == 0 or epoch_i == NUM_EPOCHS-1:\n",
    "      dummy_graph = graph_dataset_train[0].clone().to(DEVICE)\n",
    "      print(\"start graph generation\")\n",
    "      deg_mean, deg_var, graphs_pred_nx = generate_graphs(NUM_GRAPHS_GENERATE, epoch_i, model, dummy_graph, config)\n",
    "      print(\"finish graph generation\")\n",
    "      generator_loss = (DEGREE-deg_mean)**2 + deg_var\n",
    "      wandb.log({\"graph-unmasking/gen-loss\": generator_loss, \"mean degree\": deg_mean, \"mean degree var\":deg_var, \"graph-unmasking/loss\": np.mean(loss_list)})\n",
    "      degree_loss, cluster_loss = compute_mmd_stats(graphs_pred_nx, graph_dataset_test)\n",
    "      wandb.log({\"stats/degree\": degree_loss,  \"stats/cluster\": cluster_loss})\n",
    "      print(deg_mean, deg_var, degree_loss, cluster_loss)\n",
    "\n",
    "  torch.save(model.state_dict(), \"model.weights\")\n",
    "  wandb.log_artifact(\"model.weights\", name=f'nn_weights_{SWEEP_ID}', type='weights') \n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "id": "qPcPralV7IF0"
   },
   "outputs": [],
   "source": [
    "def start_agent_envelope():\n",
    "  try:\n",
    "    with wandb.init():\n",
    "      config = wandb.config\n",
    "      set_seeds(SWEEP_ID)\n",
    "      print(SWEEP_ID, config)\n",
    "      if not IN_COLAB:\n",
    "        for python_file in sorted(glob.glob('*.ipynb')):\n",
    "          wandb.log_artifact(python_file, name=f\"src_ipynb_{SWEEP_ID}\", type=\"my_dataset\")\n",
    "        for python_file in sorted(glob.glob('*.py')):\n",
    "          wandb.log_artifact(python_file, name=f\"src_py_{SWEEP_ID}\", type=\"my_dataset\")\n",
    "      return start_agent(config)\n",
    "  except Exception:\n",
    "    print(traceback.format_exc())\n",
    "    wandb.log({\"graph-unmasking/gen-loss\": -1,  \"epoch\": -1, \"graph-unmasking/loss\": -1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OHuZY5f_4NrN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 000071  loss: -0.22832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: tvg32r8y\n",
      "Sweep URL: https://wandb.ai/nextaid/toad_double/sweeps/tvg32r8y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: a1v5vtic with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcandidate_selection_radius: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdouble_inference: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgraph_transform: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: bce\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: pna\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnoise_probability: 0.05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnormalization: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_post_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_pass: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttowers: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<IPython.core.display.HTML object>\n",
      "<IPython.core.display.HTML object>\n",
      "<IPython.core.display.HTML object>\n",
      "<IPython.core.display.HTML object>\n",
      "epoch: 000072  loss: -0.20841\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tvg32r8y {'batch_size': 100, 'candidate_selection_radius': 5, 'double_inference': True, 'dropout': 0, 'graph_transform': True, 'hidden_dim': 64, 'hidden_layer': 5, 'learning_rate': 1e-05, 'loss': 'bce', 'model': 'pna', 'noise_probability': 0.05, 'normalization': True, 'pre_post_layers': 1, 'single_pass': True, 'towers': 2}\n",
      "Reference distance is:  0.0 0.009534636872397473\n",
      "epoch: 000073  loss: -0.18126\n",
      "epoch: 000001  loss: -0.02912\n",
      "start graph generation\n",
      "candidates  [58, 72, 40, 60, 49]\n",
      "candidates  [72, 40, 60, 49, 43]\n",
      "candidates  [40, 60, 49, 43, 50]\n",
      "candidates  [60, 49, 43, 50, 64]\n",
      "candidates  [49, 43, 50, 64, 21]\n",
      "candidates  [43, 50, 64, 21, 56]\n",
      "candidates  [50, 64, 21, 56, 42]\n",
      "candidates  [64, 21, 56, 42, 68]\n",
      "candidates  [21, 56, 42, 68, 65]\n",
      "candidates  [56, 42, 68, 65, 75]\n",
      "candidates  [42, 68, 65, 75, 5]\n",
      "candidates  [68, 65, 75, 5, 35]\n",
      "candidates  [65, 75, 5, 35, 47]\n",
      "candidates  [75, 5, 35, 47, 59]\n",
      "candidates  [5, 35, 47, 59, 33]\n",
      "candidates  [35, 47, 59, 33, 71]\n",
      "epoch: 000074  loss: -0.16735\n",
      "candidates  [47, 59, 33, 71, 17]\n",
      "candidates  [59, 33, 71, 17, 66]\n",
      "candidates  [33, 71, 17, 66, 11]\n",
      "candidates  [71, 17, 66, 11, 3]\n",
      "candidates  [17, 66, 11, 3, 63]\n",
      "candidates  [66, 11, 3, 63, 48]\n",
      "candidates  [11, 3, 63, 48, 36]\n",
      "candidates  [3, 63, 48, 36, 19]\n",
      "candidates  [63, 48, 36, 19, 24]\n",
      "candidates  [48, 36, 19, 24, 15]\n",
      "candidates  [36, 19, 24, 15, 74]\n",
      "candidates  [19, 24, 15, 74, 38]\n",
      "candidates  [24, 15, 74, 38, 73]\n",
      "candidates  [15, 74, 38, 73, 9]\n",
      "candidates  [74, 38, 73, 9, 1]\n",
      "candidates  [38, 73, 9, 1, 28]\n",
      "candidates  [73, 9, 1, 28, 26]\n",
      "candidates  [9, 1, 28, 26, 29]\n",
      "candidates  [1, 28, 26, 29, 39]\n",
      "candidates  [28, 26, 29, 39, 30]\n",
      "candidates  [26, 29, 39, 30, 13]\n",
      "candidates  [29, 39, 30, 13, 23]\n",
      "candidates  [39, 30, 13, 23, 62]\n",
      "candidates  [30, 13, 23, 62, 51]\n",
      "candidates  [13, 23, 62, 51, 54]\n",
      "candidates  [23, 62, 51, 54, 53]\n",
      "candidates  [62, 51, 54, 53, 76]\n",
      "candidates  [51, 54, 53, 76, 34]\n",
      "candidates  [54, 53, 76, 34, 55]\n",
      "candidates  [53, 76, 34, 55, 46]\n",
      "candidates  [76, 34, 55, 46, 70]\n",
      "candidates  [34, 55, 46, 70, 37]\n",
      "candidates  [55, 46, 70, 37, 25]\n",
      "candidates  [46, 70, 37, 25, 32]\n",
      "candidates  [70, 37, 25, 32, 41]\n",
      "candidates  [37, 25, 32, 41, 57]\n",
      "candidates  [25, 32, 41, 57, 52]\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"WANDB_MODE\"] = WANDB_MODE \n",
    "\n",
    "SWEEP_ID = wandb.sweep(sweep_config, project=PROJECT_NAME)\n",
    "wandb.agent(SWEEP_ID, project=PROJECT_NAME, function=start_agent_envelope, count=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DHcAvy-w6Zlu"
   },
   "outputs": [],
   "source": [
    "jljkl = sdfljldf/0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tg-wy3DnJRA9"
   },
   "source": [
    "# Load graph datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NWlIj_iUJUtp"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.system(\"git clone https://github.com/KarolisMart/SPECTRE.git\")\n",
    "\n",
    "\n",
    "from argparse import ArgumentParser\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "#import pytorch_lightning as pl\n",
    "import networkx as nx\n",
    "from torch.utils.data import random_split, DataLoader, Dataset\n",
    "from scipy.spatial import Delaunay\n",
    "#from torch_geometric.datasets import QM9\n",
    "#from rdkit import Chem\n",
    "#from torch_geometric.utils import dense_to_sparse, to_dense_adj, to_networkx\n",
    "\n",
    "#from util.eval_helper import degree_stats, orbit_stats_all, clustering_stats, spectral_stats, eigval_stats, compute_list_eigh, spectral_filter_stats\n",
    "#from util.molecular_eval import BasicMolecularMetrics\n",
    "\n",
    "\n",
    "class SpectreGraphDataset(Dataset):\n",
    "    def __init__(self, data_file):\n",
    "        \"\"\" This class can be used to load the comm20, sbm and planar datasets. \"\"\"\n",
    "        base_path = 'SPECTRE/data/'\n",
    "        filename = os.path.join(base_path, data_file)\n",
    "        self.adjs, self.eigvals, self.eigvecs, self.n_nodes, self.max_eigval, self.min_eigval, self.same_sample, self.n_max = torch.load(\n",
    "            filename)\n",
    "        print(f'Dataset {filename} loaded from file')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.adjs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        adj = self.adjs[idx]\n",
    "        n = adj.shape[-1]\n",
    "        X = torch.ones(n, 1, dtype=torch.float)\n",
    "        y = torch.zeros([1, 0]).float()\n",
    "        edge_index, _ = torch_geometric.utils.dense_to_sparse(adj)\n",
    "        edge_attr = torch.zeros(edge_index.shape[-1], 2, dtype=torch.float)\n",
    "        edge_attr[:, 1] = 1\n",
    "        num_nodes = n * torch.ones(1, dtype=torch.long)\n",
    "        data = torch_geometric.data.Data(x=X, edge_index=edge_index, edge_attr=edge_attr,\n",
    "                                         y=y, idx=idx, n_nodes=num_nodes)\n",
    "        return data\n",
    "\n",
    "\n",
    "class PlanarDataset(SpectreGraphDataset):\n",
    "    def __init__(self):\n",
    "        super().__init__('planar_64_200.pt')\n",
    "\n",
    "\n",
    "PlanarDataset()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t9QJ8aL44va_"
   },
   "outputs": [],
   "source": [
    "\n",
    "adjs, eigvals, eigvecs, n_nodes, max_eigval, min_eigval, same_sample, n_max = torch.load('SPECTRE/data/planar_64_200.pt')\n",
    "adjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_rZedjy0wJxy"
   },
   "outputs": [],
   "source": [
    "graphs = adjs\n",
    "test_len = int(round(len(graphs) * 0.2))\n",
    "train_len = int(round((len(graphs) - test_len) * 0.8))\n",
    "val_len = len(graphs) - train_len - test_len\n",
    "print(f'Dataset sizes: train {train_len}, val {val_len}, test {test_len}')\n",
    "splits = random_split(graphs, [train_len, val_len, test_len], generator=torch.Generator().manual_seed(1234))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AK2hS79yrqST"
   },
   "source": [
    "### next try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D_GqY9tyuKpA"
   },
   "outputs": [],
   "source": [
    "os.system(\"pip install omegaconf\")\n",
    "os.system(\"pip install pytorch_lightning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jJJ8ICD9vgCQ"
   },
   "outputs": [],
   "source": [
    "os.system(\"pip install overrides\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XGc8eQCbrrd0"
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "os.system(\"git clone https://github.com/cvignac/DiGress.git\")\n",
    "os.system(\"cp -r DiGress/src src/\")\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import random_split, Dataset\n",
    "import torch_geometric.utils\n",
    "\n",
    "from src.datasets.abstract_dataset import AbstractDataModule, AbstractDatasetInfos\n",
    "\n",
    "\n",
    "class SpectreGraphDataset(Dataset):\n",
    "    def __init__(self, data_file):\n",
    "        \"\"\" This class can be used to load the comm20, sbm and planar datasets. \"\"\"\n",
    "        base_path = os.path.join(os.path.dirname(os.path.realpath(__file__)), os.pardir, os.pardir, 'data')\n",
    "        filename = os.path.join(base_path, data_file)\n",
    "        self.adjs, self.eigvals, self.eigvecs, self.n_nodes, self.max_eigval, self.min_eigval, self.same_sample, self.n_max = torch.load(\n",
    "            filename)\n",
    "        print(f'Dataset {filename} loaded from file')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.adjs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        adj = self.adjs[idx]\n",
    "        n = adj.shape[-1]\n",
    "        X = torch.ones(n, 1, dtype=torch.float)\n",
    "        y = torch.zeros([1, 0]).float()\n",
    "        edge_index, _ = torch_geometric.utils.dense_to_sparse(adj)\n",
    "        edge_attr = torch.zeros(edge_index.shape[-1], 2, dtype=torch.float)\n",
    "        edge_attr[:, 1] = 1\n",
    "        num_nodes = n * torch.ones(1, dtype=torch.long)\n",
    "        data = torch_geometric.data.Data(x=X, edge_index=edge_index, edge_attr=edge_attr,\n",
    "                                         y=y, idx=idx, n_nodes=num_nodes)\n",
    "        return data\n",
    "\n",
    "class SpectreGraphDataModule(AbstractDataModule):\n",
    "    def __init__(self, cfg, n_graphs=200):\n",
    "        super().__init__(cfg)\n",
    "        self.n_graphs = n_graphs\n",
    "        self.prepare_data()\n",
    "        self.inner = self.train_dataloader()\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.inner[item]\n",
    "\n",
    "    def prepare_data(self, graphs):\n",
    "        test_len = int(round(len(graphs) * 0.2))\n",
    "        train_len = int(round((len(graphs) - test_len) * 0.8))\n",
    "        val_len = len(graphs) - train_len - test_len\n",
    "        print(f'Dataset sizes: train {train_len}, val {val_len}, test {test_len}')\n",
    "        splits = random_split(graphs, [train_len, val_len, test_len], generator=torch.Generator().manual_seed(1234))\n",
    "\n",
    "        datasets = {'train': splits[0], 'val': splits[1], 'test': splits[2]}\n",
    "        super().prepare_data(datasets)\n",
    "\n",
    "class Comm20Dataset(SpectreGraphDataset):\n",
    "    def __init__(self):\n",
    "        super().__init__('community_12_21_100.pt')\n",
    "\n",
    "\n",
    "class SBMDataset(SpectreGraphDataset):\n",
    "    def __init__(self):\n",
    "        super().__init__('sbm_200.pt')\n",
    "\n",
    "\n",
    "class PlanarDataset(SpectreGraphDataset):\n",
    "    def __init__(self):\n",
    "        super().__init__('planar_64_200.pt')\n",
    "\n",
    "dataset = PlanarDataset()\n",
    "dataset.prepare_data\n",
    "dataset.datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JbPFtDS8x810"
   },
   "source": [
    "# Quality Measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9oSqDFX4x_7C"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pCDeFcFFyVRQ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.system(\"pip install pyemd\")\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9s_ZCqiiyVfj"
   },
   "outputs": [],
   "source": [
    "import pyemd\n",
    "import numpy as np\n",
    "import concurrent.futures\n",
    "from functools import partial\n",
    "from scipy.linalg import toeplitz\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "PRINT_TIME = False\n",
    "\n",
    "def degree_worker(G):\n",
    "    return np.array(nx.degree_histogram(G))\n",
    "\n",
    "def degree_stats(graph_ref_list, graph_pred_list, is_parallel=True, compute_emd=False):\n",
    "    ''' Compute the distance between the degree distributions of two unordered sets of graphs.\n",
    "        Args:\n",
    "            graph_ref_list, graph_target_list: two lists of networkx graphs to be evaluated\n",
    "        '''\n",
    "    sample_ref = []\n",
    "    sample_pred = []\n",
    "    # in case an empty graph is generated\n",
    "    graph_pred_list_remove_empty = [\n",
    "        G for G in graph_pred_list if not G.number_of_nodes() == 0\n",
    "    ]\n",
    "\n",
    "    prev = datetime.now()\n",
    "    if is_parallel:\n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            for deg_hist in executor.map(degree_worker, graph_ref_list):\n",
    "                sample_ref.append(deg_hist)\n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            for deg_hist in executor.map(degree_worker, graph_pred_list_remove_empty):\n",
    "                sample_pred.append(deg_hist)\n",
    "    else:\n",
    "        for i in range(len(graph_ref_list)):\n",
    "            degree_temp = np.array(nx.degree_histogram(graph_ref_list[i]))\n",
    "            sample_ref.append(degree_temp)\n",
    "        for i in range(len(graph_pred_list_remove_empty)):\n",
    "            degree_temp = np.array(\n",
    "                nx.degree_histogram(graph_pred_list_remove_empty[i]))\n",
    "            sample_pred.append(degree_temp)\n",
    "\n",
    "    # mmd_dist = compute_mmd(sample_ref, sample_pred, kernel=gaussian_emd)\n",
    "    # mmd_dist = compute_mmd(sample_ref, sample_pred, kernel=emd)\n",
    "    if compute_emd:\n",
    "        # EMD option uses the same computation as GraphRNN, the alternative is MMD as computed by GRAN\n",
    "        # mmd_dist = compute_mmd(sample_ref, sample_pred, kernel=emd)\n",
    "        mmd_dist = compute_mmd(sample_ref, sample_pred, kernel=gaussian_emd)\n",
    "    else:\n",
    "        mmd_dist = compute_mmd(sample_ref, sample_pred, kernel=gaussian_tv)\n",
    "    # mmd_dist = compute_mmd(sample_ref, sample_pred, kernel=gaussian)\n",
    "\n",
    "    elapsed = datetime.now() - prev\n",
    "    if PRINT_TIME:\n",
    "        print('Time computing degree mmd: ', elapsed)\n",
    "    return mmd_dist\n",
    "\n",
    "\n",
    "\n",
    "def clustering_worker(param):\n",
    "    G, bins = param\n",
    "    clustering_coeffs_list = list(nx.clustering(G).values())\n",
    "    hist, _ = np.histogram(\n",
    "        clustering_coeffs_list, bins=bins, range=(0.0, 1.0), density=False)\n",
    "    return hist\n",
    "\n",
    "\n",
    "def clustering_stats(graph_ref_list,\n",
    "                     graph_pred_list,\n",
    "                     bins=100,\n",
    "                     is_parallel=True, compute_emd=False):\n",
    "    sample_ref = []\n",
    "    sample_pred = []\n",
    "    graph_pred_list_remove_empty = [\n",
    "        G for G in graph_pred_list if not G.number_of_nodes() == 0\n",
    "    ]\n",
    "\n",
    "    prev = datetime.now()\n",
    "    if is_parallel:\n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            for clustering_hist in executor.map(clustering_worker,\n",
    "                                                [(G, bins) for G in graph_ref_list]):\n",
    "                sample_ref.append(clustering_hist)\n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            for clustering_hist in executor.map(\n",
    "                    clustering_worker, [(G, bins) for G in graph_pred_list_remove_empty]):\n",
    "                sample_pred.append(clustering_hist)\n",
    "\n",
    "        # check non-zero elements in hist\n",
    "        # total = 0\n",
    "        # for i in range(len(sample_pred)):\n",
    "        #    nz = np.nonzero(sample_pred[i])[0].shape[0]\n",
    "        #    total += nz\n",
    "        # print(total)\n",
    "    else:\n",
    "        for i in range(len(graph_ref_list)):\n",
    "            clustering_coeffs_list = list(nx.clustering(graph_ref_list[i]).values())\n",
    "            hist, _ = np.histogram(\n",
    "                clustering_coeffs_list, bins=bins, range=(0.0, 1.0), density=False)\n",
    "            sample_ref.append(hist)\n",
    "\n",
    "        for i in range(len(graph_pred_list_remove_empty)):\n",
    "            clustering_coeffs_list = list(\n",
    "                nx.clustering(graph_pred_list_remove_empty[i]).values())\n",
    "            hist, _ = np.histogram(\n",
    "                clustering_coeffs_list, bins=bins, range=(0.0, 1.0), density=False)\n",
    "            sample_pred.append(hist)\n",
    "\n",
    "    if compute_emd:\n",
    "        # EMD option uses the same computation as GraphRNN, the alternative is MMD as computed by GRAN\n",
    "        # mmd_dist = compute_mmd(sample_ref, sample_pred, kernel=emd, sigma=1.0 / 10)\n",
    "        mmd_dist = compute_mmd(sample_ref, sample_pred, kernel=gaussian_emd, sigma=1.0 / 10, distance_scaling=bins)\n",
    "    else:\n",
    "        mmd_dist = compute_mmd(sample_ref, sample_pred, kernel=gaussian_tv, sigma=1.0 / 10)\n",
    "\n",
    "    elapsed = datetime.now() - prev\n",
    "    if PRINT_TIME:\n",
    "        print('Time computing clustering mmd: ', elapsed)\n",
    "    return mmd_dist\n",
    "\n",
    "\n",
    "\n",
    "# maps motif/orbit name string to its corresponding list of indices from orca output\n",
    "motif_to_indices = {\n",
    "    '3path': [1, 2],\n",
    "    '4cycle': [8],\n",
    "}\n",
    "COUNT_START_STR = 'orbit counts:'\n",
    "\n",
    "\n",
    "def edge_list_reindexed(G):\n",
    "    idx = 0\n",
    "    id2idx = dict()\n",
    "    for u in G.nodes():\n",
    "        id2idx[str(u)] = idx\n",
    "        idx += 1\n",
    "\n",
    "    edges = []\n",
    "    for (u, v) in G.edges():\n",
    "        edges.append((id2idx[str(u)], id2idx[str(v)]))\n",
    "    return edges\n",
    "\n",
    "def orca(graph):\n",
    "    # tmp_fname = f'analysis/orca/tmp_{\"\".join(secrets.choice(ascii_uppercase + digits) for i in range(8))}.txt'\n",
    "    tmp_fname = f'orca/tmp_{\"\".join(secrets.choice(ascii_uppercase + digits) for i in range(8))}.txt'\n",
    "    tmp_fname = os.path.join(os.path.dirname(os.path.realpath(__file__)), tmp_fname)\n",
    "    # print(tmp_fname, flush=True)\n",
    "    f = open(tmp_fname, 'w')\n",
    "    f.write(\n",
    "        str(graph.number_of_nodes()) + ' ' + str(graph.number_of_edges()) + '\\n')\n",
    "    for (u, v) in edge_list_reindexed(graph):\n",
    "        f.write(str(u) + ' ' + str(v) + '\\n')\n",
    "    f.close()\n",
    "    output = sp.check_output(\n",
    "        [str(os.path.join(os.path.dirname(os.path.realpath(__file__)), 'orca/orca')), 'node', '4', tmp_fname, 'std'])\n",
    "    output = output.decode('utf8').strip()\n",
    "    idx = output.find(COUNT_START_STR) + len(COUNT_START_STR) + 2\n",
    "    output = output[idx:]\n",
    "    node_orbit_counts = np.array([\n",
    "        list(map(int,\n",
    "                 node_cnts.strip().split(' ')))\n",
    "        for node_cnts in output.strip('\\n').split('\\n')\n",
    "    ])\n",
    "\n",
    "    try:\n",
    "        os.remove(tmp_fname)\n",
    "    except OSError:\n",
    "        pass\n",
    "\n",
    "    return node_orbit_counts\n",
    "\n",
    "\n",
    "def orbit_stats_all(graph_ref_list, graph_pred_list, compute_emd=False):\n",
    "    total_counts_ref = []\n",
    "    total_counts_pred = []\n",
    "\n",
    "    graph_pred_list_remove_empty = [\n",
    "        G for G in graph_pred_list if not G.number_of_nodes() == 0\n",
    "    ]\n",
    "\n",
    "    for G in graph_ref_list:\n",
    "        orbit_counts = orca(G)\n",
    "        orbit_counts_graph = np.sum(orbit_counts, axis=0) / G.number_of_nodes()\n",
    "        total_counts_ref.append(orbit_counts_graph)\n",
    "\n",
    "    for G in graph_pred_list:\n",
    "        orbit_counts = orca(G)\n",
    "        orbit_counts_graph = np.sum(orbit_counts, axis=0) / G.number_of_nodes()\n",
    "        total_counts_pred.append(orbit_counts_graph)\n",
    "\n",
    "    total_counts_ref = np.array(total_counts_ref)\n",
    "    total_counts_pred = np.array(total_counts_pred)\n",
    "\n",
    "    # mmd_dist = compute_mmd(\n",
    "    #     total_counts_ref,\n",
    "    #     total_counts_pred,\n",
    "    #     kernel=gaussian,\n",
    "    #     is_hist=False,\n",
    "    #     sigma=30.0)\n",
    "\n",
    "    # mmd_dist = compute_mmd(\n",
    "    #         total_counts_ref,\n",
    "    #         total_counts_pred,\n",
    "    #         kernel=gaussian_tv,\n",
    "    #         is_hist=False,\n",
    "    #         sigma=30.0)  \n",
    "\n",
    "    if compute_emd:\n",
    "        # mmd_dist = compute_mmd(total_counts_ref, total_counts_pred, kernel=emd, sigma=30.0)\n",
    "        # EMD option uses the same computation as GraphRNN, the alternative is MMD as computed by GRAN\n",
    "        mmd_dist = compute_mmd(total_counts_ref, total_counts_pred, kernel=gaussian, is_hist=False, sigma=30.0)\n",
    "    else:\n",
    "        mmd_dist = compute_mmd(total_counts_ref, total_counts_pred, kernel=gaussian_tv, is_hist=False, sigma=30.0)\n",
    "    return mmd_dist\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def gaussian(x, y, sigma=1.0):\n",
    "    support_size = max(len(x), len(y))\n",
    "    # convert histogram values x and y to float, and make them equal len\n",
    "    x = x.astype(float)\n",
    "    y = y.astype(float)\n",
    "    if len(x) < len(y):\n",
    "        x = np.hstack((x, [0.0] * (support_size - len(x))))\n",
    "    elif len(y) < len(x):\n",
    "        y = np.hstack((y, [0.0] * (support_size - len(y))))\n",
    "\n",
    "    dist = np.linalg.norm(x - y, 2)\n",
    "    return np.exp(-dist * dist / (2 * sigma * sigma))\n",
    "\n",
    "\n",
    "def gaussian_tv(x, y, sigma=1.0):  \n",
    "    support_size = max(len(x), len(y))\n",
    "    # convert histogram values x and y to float, and make them equal len\n",
    "    x = x.astype(float)\n",
    "    y = y.astype(float)\n",
    "    if len(x) < len(y):\n",
    "        x = np.hstack((x, [0.0] * (support_size - len(x))))\n",
    "    elif len(y) < len(x):\n",
    "        y = np.hstack((y, [0.0] * (support_size - len(y))))\n",
    "\n",
    "    dist = np.abs(x - y).sum() / 2.0\n",
    "    return np.exp(-dist * dist / (2 * sigma * sigma))\n",
    "\n",
    "\n",
    "def kernel_parallel_unpacked(x, samples2, kernel):\n",
    "    d = 0\n",
    "    for s2 in samples2:\n",
    "        d += kernel(x, s2)\n",
    "    return d\n",
    "\n",
    "\n",
    "def kernel_parallel_worker(t):\n",
    "    return kernel_parallel_unpacked(*t)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def disc(samples1, samples2, kernel, is_parallel=True, *args, **kwargs):\n",
    "    ''' Discrepancy between 2 samples '''\n",
    "    d = 0\n",
    "\n",
    "    if not is_parallel:\n",
    "        for s1 in samples1:\n",
    "            for s2 in samples2:\n",
    "                d += kernel(s1, s2, *args, **kwargs)\n",
    "    else:\n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            for dist in executor.map(kernel_parallel_worker, [\n",
    "                    (s1, samples2, partial(kernel, *args, **kwargs)) for s1 in samples1\n",
    "            ]):\n",
    "                d += dist\n",
    "    if len(samples1) * len(samples2) > 0:\n",
    "        d /= len(samples1) * len(samples2)\n",
    "    else:\n",
    "        d = 1e+6\n",
    "    #print('error')\n",
    "    return d\n",
    "\n",
    "\n",
    "def compute_mmd(samples1, samples2, kernel, is_hist=True, *args, **kwargs):\n",
    "    ''' MMD between two samples '''\n",
    "    # normalize histograms into pmf\n",
    "    if is_hist:\n",
    "        samples1 = [s1 / (np.sum(s1) + 1e-6) for s1 in samples1]\n",
    "        samples2 = [s2 / (np.sum(s2) + 1e-6) for s2 in samples2]\n",
    "    print(samples1)\n",
    "    return disc(samples1, samples1, kernel, *args, **kwargs) + disc(samples2, samples2, kernel, *args, **kwargs) - \\\n",
    "                2 * disc(samples1, samples2, kernel, *args, **kwargs)\n",
    "\n",
    "\n",
    "def compute_emd(samples1, samples2, kernel, is_hist=True, *args, **kwargs):\n",
    "    ''' EMD between average of two samples '''\n",
    "    # normalize histograms into pmf\n",
    "    if is_hist:\n",
    "        samples1 = [np.mean(samples1)]\n",
    "        samples2 = [np.mean(samples2)]\n",
    "    return disc(samples1, samples2, kernel, *args,\n",
    "                            **kwargs), [samples1[0], samples2[0]]\n",
    "\n",
    "\n",
    "\n",
    "def compute_mmd_stats(graphs_ref_nx, graphs_pred_nx):\n",
    "    return degree_stats(graphs_ref_nx, graphs_pred_nx), clustering_stats(graphs_ref_nx, graphs_pred_nx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pscy53ZLz9Se"
   },
   "outputs": [],
   "source": [
    "samples1 = [np.array([1,2,3.0]),  np.array([1,20,4.0])]\n",
    "samples2 = [np.array([1,2,3.5]),  np.array([1,20,4.5])]\n",
    "\n",
    "compute_mmd(samples1, samples2, kernel=gaussian_tv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LTAYm3qa2rr_"
   },
   "outputs": [],
   "source": [
    "samples1 = [np.array([1,200,3.0]),  np.array([1,20,4.0])]\n",
    "samples2 = [np.array([1,2,3.01]),  np.array([1,20,4.01])]\n",
    "\n",
    "compute_mmd(samples1, samples2, kernel=gaussian_tv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zpfa0Ldw0Pkm"
   },
   "outputs": [],
   "source": [
    "graph_ref_list = [nx.erdos_renyi_graph(15, 0.5) for _ in range(15) ]\n",
    "graph_pred_list = [nx.erdos_renyi_graph(15, 0.5) for _ in range(15) ]\n",
    "\n",
    "degree_stats(graph_ref_list, graph_pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DVv3mnMY-fal"
   },
   "outputs": [],
   "source": [
    "graph_ref_list = [nx.erdos_renyi_graph(15, 0.5) for _ in range(15) ]\n",
    "graph_pred_list = [nx.erdos_renyi_graph(15, 0.9) for _ in range(15) ]\n",
    "\n",
    "degree_stats(graph_ref_list, graph_pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4ScNBY6Z-vqM"
   },
   "outputs": [],
   "source": [
    "graph_ref_list = [nx.erdos_renyi_graph(15, 0.1) for _ in range(15) ]\n",
    "graph_pred_list = [nx.erdos_renyi_graph(15, 0.5) for _ in range(15) ]\n",
    "\n",
    "clustering_stats(graph_ref_list, graph_pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7O9ZYYVk4rWL"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMR74OtRj8zkHMB/tLBN7/H",
   "include_colab_link": true,
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
