{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ulnOzsCCmA8g"
   },
   "source": [
    "\n",
    "# <img src=\"https://mario.wiki.gallery/images/thumb/8/89/MPS_Toad_Artwork.png/170px-MPS_Toad_Artwork.png\" alt=\"Dataset Summary\" width=\"3%\">  Batched Toad  <img src=\"https://mario.wiki.gallery/images/thumb/8/89/MPS_Toad_Artwork.png/170px-MPS_Toad_Artwork.png\" alt=\"Dataset Summary\" width=\"3%\"> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rCWLJT5DLH78"
   },
   "source": [
    "Todos:\n",
    "- weightes sampling\n",
    "- multi-channel\n",
    "- uncertainty\n",
    "- better ensable like skip one during training or learn weights\n",
    "- to make network better: virutal node, degree input, spectral input, edge features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x-k6-4CDmEwH"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "Csn1_ff8mJCE"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys, os\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "\n",
    "\n",
    "PATH_TO_NOTEBOOK = \"Batched Toad 3.ipynb\"\n",
    "PROJECT_NAME = \"toad_laptop_backup\"\n",
    "KEY = \"e306abc657482e172a5ccc8d7c0b81bc4d297dd4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "cN9PW__MvfFk"
   },
   "outputs": [],
   "source": [
    "def get_wand_api_key():\n",
    "  api_key = KEY\n",
    "  # use   echo \"your_api_key_here\" > ~/api_key.txt   to write the api key to the home file dir    \n",
    "  if api_key != \"\":\n",
    "    return api_key\n",
    "  home_dir = os.path.expanduser('~')\n",
    "  file_path = os.path.join(home_dir, 'api_key.txt')\n",
    "  with open(file_path, 'r') as file:\n",
    "      api_key = file.read().strip()\n",
    "  return api_key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e306abc657482e172a5ccc8d7c0b81bc4d297dd4'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_wand_api_key()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mUcQ44Bj42GY"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "nKbKpbiSmMfW"
   },
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.dpi'] = 100 # Set this to 300 to get better image quality\n",
    "from PIL import Image # We use PIL to load images\n",
    "import seaborn as sns\n",
    "import imageio # to generate .gifs\n",
    "\n",
    "# always good to have\n",
    "import glob, random, os, traceback\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import math\n",
    "\n",
    "# the typical pytorch imports\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torch.nn import Linear as Lin\n",
    "from torch.nn import Sequential as Seq\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# PyG\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import erdos_renyi_graph, to_networkx, from_networkx\n",
    "from torch_geometric.nn import GINConv\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import global_mean_pool, global_add_pool\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "#Video\n",
    "from PIL import Image, ImageDraw\n",
    "#import cv2\n",
    "from IPython.display import HTML\n",
    "from base64 import b64encode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SAyrOuvomPAE"
   },
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZaElc28pmSzf",
    "outputId": "4c95e1d8-65e6-4aed-bb11-13e55ea20e81"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_NODES = 12 #12   \n",
    "DEGREE = 3 #3\n",
    "NUM_EPOCHS = 2000\n",
    "\n",
    "NUM_SAMPLES = 1000\n",
    "NUM_GRAPHS_GENERATE = 10\n",
    "\n",
    "NO_EDGE_INDICATOR = 3.0\n",
    "EDGE_INDICATOR = 1.0 \n",
    "DUMMY = 0.0 # this node is an actual node not a placeholder for an edge\n",
    "MASK = 2.0\n",
    "NUM_CLASSES = 4  #todo change to 5 an\n",
    "\n",
    "EPSILON = 0.000000001\n",
    "\n",
    "NODE_FEATURE_EXTEND = 3\n",
    "\n",
    "BATCH_SIZE_TEST = 10\n",
    "#TIME_EMBEDDING_DIM = 1\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#DEVICE = torch.device('cpu')\n",
    "DEVICE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qWpdimGn3fDH"
   },
   "source": [
    "### Seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "eCtxrGI4mVz2"
   },
   "outputs": [],
   "source": [
    "# from stack overflow\n",
    "def str_to_float(s, encoding=\"utf-8\"):\n",
    "  from zlib import crc32\n",
    "  def bytes_to_float(b):\n",
    "    return float(crc32(b) & 0xffffffff) / 2**32\n",
    "  return bytes_to_float(s.encode(encoding))\n",
    "\n",
    "    \n",
    "def set_seeds(seed=42):\n",
    "  if not \"int\" in str(type(seed)):\n",
    "    seed = int(str_to_float(str(seed))*1000 % 100000000)\n",
    "  np.random.seed(seed)\n",
    "  torch.random.manual_seed(seed)\n",
    "  random.seed(seed)\n",
    "  torch.cuda.manual_seed_all(seed)\n",
    "  os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "  torch.backends.cudnn.deterministic = True\n",
    "\n",
    "set_seeds()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "32hyXlJG8360"
   },
   "source": [
    "## Weights and Biases Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i_pixfTW84rq",
    "outputId": "e14888df-a769-4b9c-a792-9dde66d6d273"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'method': 'random',\n",
      " 'metric': {'goal': 'minimize', 'name': 'graph-unmasking/gen-loss'},\n",
      " 'name': 'graph-unmasking',\n",
      " 'parameters': {'batch_size': {'values': [50, 100, 200, 500]},\n",
      "                'candidate_selection_radius': {'values': [1, 5]},\n",
      "                'dropout': {'values': [0.0]},\n",
      "                'graph_transform': {'values': [True, False]},\n",
      "                'hidden_dim': {'values': [16, 32, 64]},\n",
      "                'hidden_layer': {'values': [4, 5, 6]},\n",
      "                'learning_rate': {'values': [1e-05, 5e-05, 0.0001]},\n",
      "                'loss': {'values': ['bce']},\n",
      "                'model': {'values': ['pna']},\n",
      "                'noise_probability': {'values': [0.0, 0.05, 0.1]},\n",
      "                'normalization': {'values': [True, False]},\n",
      "                'pre_post_layers': {'values': [1]},\n",
      "                'single_pass': {'values': [True]},\n",
      "                'towers': {'values': [1, 2]}}}\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login(key=get_wand_api_key(), relogin=True)\n",
    "\n",
    "sweep_config = {\n",
    "    \"name\": \"graph-unmasking\",\n",
    "    \"method\": \"random\",\n",
    "    \"metric\": {\n",
    "        \"name\": \"graph-unmasking/gen-loss\",\n",
    "        \"goal\": \"minimize\",\n",
    "    },\n",
    "    \"parameters\": {\n",
    "        \"batch_size\": {\"values\": [50, 100, 200, 500]},  # write only\n",
    "        \"hidden_dim\": {\"values\": [16,32, 64]},  \n",
    "        \"hidden_layer\": {\"values\": [4,5,6]},\n",
    "        \"learning_rate\": {\"values\": [0.00001,0.00005,0.0001]},\n",
    "        \"dropout\": {\"values\": [0.0]},\n",
    "        \"normalization\": {\"values\": [True, False]},\n",
    "        \"model\": {\"values\": [\"pna\"]},  # [ \"pnamulti\", \"pna\",\"pna2\", \"attention\",\"transformer\", \"unet\"]}, \n",
    "        \"candidate_selection_radius\": {\"values\": [1, 5]},\n",
    "        \"loss\": {\"values\": [\"bce\"]},   # \"loss\": {\"values\": [\"l2\",\"l1\", \"bce\"]}, \n",
    "        \"single_pass\": {\"values\": [True]},  \n",
    "        \"towers\": {\"values\": [1, 2]},   \n",
    "        \"noise_probability\": {\"values\": [0.0, 0.05, 0.1]},\n",
    "        \"graph_transform\": {\"values\": [True, False]},    \n",
    "        \"pre_post_layers\": {\"values\": [1]}, \n",
    "    },\n",
    "}\n",
    "\n",
    "import pprint\n",
    "pprint.pprint(sweep_config)\n",
    "torch.set_printoptions(threshold=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dQyrEbzkmMCL"
   },
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "9_zto3HQmp5v"
   },
   "outputs": [],
   "source": [
    "def lift_nx_to_pyg(g_nx):\n",
    "  import torch_geometric.transforms as T\n",
    "  transform = T.Compose([T.ToUndirected()])\n",
    "\n",
    "  # g_nx has to have node_labels 0 ... number_of_nodes-1\n",
    "  num_nodes = g_nx.number_of_nodes()\n",
    "  g_complete_nx = nx.complete_graph(num_nodes)\n",
    "\n",
    "  edges_new = list()\n",
    "  node_value_dict = dict()\n",
    "  for v1, v2 in g_complete_nx.edges():\n",
    "    v3 = (v1+1)*10000+(v2+1)*100000000000\n",
    "    edges_new.append((v1, v3))\n",
    "    edges_new.append((v2, v3))\n",
    "    node_value_dict[v1] = DUMMY\n",
    "    node_value_dict[v2] = DUMMY\n",
    "    node_value_dict[v3] = EDGE_INDICATOR if g_nx.has_edge(v1,v2) else NO_EDGE_INDICATOR\n",
    "\n",
    "  graph_new = nx.from_edgelist(edges_new)\n",
    "  for node, x_value in node_value_dict.items():\n",
    "    graph_new.nodes[node]['x'] = x_value\n",
    "\n",
    "  graph_new = nx.convert_node_labels_to_integers(graph_new, ordering='sorted')\n",
    "\n",
    "  g = from_networkx(graph_new, group_node_attrs=['x'])\n",
    "  g = transform(g)  # probably unnecs.\n",
    "  return g\n",
    "\n",
    "\n",
    "def reduce_nx_graph(g_old):\n",
    "  g_new = nx.Graph()\n",
    "  for v_i in g_old.nodes():\n",
    "    if g_old.nodes[v_i]['x'] == DUMMY:\n",
    "      g_new.add_node(v_i)\n",
    "      g_new.nodes[v_i]['x'] = DUMMY\n",
    "\n",
    "  for v_i in g_old.nodes():\n",
    "    if g_old.nodes[v_i]['x'] == EDGE_INDICATOR:\n",
    "      neigh_list = list(g_old.neighbors(v_i))\n",
    "      assert(len(neigh_list) == 2)\n",
    "      g_new.add_edge(neigh_list[0], neigh_list[1])\n",
    "\n",
    "  return g_new\n",
    "\n",
    "def draw_pyg(g_pyg, ax = None, filename = None):\n",
    "  if ax is None:\n",
    "    plt.clf()\n",
    "  g_nx = to_networkx(g_pyg, node_attrs=['x'], to_undirected=True,)\n",
    "\n",
    "  g_nx = reduce_nx_graph(g_nx)\n",
    "\n",
    "  node_labels = {i: g_nx.nodes[i]['x'] for i in g_nx.nodes}\n",
    "  pos = nx.spring_layout(g_nx, seed=1234)\n",
    "  try:\n",
    "    nx.draw(g_nx, with_labels = True, labels=node_labels, ax=ax, pos=pos)\n",
    "  except:\n",
    "    pass\n",
    "  if filename is not None:\n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "  return g_nx\n",
    "\n",
    "\n",
    "def shuffle_tensor(x):\n",
    "  x = x.clone()\n",
    "  x_shape = x.shape\n",
    "  x = x.flatten()\n",
    "  x = x[torch.randperm(x.numel())]\n",
    "  return x.reshape(x.shape)\n",
    "\n",
    "\n",
    "def note_features_to_one_hot(x):\n",
    "  # create indicator vector for NUM_CLASSES classes, values outside are set to all zeros (first to special class that then gets truncated)\n",
    "  x_cut = torch.where((x < -0.1) | (x > NUM_CLASSES-0.5), torch.tensor(NUM_CLASSES, device = DEVICE, dtype=torch.float), x)\n",
    "  x_one_hot = torch.zeros(x.shape[0], NUM_CLASSES+1, device = DEVICE)\n",
    "  x_one_hot.scatter_(1, x_cut.round().long().view(-1).unsqueeze(1), 1)\n",
    "  x_one_hot = x_one_hot[:,0:NUM_CLASSES]\n",
    "  return x_one_hot\n",
    "\n",
    "def global_mask_pool(x, x_in, batch):\n",
    "  mask_indicator = torch.lt(torch.sum(x_in, dim=1), 0.5).view(-1, 1)\n",
    "  x = x * mask_indicator\n",
    "  x = global_add_pool(x, batch)\n",
    "  return x \n",
    "\n",
    "\n",
    "def flip_edges_randomly(tensor, probability):\n",
    "  if probability < EPSILON:\n",
    "    return tensor\n",
    "\n",
    "  # Find the positions where the tensor has values 1.0 or 3.0\n",
    "  ones_positions = (tensor == EDGE_INDICATOR).to(DEVICE)\n",
    "  threes_positions = (tensor == NO_EDGE_INDICATOR).to(DEVICE)\n",
    "\n",
    "  # Generate a random binary mask for switching values\n",
    "  mask = torch.rand(tensor.shape, device=DEVICE) < probability\n",
    "\n",
    "  # Switch 1.0s to 3.0s using the random binary mask\n",
    "  tensor = torch.where(ones_positions & mask, torch.tensor(NO_EDGE_INDICATOR, device=DEVICE), tensor)\n",
    "\n",
    "  # Switch 3.0s to 1.0s using the inverted random binary mask\n",
    "  tensor = torch.where(threes_positions & mask, torch.tensor(EDGE_INDICATOR, device=DEVICE), tensor)\n",
    "\n",
    "  return tensor\n",
    "\n",
    "def extend_node_features(x, edge_index, batch):\n",
    "  assert(NODE_FEATURE_EXTEND == 3)\n",
    "\n",
    "  num_graphs = batch.max()+1\n",
    "  num_nodes = x.shape[0]\n",
    "  degree_feature = torch.zeros([num_nodes, NODE_FEATURE_EXTEND], device=DEVICE)\n",
    "  for i in range(edge_index.shape[1]):\n",
    "    src_node = edge_index[0,i]\n",
    "    target_node = edge_index[1,i]\n",
    "    # if src is real node and connection is edge indicator \n",
    "    if x[src_node, round(DUMMY)].item() > 0.5 and x[target_node, round(EDGE_INDICATOR)].item() > 0.5:\n",
    "      degree_feature[src_node,0] += 1.0\n",
    "    if x[src_node, round(DUMMY)].item() > 0.5 and x[target_node, round(MASK)].item() > 0.5:\n",
    "      degree_feature[src_node,1] += 1.0\n",
    "  for i in range(num_graphs):\n",
    "    num_mask_in_this_graph = torch.sum(x[batch == i,round(MASK)])\n",
    "    degree_feature[batch == i, 2] = num_mask_in_this_graph\n",
    "  x = torch.cat([x, degree_feature], dim=1)\n",
    "\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rEusLk_fd7hC",
    "outputId": "77a08684-19a3-4f34-bb49-385e3644110b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[4, 4], edge_index=[2, 8])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch_geometric.transforms as T\n",
    "transform = T.Compose([T.ToUndirected()])\n",
    "\n",
    "edge_index = torch.tensor([[0, 1, 2, 3, 1, 2, 3],\n",
    "                           [1, 2, 3, 1, 0, 1, 2]], dtype=torch.long).to(DEVICE)\n",
    "x = torch.tensor([[0,1,0,0], [1,0,0,1], [0,0,1,1], [0,1,0,0]], dtype=torch.float).to(DEVICE)\n",
    "\n",
    "data = Data(x=x, edge_index=edge_index)\n",
    "\n",
    "data = transform(data)\n",
    "data\n",
    "#extend_node_features(data.x, data.edge_index, batch=torch.zeros(data.x.shape[0], dtype=torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 516
    },
    "id": "bJ3hIT0pmBXp",
    "outputId": "5c75bb0a-f9f0-4d0c-d454-d9d2451a288c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "edge_index = torch.tensor([[0, 1, 2, 3, 1, 2, 3, 1],\n",
    "                           [1, 2, 3, 1, 0, 1, 2, 3]], dtype=torch.long).to(DEVICE)\n",
    "x = torch.tensor([[-1], [0], [1], [1]], dtype=torch.float).to(DEVICE)\n",
    "\n",
    "data = Data(x=x, edge_index=edge_index)\n",
    "\n",
    "g = torch_geometric.utils.to_networkx(data, to_undirected=True, node_attrs=['x'])\n",
    "try:\n",
    "  nx.draw(g, pos=nx.spring_layout(g),  with_labels = True)\n",
    "except:\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AiLapF9HnilF",
    "outputId": "9d4f30e5-9da8-4af5-c69d-af7b1ac24833"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Data(edge_index=[2, 24], x=[10, 1]),\n",
       " tensor([[0.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [3.],\n",
       "         [0.],\n",
       "         [3.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.]]),\n",
       " tensor([[0, 0, 0, 1, 1, 2, 2, 2, 3, 3, 4, 4, 4, 5, 5, 6, 6, 6, 7, 7, 8, 8, 9, 9],\n",
       "         [1, 3, 5, 0, 2, 1, 7, 8, 0, 4, 3, 7, 9, 0, 6, 5, 8, 9, 2, 4, 2, 6, 4, 6]]))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = lift_nx_to_pyg(g)\n",
    "data, data.x, data.edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 516
    },
    "id": "cgkOkx4amnfY",
    "outputId": "29ef25ae-a384-4346-d05c-d42e9ab4c55b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_pyg(data, filename='examplegraph.png')\n",
    "if IN_COLAB:\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iaElQYAbWu8M"
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "mCpXui1mW9mp"
   },
   "outputs": [],
   "source": [
    "class ShuffleList:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.index = 0\n",
    "\n",
    "    def __iter__(self):\n",
    "        random.shuffle(self.data)\n",
    "        self.index = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.index < len(self.data):\n",
    "            value = self.data[self.index]\n",
    "            self.index += 1\n",
    "            return value\n",
    "        else:\n",
    "            raise StopIteration\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "IgbW4Z0tWuN1"
   },
   "outputs": [],
   "source": [
    "def build_dataset(num_nodes=NUM_NODES, num_samples=NUM_SAMPLES, degree=DEGREE, seed=1234):\n",
    "  graph_dataset = list() \n",
    "\n",
    "  for _ in range(num_samples):\n",
    "    while True:\n",
    "      seed += 1\n",
    "      graph = nx.random_regular_graph(d=degree, n=num_nodes, seed=seed)\n",
    "      if nx.is_connected(graph):\n",
    "        graph.x = torch.ones(num_nodes).t()\n",
    "        graph_dataset.append(lift_nx_to_pyg(graph))\n",
    "        break\n",
    "\n",
    "  return ShuffleList(graph_dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 533
    },
    "id": "xKqFT6D7XHE7",
    "outputId": "b0da8e58-6897-490a-9e5c-a57afc97476e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 001882  loss: -0.35211\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<networkx.classes.graph.Graph at 0x2b7f61040>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = build_dataset()\n",
    "data = dataset[0]\n",
    "draw_pyg(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U2FUnVjG4Cwh",
    "outputId": "a1c2ce6f-9163-4d0c-e3ae-097cce030949"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1:\n",
      "=======\n",
      "Number of graphs in the current batch: 10\n",
      "DataBatch(edge_index=[2, 2640], x=[780, 1], batch=[780], ptr=[11])\n",
      "\n",
      "tensor([0., 3., 0., 3., 0., 3., 0., 3., 0., 3., 0., 3., 0., 1., 0., 1., 0., 3.,\n",
      "        0., 3., 0., 1., 0., 3., 1., 3., 1., 1., 3., 3., 3., 3., 3., 3., 1., 3.,\n",
      "        3., 3., 1., 3., 1., 3., 3., 1., 3., 3., 3., 3., 1., 3., 3., 3., 3., 3.,\n",
      "        1., 1., 3., 3., 3., 3., 3., 3., 1., 3., 1., 1., 3., 3., 3., 1., 3., 1.,\n",
      "        3., 3., 3., 3., 3., 3., 0., 1., 0., 3., 0., 3., 0., 3., 0., 3., 0., 3.,\n",
      "        0., 1., 0., 3., 0., 3., 0., 3., 0., 1., 0., 3., 3., 3., 3., 3., 3., 1.,\n",
      "        1., 3., 3., 3., 3., 1., 3., 3., 3., 3., 1., 1., 3., 3., 1., 3., 3., 1.,\n",
      "        1., 3., 3., 1., 3., 3., 1., 1., 3., 3., 1., 1., 3., 3., 3., 1., 3., 3.,\n",
      "        3., 3., 3., 3., 3., 3., 3., 3., 1., 3., 3., 3., 0., 1., 0., 3., 0., 3.,\n",
      "        0., 3., 0., 3., 0., 1., 0., 3., 0., 3., 0., 3., 0., 3., 0., 1., 0., 3.,\n",
      "        3., 3., 1., 3., 3., 3., 1., 3., 3., 3., 3., 1., 1., 3., 3., 3., 3., 1.,\n",
      "        1., 3., 1., 3., 3., 3., 3., 1., 3., 3., 1., 3., 3., 1., 3., 3., 3., 3.,\n",
      "        1., 3., 3., 3., 3., 3., 3., 3., 1., 3., 1., 3., 1., 1., 3., 3., 3., 3.,\n",
      "        0., 3., 0., 1., 0., 1., 0., 3., 0., 3., 0., 3., 0., 3., 0., 3., 0., 3.,\n",
      "        0., 1., 0., 3., 0., 3., 3., 3., 3., 3., 3., 1., 3., 1., 1., 3., 3., 1.,\n",
      "        3., 3., 3., 3., 3., 1., 3., 3., 3., 1., 3., 1., 3., 3., 1., 1., 3., 1.,\n",
      "        3., 3., 3., 3., 3., 3., 3., 3., 1., 3., 1., 1., 3., 3., 3., 1., 1., 3.,\n",
      "        3., 3., 3., 3., 3., 3., 0., 3., 0., 3., 0., 3., 0., 3., 0., 3., 0., 1.,\n",
      "        0., 3., 0., 1., 0., 3., 0., 1., 0., 3., 0., 3., 3., 3., 3., 1., 3., 1.,\n",
      "        1., 3., 3., 3., 1., 1., 3., 3., 3., 3., 3., 1., 3., 1., 3., 3., 3., 1.,\n",
      "        3., 1., 3., 1., 1., 3., 3., 3., 3., 3., 3., 3., 3., 3., 1., 3., 3., 3.,\n",
      "        3., 3., 1., 3., 1., 3., 3., 3., 3., 1., 3., 3., 0., 3., 0., 3., 0., 1.,\n",
      "        0., 3., 0., 1., 0., 3., 0., 3., 0., 3., 0., 3., 0., 3., 0., 1., 0., 1.,\n",
      "        3., 3., 3., 1., 3., 3., 1., 3., 3., 3., 3., 1., 3., 3., 3., 3., 1., 3.,\n",
      "        3., 3., 3., 1., 3., 1., 3., 3., 3., 1., 3., 1., 3., 1., 3., 3., 3., 3.,\n",
      "        3., 1., 3., 3., 3., 3., 3., 1., 1., 1., 3., 3., 3., 3., 1., 3., 3., 3.,\n",
      "        0., 1., 0., 3., 0., 1., 0., 3., 0., 3., 0., 3., 0., 3., 0., 3., 0., 3.,\n",
      "        0., 3., 0., 1., 0., 3., 3., 3., 3., 3., 3., 3., 1., 3., 1., 3., 1., 3.,\n",
      "        3., 3., 3., 1., 3., 1., 3., 3., 1., 1., 3., 3., 3., 3., 1., 3., 3., 1.,\n",
      "        3., 3., 3., 3., 3., 1., 3., 1., 3., 1., 3., 3., 1., 3., 1., 3., 3., 3.,\n",
      "        3., 3., 3., 1., 3., 3., 0., 3., 0., 3., 0., 1., 0., 1., 0., 3., 0., 3.,\n",
      "        0., 3., 0., 1., 0., 3., 0., 3., 0., 3., 0., 1., 3., 3., 3., 1., 3., 3.,\n",
      "        3., 1., 3., 1., 1., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,\n",
      "        3., 1., 3., 3., 3., 3., 3., 3., 1., 1., 1., 3., 1., 3., 3., 3., 3., 3.,\n",
      "        1., 3., 1., 3., 3., 1., 1., 3., 3., 1., 3., 3., 0., 3., 0., 3., 0., 3.,\n",
      "        0., 3., 0., 1., 0., 3., 0., 1., 0., 3., 0., 3., 0., 3., 0., 1., 0., 1.,\n",
      "        1., 3., 3., 3., 3., 3., 3., 1., 3., 3., 3., 1., 3., 3., 3., 3., 1., 3.,\n",
      "        1., 3., 3., 3., 3., 1., 3., 3., 3., 1., 1., 3., 3., 3., 3., 1., 3., 3.,\n",
      "        3., 3., 3., 3., 3., 3., 3., 1., 3., 1., 3., 3., 1., 1., 1., 3., 3., 3.,\n",
      "        0., 1., 0., 3., 0., 3., 0., 3., 0., 3., 0., 1., 0., 1., 0., 3., 0., 3.,\n",
      "        0., 3., 0., 3., 0., 1., 3., 3., 3., 3., 3., 3., 1., 3., 3., 3., 3., 3.,\n",
      "        3., 3., 3., 3., 1., 1., 3., 1., 3., 1., 1., 3., 3., 3., 1., 1., 3., 3.,\n",
      "        3., 3., 1., 3., 3., 3., 3., 3., 1., 3., 3., 3., 1., 3., 1., 3., 3., 3.,\n",
      "        1., 3., 3., 1., 3., 3.]) tensor([[  0,   0,   0,  ..., 778, 779, 779],\n",
      "        [  1,   3,   5,  ..., 724, 722, 724]]) tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7,\n",
      "        7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
      "        7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
      "        7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
      "        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
      "        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
      "        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
      "        8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
      "        9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
      "        9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
      "        9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9])\n"
     ]
    }
   ],
   "source": [
    "# TODO dataloader\n",
    "from torch_geometric.loader import DataLoader\n",
    "train_loader = DataLoader(dataset, batch_size=BATCH_SIZE_TEST, shuffle=True)\n",
    "for step, data in enumerate(train_loader):\n",
    "  print(f'Step {step + 1}:')\n",
    "  print('=======')\n",
    "  print(f'Number of graphs in the current batch: {data.num_graphs}')\n",
    "  print(data)\n",
    "  print()\n",
    "  print(data.x.flatten(), data.edge_index, data.batch)\n",
    "  break\n",
    "\n",
    "\n",
    "# for gen of training sample:\n",
    "# 1) mask 0 ... (all -1) (inclusivly) \n",
    "# 2) swich exactly 1 of the unmasked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dqztDRIj0UdF"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kV_DnkKhs9P-"
   },
   "source": [
    "#### AttentionNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "eoLXRG6utBBU"
   },
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GATv2Conv, GraphNorm, BatchNorm\n",
    "\n",
    "class AttentionNet(torch.nn.Module):\n",
    "  def __init__(self, hidden_dim=32, layer_num=6, dropout=0.1, normalization=False, single_pass_pooling=False):\n",
    "    super(AttentionNet, self).__init__()\n",
    "\n",
    "    self.mlp_list = nn.ModuleList()\n",
    "    self.conv_list = nn.ModuleList()\n",
    "    self.sigmoid = nn.Sigmoid()\n",
    "    self.dropout = dropout\n",
    "    self.graph_norms = nn.ModuleList()\n",
    "    self.normalization = normalization\n",
    "    self.single_pass_pooling = single_pass_pooling\n",
    "    assert(hidden_dim % 2 == 0)\n",
    "    input_channels = NUM_CLASSES\n",
    "\n",
    "    for i in range(layer_num):\n",
    "      in_dim = hidden_dim if i > 0 else input_channels \n",
    "      out_dim = hidden_dim if i < layer_num-1 else 1 \n",
    "      self.conv_list.append(GATv2Conv(in_channels=in_dim, out_channels=hidden_dim // 2, heads=2))\n",
    "      self.graph_norms.append(BatchNorm(hidden_dim))\n",
    "      self.mlp_list.append(Seq(Lin(hidden_dim, hidden_dim), nn.ReLU(), Lin(hidden_dim, hidden_dim), nn.ReLU(), Lin(hidden_dim, out_dim)))\n",
    "\n",
    "  def forward(self, x_in, edge_index, batch):\n",
    "    x = note_features_to_one_hot(x_in)\n",
    "    for i in range(len(self.conv_list)):\n",
    "      x = self.conv_list[i](x, edge_index)\n",
    "      x = F.relu(x)\n",
    "      if self.normalization:\n",
    "        x = self.graph_norms[i](x)\n",
    "      x = self.mlp_list[i](x)\n",
    "      #if i == 0:\n",
    "      #  x = self.dropout(x)\n",
    "\n",
    "    if self.single_pass_pooling:\n",
    "      x = global_mask_pool(x, x_in, batch)\n",
    "    else:\n",
    "      x = global_mean_pool(x, batch)\n",
    "    x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "    x = self.sigmoid(x) + EPSILON\n",
    "    return x.flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iTUh3uVOtEMO",
    "outputId": "2e193795-0dd2-40d0-f610-6760686b23e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AttentionNet(\n",
      "  (mlp_list): ModuleList(\n",
      "    (0-4): 5 x Sequential(\n",
      "      (0): Linear(in_features=32, out_features=32, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=32, out_features=32, bias=True)\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): Linear(in_features=32, out_features=32, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=32, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (conv_list): ModuleList(\n",
      "    (0): GATv2Conv(4, 16, heads=2)\n",
      "    (1-5): 5 x GATv2Conv(32, 16, heads=2)\n",
      "  )\n",
      "  (sigmoid): Sigmoid()\n",
      "  (graph_norms): ModuleList(\n",
      "    (0-5): 6 x BatchNorm(32)\n",
      "  )\n",
      ")\n",
      "tensor([0.9037, 0.9037, 0.9037, 0.9037, 0.9037, 0.9037, 0.9037, 0.5000, 0.9037,\n",
      "        0.9037], grad_fn=<ReshapeAliasBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = AttentionNet(single_pass_pooling=True)\n",
    "model.to(DEVICE)\n",
    "print(model) \n",
    "for step, data in enumerate(train_loader):\n",
    "  data = data.to(DEVICE)\n",
    "  print(model(data.x, data.edge_index, data.batch))\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SaQ7f2E4dCqd"
   },
   "source": [
    "#### TransformerNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "nS3CzlgcdEAK"
   },
   "outputs": [],
   "source": [
    "#relu = nn.Relu() ## todo: changed to relu here\n",
    "from torch_geometric.nn import TransformerConv\n",
    "\n",
    "class TransformerNet(torch.nn.Module):\n",
    "  def __init__(self, hidden_dim=32, layer_num=6, dropout=0.1, normalization=False, single_pass_pooling = False):\n",
    "    super(TransformerNet, self).__init__()\n",
    "\n",
    "    self.mlp_list = nn.ModuleList()\n",
    "    self.conv_list = nn.ModuleList()\n",
    "    self.sigmoid = nn.Sigmoid()\n",
    "    self.graph_norms = nn.ModuleList()\n",
    "    self.dropout = dropout\n",
    "    self.normalization = normalization\n",
    "    assert(hidden_dim % 2 == 0)\n",
    "    input_channels = NUM_CLASSES\n",
    "    self.single_pass_pooling = single_pass_pooling\n",
    "\n",
    "\n",
    "    for i in range(layer_num):\n",
    "      in_dim = hidden_dim if i > 0 else input_channels \n",
    "      out_dim = hidden_dim if i < layer_num-1 else 1 \n",
    "      self.conv_list.append(TransformerConv(in_channels=in_dim, out_channels=hidden_dim // 2, heads=2))\n",
    "      self.graph_norms.append(BatchNorm(hidden_dim))\n",
    "      self.mlp_list.append(Seq(Lin(hidden_dim, hidden_dim), nn.ReLU(), Lin(hidden_dim, hidden_dim), nn.ReLU(), Lin(hidden_dim, out_dim)))\n",
    "\n",
    "  def forward(self, x_in, edge_index, batch):\n",
    "    x = note_features_to_one_hot(x_in)\n",
    "    for i in range(len(self.conv_list)):\n",
    "      x = self.conv_list[i](x, edge_index)\n",
    "      if self.normalization:\n",
    "        x = self.graph_norms[i](x)\n",
    "      x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "      x = self.mlp_list[i](x)\n",
    "    \n",
    "    if self.single_pass_pooling:\n",
    "      x = global_mask_pool(x, x_in, batch)\n",
    "    else:\n",
    "      x = global_mean_pool(x, batch)\n",
    "\n",
    "    x = self.sigmoid(x) + EPSILON\n",
    "    return x.flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "plkfTVUrXRO-",
    "outputId": "598c4704-2c70-4949-ff97-d3a9c62b710d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TransformerNet(\n",
      "  (mlp_list): ModuleList(\n",
      "    (0-4): 5 x Sequential(\n",
      "      (0): Linear(in_features=32, out_features=32, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=32, out_features=32, bias=True)\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): Linear(in_features=32, out_features=32, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=32, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (conv_list): ModuleList(\n",
      "    (0): TransformerConv(4, 16, heads=2)\n",
      "    (1-5): 5 x TransformerConv(32, 16, heads=2)\n",
      "  )\n",
      "  (sigmoid): Sigmoid()\n",
      "  (graph_norms): ModuleList(\n",
      "    (0-5): 6 x BatchNorm(32)\n",
      "  )\n",
      ")\n",
      "tensor([0.5099, 0.5100, 0.5101, 0.5098, 0.5100, 0.5099, 0.5100, 0.5099, 0.5100,\n",
      "        0.5098], grad_fn=<ReshapeAliasBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = TransformerNet()\n",
    "model.to(DEVICE)\n",
    "print(model) \n",
    "for step, data in enumerate(train_loader):\n",
    "  data = data.to(DEVICE)\n",
    "  print(model(data.x, data.edge_index, data.batch))\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UwghOZsDdEJz"
   },
   "source": [
    "#### Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "LEwIcO4w0VaR"
   },
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GraphUNet\n",
    "\n",
    "class Unet(torch.nn.Module):\n",
    "  def __init__(self, hidden_channels=32, out_channels=1, depth=4, single_pass_pooling = False):\n",
    "    super(Unet, self).__init__()\n",
    "    self.sigmoid = nn.Sigmoid()\n",
    "    in_channels = NUM_CLASSES\n",
    "    self.single_pass_pooling = single_pass_pooling\n",
    "    self.unet = GraphUNet(in_channels=in_channels, hidden_channels=hidden_channels, out_channels=out_channels, depth=depth)\n",
    "\n",
    "  def forward(self, x_in, edge_index, batch):\n",
    "    x = note_features_to_one_hot(x_in)\n",
    "    x = self.unet(x, edge_index)\n",
    "\n",
    "    if self.single_pass_pooling:\n",
    "      x = global_mask_pool(x, x_in, batch)\n",
    "    else:\n",
    "      x = global_mean_pool(x, batch)\n",
    "\n",
    "    x = self.sigmoid(x) + 0.0000001 # add eps to avoid div. by zero\n",
    "    return x.flatten()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YBYSWAp9XOLz",
    "outputId": "f60120e4-6c90-4e00-caf8-9e5980cc79ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unet(\n",
      "  (sigmoid): Sigmoid()\n",
      "  (unet): GraphUNet(4, 32, 1, depth=4, pool_ratios=[0.5, 0.5, 0.5, 0.5])\n",
      ")\n",
      "tensor([0.4662, 0.4661, 0.4661, 0.4662, 0.4662, 0.4661, 0.4661, 0.4661, 0.4661,\n",
      "        0.4661], grad_fn=<ReshapeAliasBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Unet()\n",
    "model.to(DEVICE)\n",
    "print(model) \n",
    "for step, data in enumerate(train_loader):\n",
    "  data.to(DEVICE)\n",
    "  print(model(data.x, data.edge_index, data.batch))\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ir4sFS6YS5UY"
   },
   "source": [
    "#### PNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "ydDINWbaaSav"
   },
   "outputs": [],
   "source": [
    "def print_inputs(*args):\n",
    "    for arg in args:\n",
    "        print(arg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "U_8SApKdS3wo"
   },
   "outputs": [],
   "source": [
    "from torch_geometric.nn import PNA\n",
    "from torch_geometric.utils import degree\n",
    "\n",
    "#train_dataset = build_dataset()\n",
    "\n",
    "def dataset_to_degree_bin(train_dataset):\n",
    "  # Compute the maximum in-degree in the training data.\n",
    "  max_degree = -1\n",
    "  for data in train_dataset:\n",
    "      d = degree(data.edge_index[1], num_nodes=data.num_nodes, dtype=torch.long)\n",
    "      max_degree = max(max_degree, int(d.max()))\n",
    "\n",
    "  deg = torch.zeros(max_degree + 1, dtype=torch.long)\n",
    "  for data in train_dataset:\n",
    "      d = degree(data.edge_index[1], num_nodes=data.num_nodes, dtype=torch.long)\n",
    "      deg += torch.bincount(d, minlength=deg.numel())\n",
    "  return deg\n",
    "\n",
    "class PNAnet(torch.nn.Module):\n",
    "  def __init__(self, train_dataset_example, hidden_channels=32, depth=4, dropout=0.0, towers=2, single_pass_pooling=False, graph_transform=False, normalization=True, pre_post_layers=1):\n",
    "    super(PNAnet, self).__init__()\n",
    "    self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    # Calculate x as the difference between mult_y and hidden_dim\n",
    "    hidden_channels = towers * ((hidden_channels // towers) + 1)\n",
    "    #out_channels = towers * ((out_channels // towers) + 1)\n",
    "\n",
    "    in_channels = NUM_CLASSES\n",
    "    if graph_transform:\n",
    "      in_channels += NODE_FEATURE_EXTEND\n",
    "    deg = dataset_to_degree_bin(train_dataset_example)\n",
    "    aggregators = ['mean', 'min', 'max', 'std']\n",
    "    scalers = ['identity', 'amplification', 'attenuation']\n",
    "    self.normalization = BatchNorm(hidden_channels) if normalization else None\n",
    "    self.pnanet = PNA(in_channels=in_channels, hidden_channels=hidden_channels, out_channels=hidden_channels, num_layers=depth, aggregators=aggregators, scalers=scalers, deg=deg, dropout=dropout, towers=towers, norm=self.normalization, pre_layers=pre_post_layers, post_layers=pre_post_layers)\n",
    "    self.single_pass_pooling = single_pass_pooling\n",
    "    self.graph_transform = graph_transform\n",
    "\n",
    "    self.final_mlp = Seq(Lin(hidden_channels, hidden_channels), nn.ReLU(), Lin(hidden_channels, hidden_channels), nn.ReLU(), Lin(hidden_channels, 1))\n",
    "\n",
    "\n",
    "  def forward(self, x_in, edge_index, batch):\n",
    "    x = note_features_to_one_hot(x_in)\n",
    "    if self.graph_transform:\n",
    "      x = extend_node_features(x, edge_index, batch)\n",
    "    x = self.pnanet(x, edge_index)\n",
    "\n",
    "    if self.single_pass_pooling:\n",
    "      x = global_mask_pool(x, x_in, batch)\n",
    "    else:\n",
    "      x = global_mean_pool(x, batch)\n",
    "\n",
    "    #x = x.sum(dim=1)\n",
    "    x = self.final_mlp(x)\n",
    "    x = self.sigmoid(x) + EPSILON # add eps to avoid div. by zero\n",
    "    return x.flatten()\n",
    "\n",
    "class PNAmulti(torch.nn.Module):\n",
    "  def __init__(self, train_dataset_example, hidden_channels=32, graph_transform=False, depth=4, dropout=0.0, towers=1, model_num=5, single_pass_pooling=False, normalization=True, pre_post_layers=1):\n",
    "    super(PNAmulti, self).__init__()\n",
    "    self.model_num = model_num\n",
    "    self.pna_list = nn.ModuleList()\n",
    "    self.sigmoid = nn.Sigmoid()\n",
    "    weights = torch.ones(model_num)\n",
    "    self.weights = nn.Parameter(weights)  # nn.Parameter is a Tensor that's a module parameter.\n",
    "    for i in range(model_num):\n",
    "      # towers is i+1\n",
    "      pna_model = PNAnet(train_dataset_example, hidden_channels=hidden_channels, graph_transform=graph_transform, depth=depth, dropout=dropout, towers=i+1, single_pass_pooling=single_pass_pooling, normalization=normalization, pre_post_layers=pre_post_layers)\n",
    "      self.pna_list.append(pna_model)\n",
    "\n",
    "  def get_normalized_weights(self):\n",
    "    w_sigmoid = self.sigmoid(self.weights)\n",
    "    w = w_sigmoid/w_sigmoid.sum()\n",
    "    return w\n",
    "\n",
    "  def forward(self, x, edge_index, batch):\n",
    "    x_agg = None\n",
    "    i_not = random.choice(range(len(self.pna_list))) if self.training  and len(self.pna_list) > 1 else -1 # skip 1 during training\n",
    "    w = self.get_normalized_weights()\n",
    "    for i, pna_model in enumerate(self.pna_list):\n",
    "      if i == i_not:\n",
    "        continue\n",
    "      if x_agg is None:\n",
    "        x_agg = pna_model(x, edge_index, batch) * w[i]\n",
    "      else:\n",
    "        x_agg = x_agg + pna_model( x, edge_index, batch) * w[i]\n",
    "    return x_agg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TTvXwuajPPOJ",
    "outputId": "fcf2e0b4-3416-41ad-a346-46757ef749a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNAmulti(\n",
      "  (pna_list): ModuleList(\n",
      "    (0): PNAnet(\n",
      "      (sigmoid): Sigmoid()\n",
      "      (normalization): BatchNorm(33)\n",
      "      (pnanet): PNA(4, 33, num_layers=4)\n",
      "      (final_mlp): Sequential(\n",
      "        (0): Linear(in_features=33, out_features=33, bias=True)\n",
      "        (1): ReLU()\n",
      "        (2): Linear(in_features=33, out_features=33, bias=True)\n",
      "        (3): ReLU()\n",
      "        (4): Linear(in_features=33, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (1): PNAnet(\n",
      "      (sigmoid): Sigmoid()\n",
      "      (normalization): BatchNorm(34)\n",
      "      (pnanet): PNA(4, 34, num_layers=4)\n",
      "      (final_mlp): Sequential(\n",
      "        (0): Linear(in_features=34, out_features=34, bias=True)\n",
      "        (1): ReLU()\n",
      "        (2): Linear(in_features=34, out_features=34, bias=True)\n",
      "        (3): ReLU()\n",
      "        (4): Linear(in_features=34, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (2): PNAnet(\n",
      "      (sigmoid): Sigmoid()\n",
      "      (normalization): BatchNorm(33)\n",
      "      (pnanet): PNA(4, 33, num_layers=4)\n",
      "      (final_mlp): Sequential(\n",
      "        (0): Linear(in_features=33, out_features=33, bias=True)\n",
      "        (1): ReLU()\n",
      "        (2): Linear(in_features=33, out_features=33, bias=True)\n",
      "        (3): ReLU()\n",
      "        (4): Linear(in_features=33, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (3): PNAnet(\n",
      "      (sigmoid): Sigmoid()\n",
      "      (normalization): BatchNorm(36)\n",
      "      (pnanet): PNA(4, 36, num_layers=4)\n",
      "      (final_mlp): Sequential(\n",
      "        (0): Linear(in_features=36, out_features=36, bias=True)\n",
      "        (1): ReLU()\n",
      "        (2): Linear(in_features=36, out_features=36, bias=True)\n",
      "        (3): ReLU()\n",
      "        (4): Linear(in_features=36, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (4): PNAnet(\n",
      "      (sigmoid): Sigmoid()\n",
      "      (normalization): BatchNorm(35)\n",
      "      (pnanet): PNA(4, 35, num_layers=4)\n",
      "      (final_mlp): Sequential(\n",
      "        (0): Linear(in_features=35, out_features=35, bias=True)\n",
      "        (1): ReLU()\n",
      "        (2): Linear(in_features=35, out_features=35, bias=True)\n",
      "        (3): ReLU()\n",
      "        (4): Linear(in_features=35, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "tensor([0.4272, 0.4272, 0.4272, 0.4272, 0.4272, 0.4272, 0.4272, 0.4272, 0.4272,\n",
      "        0.4272], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = PNAmulti(build_dataset())\n",
    "model.to(DEVICE)\n",
    "print(model) \n",
    "for step, data in enumerate(train_loader):\n",
    "  data.to(DEVICE)\n",
    "  print(model(data.x, data.edge_index, data.batch))\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hSyYUfY1X6Os",
    "outputId": "61c73191-21d8-48f5-c7a8-4b3ba8d48f61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNAnet(\n",
      "  (sigmoid): Sigmoid()\n",
      "  (normalization): BatchNorm(34)\n",
      "  (pnanet): PNA(4, 34, num_layers=4)\n",
      "  (final_mlp): Sequential(\n",
      "    (0): Linear(in_features=34, out_features=34, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=34, out_features=34, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=34, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "tensor([0.5122, 0.5122, 0.5122, 0.5122, 0.5122, 0.5122, 0.5122, 0.5122, 0.5122,\n",
      "        0.5122], grad_fn=<ReshapeAliasBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = PNAnet(build_dataset())\n",
    "model.to(DEVICE)\n",
    "print(model) \n",
    "for step, data in enumerate(train_loader):\n",
    "  data.to(DEVICE)\n",
    "  print(model(data.x, data.edge_index, data.batch))\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jB6WbKuwVdix"
   },
   "source": [
    "#### PNA2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "6Mvgyb_hVgpv"
   },
   "outputs": [],
   "source": [
    "from torch_geometric.nn import PNAConv\n",
    "\n",
    "class PNA2net(torch.nn.Module):\n",
    "  def __init__(self, train_dataset_example, hidden_dim=32, layer_num=4, dropout=0.0, normalization=False, tower_num=5, single_pass_pooling=False):\n",
    "    super().__init__()\n",
    "\n",
    "    aggregators = ['mean', 'min', 'max', 'std', 'var', 'sum']\n",
    "    scalers = ['identity', 'amplification', 'attenuation']\n",
    "    deg = dataset_to_degree_bin(train_dataset_example)\n",
    "\n",
    "    # Calculate x as the difference between mult_y and hidden_dim\n",
    "    hidden_dim = tower_num * ((hidden_dim // tower_num) + 1)\n",
    "\n",
    "    self.conv_list = nn.ModuleList()\n",
    "    self.batchnorm_list = nn.ModuleList()\n",
    "    self.mlp_list = nn.ModuleList()\n",
    "\n",
    "    self.dropout = dropout\n",
    "    self.normalization = normalization\n",
    "    self.sigmoid = nn.Sigmoid()\n",
    "    self.single_pass_pooling = single_pass_pooling\n",
    "\n",
    "    input_channels = NUM_CLASSES\n",
    "  \n",
    "\n",
    "    for i in range(layer_num):\n",
    "      in_dim = hidden_dim if i > 0 else input_channels \n",
    "      out_dim = hidden_dim if i < layer_num-1 else 1 \n",
    "      self.conv_list.append(PNAConv(in_channels=in_dim, out_channels=hidden_dim, aggregators=aggregators, scalers=scalers, deg=deg, towers=tower_num, pre_layers=1, post_layers=1, divide_input=False))\n",
    "      self.batchnorm_list.append(BatchNorm(hidden_dim))\n",
    "      self.mlp_list.append(Seq(nn.ReLU(), Lin(hidden_dim+NUM_CLASSES+in_dim, hidden_dim+NUM_CLASSES+in_dim), nn.ReLU(), Lin(hidden_dim+NUM_CLASSES+in_dim, hidden_dim+NUM_CLASSES+in_dim), nn.ReLU(), Lin(hidden_dim+NUM_CLASSES+in_dim, out_dim)))\n",
    "          \n",
    "  def forward(self, x_in, edge_index, batch):\n",
    "    x_onehot = note_features_to_one_hot(x_in)\n",
    "    x = x_onehot.clone()\n",
    "    for i in range(len(self.conv_list)):\n",
    "      x_in = x.clone()\n",
    "      x = self.conv_list[i](x, edge_index)\n",
    "      if self.normalization:\n",
    "        x = self.batchnorm_list[i](x)\n",
    "      x_concat = torch.concat([x, x_onehot, x_in], dim=1)\n",
    "      x = self.mlp_list[i](x_concat)\n",
    "      if i < len(self.conv_list)-1:\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "\n",
    "    if self.single_pass_pooling:\n",
    "      x = global_mask_pool(x, x_in, batch)\n",
    "    else:\n",
    "      x = global_mean_pool(x, batch)\n",
    "      \n",
    "    x = self.sigmoid(x) + EPSILON\n",
    "    return x.flatten()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rgjqgcfhY1gC",
    "outputId": "11ccc1cc-7127-463c-c375-21325d939d71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNA2net(\n",
      "  (conv_list): ModuleList(\n",
      "    (0): PNAConv(4, 35, towers=5, edge_dim=None)\n",
      "    (1-3): 3 x PNAConv(35, 35, towers=5, edge_dim=None)\n",
      "  )\n",
      "  (batchnorm_list): ModuleList(\n",
      "    (0-3): 4 x BatchNorm(35)\n",
      "  )\n",
      "  (mlp_list): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): ReLU()\n",
      "      (1): Linear(in_features=43, out_features=43, bias=True)\n",
      "      (2): ReLU()\n",
      "      (3): Linear(in_features=43, out_features=43, bias=True)\n",
      "      (4): ReLU()\n",
      "      (5): Linear(in_features=43, out_features=35, bias=True)\n",
      "    )\n",
      "    (1-2): 2 x Sequential(\n",
      "      (0): ReLU()\n",
      "      (1): Linear(in_features=74, out_features=74, bias=True)\n",
      "      (2): ReLU()\n",
      "      (3): Linear(in_features=74, out_features=74, bias=True)\n",
      "      (4): ReLU()\n",
      "      (5): Linear(in_features=74, out_features=35, bias=True)\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): ReLU()\n",
      "      (1): Linear(in_features=74, out_features=74, bias=True)\n",
      "      (2): ReLU()\n",
      "      (3): Linear(in_features=74, out_features=74, bias=True)\n",
      "      (4): ReLU()\n",
      "      (5): Linear(in_features=74, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "tensor([0.4970, 0.4970, 0.4970, 0.4970, 0.4970, 0.4970, 0.4970, 0.4970, 0.4970,\n",
      "        0.4970], grad_fn=<ReshapeAliasBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = PNA2net(build_dataset())\n",
    "model.to(DEVICE)\n",
    "print(model) \n",
    "for step, data in enumerate(train_loader):\n",
    "  data.to(DEVICE)\n",
    "  print(model(data.x, data.edge_index, data.batch))\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tph0rjhNS6iS"
   },
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_K0Yuz5FNVdy"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "gDKYLoMV6z6J"
   },
   "outputs": [],
   "source": [
    "def build_model(config, dataset):\n",
    "  hidden_dim = config.hidden_dim\n",
    "  single_pass_pooling = config.single_pass\n",
    "  if config.model == \"unet\":\n",
    "    model =  Unet(hidden_channels = hidden_dim,  out_channels = 1, depth=config.hidden_layer, single_pass_pooling=single_pass_pooling)\n",
    "  elif config.model == \"attention\":\n",
    "     model = AttentionNet(hidden_dim=hidden_dim, layer_num=config.hidden_layer, dropout=config.dropout, normalization=config.normalization, single_pass_pooling=single_pass_pooling)\n",
    "  elif config.model == \"transformer\":\n",
    "    model = TransformerNet(hidden_dim=hidden_dim, layer_num=config.hidden_layer, dropout=config.dropout, normalization=config.normalization, single_pass_pooling=single_pass_pooling)\n",
    "  elif config.model == \"pna\":\n",
    "    model = PNAnet(dataset, hidden_channels=hidden_dim, depth=config.hidden_layer, dropout=config.dropout, towers=config.towers, single_pass_pooling=single_pass_pooling, graph_transform=config.graph_transform, normalization=config.normalization, pre_post_layers=config.pre_post_layers)\n",
    "  elif config.model == \"pnamulti\":\n",
    "    model = PNAmulti(dataset, hidden_channels=hidden_dim, depth=config.hidden_layer, dropout=config.dropout, towers=config.towers, single_pass_pooling=single_pass_pooling, graph_transform=config.graph_transform, normalization=config.normalization, pre_post_layers=config.pre_post_layers)\n",
    "  elif config.model == \"pna2\":\n",
    "    model = PNA2net(dataset, hidden_dim=hidden_dim, layer_num=config.hidden_layer, dropout=config.dropout, normalization=config.normalization, single_pass_pooling=single_pass_pooling)\n",
    "  else:\n",
    "    ValueError(\"illegal net\")\n",
    "  return model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2GDOIysiiIGT"
   },
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "FsofkLkkP3GK"
   },
   "outputs": [],
   "source": [
    "def find_best_choice(model, g, test_choices, x, x_shape):\n",
    "  p_0_list = list()\n",
    "  p_1_list = list()\n",
    "  x_noedge_list = list()\n",
    "  x_edge_list = list()\n",
    "  mask_indicator_list = list()\n",
    "\n",
    "  for i, mask_indicator in enumerate(test_choices):\n",
    "    x_noedge, x_edge = x.clone(), x.clone()\n",
    "    x_noedge[mask_indicator] = NO_EDGE_INDICATOR\n",
    "    x_edge[mask_indicator] = EDGE_INDICATOR\n",
    "    batch = torch.zeros(x_shape[0], dtype=torch.long).to(DEVICE)\n",
    "    p_0 = model(x_noedge.view(x_shape), g.edge_index, batch=batch).item()\n",
    "    p_1 = model(x_edge.view(x_shape), g.edge_index, batch=batch).item()\n",
    "\n",
    "    p_0_list.append(p_0/(p_0+p_1))\n",
    "    p_1_list.append(p_1/(p_0+p_1))\n",
    "    x_noedge_list.append(x_noedge)\n",
    "    x_edge_list.append(x_edge)\n",
    "    mask_indicator_list.append(mask_indicator)\n",
    "\n",
    "  best_i = np.argmax(p_1_list)\n",
    "  return p_0_list[best_i], p_1_list[best_i], x_noedge_list[best_i],  x_edge_list[best_i], mask_indicator_list[best_i]\n",
    "\n",
    "\n",
    "def generate_graph_multi(model, g, choice_num=5):\n",
    "  x = g.x\n",
    "  x_shape = x.shape\n",
    "  x = x.flatten()\n",
    "  indices_of_edges = (x != DUMMY).nonzero(as_tuple=False).flatten()\n",
    "  num_edges = indices_of_edges.numel()\n",
    "  x[indices_of_edges] = MASK\n",
    "  indices_of_edges = indices_of_edges.flatten().tolist()\n",
    "\n",
    "  for _ in range(num_edges):\n",
    "    random.shuffle(indices_of_edges)\n",
    "    choice_num_i = min(choice_num, len(indices_of_edges)) \n",
    "    test_choices = indices_of_edges[0:choice_num_i]\n",
    "    p_0, p_1, x_noedge, x_edge, mask_indicator = find_best_choice(model, g, test_choices, x, x_shape)\n",
    "    random_selection_index = int(np.random.choice([0, 1], size=1, p=[p_0, p_1]))\n",
    "    x = (x_noedge, x_edge)[random_selection_index]\n",
    "    indices_of_edges.remove(mask_indicator)\n",
    "\n",
    "  g.x = x.reshape(x_shape)\n",
    "  return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "DQay_Zy35bHr"
   },
   "outputs": [],
   "source": [
    "def generate_graph_singlepass(model, g):\n",
    "  # does not have multi\n",
    "  model.eval()\n",
    "  x = g.x\n",
    "  x_shape = x.shape\n",
    "  x = x.flatten()\n",
    "  indices_of_edges = (x != DUMMY).nonzero(as_tuple=False).flatten()\n",
    "  num_edges = indices_of_edges.numel()\n",
    "  x[indices_of_edges] = MASK\n",
    "  indices_of_edges = indices_of_edges.flatten().tolist()\n",
    "  random.shuffle(indices_of_edges)\n",
    "  batch = torch.zeros(x_shape[0], dtype=torch.long).to(DEVICE)\n",
    "\n",
    "  for edge_index in indices_of_edges:\n",
    "    x[edge_index] = -1.0\n",
    "    edge_prob = model(x.view(x_shape), g.edge_index, batch=batch).item()\n",
    "    assert(edge_prob > 0.0 and edge_prob < 1.0)\n",
    "    if random.random() < edge_prob:\n",
    "      x[edge_index] = EDGE_INDICATOR\n",
    "    else:\n",
    "      x[edge_index] = NO_EDGE_INDICATOR\n",
    "\n",
    "  g.x = x.reshape(x_shape)\n",
    "  return g\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "_cN5gKKUiJTR"
   },
   "outputs": [],
   "source": [
    "@torch.inference_mode()\n",
    "def generate_graphs(num, epoch_i, model, g_like, config):\n",
    "  mean_degree_list = list()\n",
    "  var_degree_list = list()\n",
    "  for j in range(num):\n",
    "    if config.single_pass:\n",
    "      g = generate_graph_singlepass(model, g_like)\n",
    "    else:\n",
    "      g = generate_graph_multi(model, g_like, choice_num = config.candidate_selection_radius)\n",
    "    nx_orig_graph = draw_pyg(g, filename=f\"generated_graph_epoch{str(epoch_i).zfill(5)}_sample{str(j).zfill(5)}.jpg\")\n",
    "    degree_list = [nx_orig_graph.degree(i) for i in nx_orig_graph.nodes()]\n",
    "    mean_degree_list.append(np.mean(degree_list))\n",
    "    var_degree_list.append(np.var(degree_list))\n",
    "  return np.mean(mean_degree_list), np.mean(var_degree_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GKxurLjrXnCo"
   },
   "source": [
    "## Generat Samples for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "nALlwSTtXmhx"
   },
   "outputs": [],
   "source": [
    "def gen_random_training_sample_unused(x):\n",
    "  x_masked = x.clone().reshape(-1)\n",
    "  indices_of_edges = (x_masked != DUMMY).nonzero(as_tuple=False).flatten()\n",
    "  num_edges = indices_of_edges.numel()\n",
    "  num_masked = torch.randint(1, num_edges+1, size=(1,), device=DEVICE)\n",
    "  #num_masked = sample_num_masked_geometric(1, num_edges+1)\n",
    "\n",
    "  shuffled_indices_of_edges = indices_of_edges[torch.randperm(indices_of_edges.numel())]\n",
    "  indices_of_edges_to_mask = shuffled_indices_of_edges[:num_masked]\n",
    "  \n",
    "  gt_value = x_masked[indices_of_edges_to_mask[0]].item() # we will change the first value back\n",
    "  x_masked[indices_of_edges_to_mask] = MASK\n",
    "\n",
    "\n",
    "  x_masked_0 = x_masked.clone()\n",
    "  x_masked_0[indices_of_edges_to_mask[0]] = NO_EDGE_INDICATOR\n",
    "  x_masked_0 = x_masked_0.reshape(x.shape)\n",
    "\n",
    "  x_masked_1 = x_masked.clone()\n",
    "  x_masked_1[indices_of_edges_to_mask[0]] = EDGE_INDICATOR\n",
    "  x_masked_1 = x_masked_1.reshape(x.shape)\n",
    "\n",
    "  if gt_value == NO_EDGE_INDICATOR:\n",
    "    return x_masked_0, x_masked_1\n",
    "  elif gt_value == EDGE_INDICATOR:\n",
    "    return x_masked_1, x_masked_0 \n",
    "  assert(False)\n",
    "\n",
    "  return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "G-gIs8GVYm5l"
   },
   "outputs": [],
   "source": [
    "def sample_mask_and_flip(batch, x):\n",
    "  num_graphs = batch.view(-1)[-1]\n",
    "  x_id_mask = list()\n",
    "  x_id_flip = list()\n",
    "\n",
    "  for graph_id in range(num_graphs+1):\n",
    "    #num_nodes = (batch == graph_id).sum()\n",
    "    #indices_of_edges = (x != DUMMY and batch == graph_id).nonzero(as_tuple=False)\n",
    "    edge_indicator = x.view(-1) != DUMMY\n",
    "    batch_indicator = batch.view(-1) == graph_id \n",
    "    indices_of_edges = torch.nonzero(batch_indicator & edge_indicator)\n",
    "    indices_of_edges = indices_of_edges.flatten().tolist()\n",
    "    random.shuffle(indices_of_edges)\n",
    "    x_id_flip.append(indices_of_edges[-1])\n",
    "    num_masked = random.choice(range(len(indices_of_edges)))\n",
    "    x_id_mask = x_id_mask + indices_of_edges[:num_masked]\n",
    "\n",
    "  mask_and_flip_indicator = torch.zeros(batch.numel(), dtype=torch.long).to(DEVICE)\n",
    "  mask_and_flip_indicator[x_id_mask] = 1\n",
    "  mask_and_flip_indicator[x_id_flip] = 2\n",
    "\n",
    "  return mask_and_flip_indicator\n",
    "\n",
    "def mask_x_based_on_indicator(x, mask_and_flip_indicator):\n",
    "  x_new = x.clone()\n",
    "  to_mask = mask_and_flip_indicator == 1\n",
    "  x_new.view(-1)[to_mask] = MASK\n",
    "  return x_new\n",
    "\n",
    "\n",
    "# this is done inplace!\n",
    "def flip_x_based_on_indicator(x, mask_and_flip_indicator):\n",
    "  to_flip = (mask_and_flip_indicator == 2)#.to(DEVICE)\n",
    "  x = x.clone()  #sadly in-place operation not allowed here\n",
    "\n",
    "  #x[to_flip] = -x[to_flip]\n",
    "\n",
    "  x[to_flip] = torch.where(x[to_flip] == EDGE_INDICATOR, torch.tensor(NO_EDGE_INDICATOR).to(DEVICE), torch.tensor(EDGE_INDICATOR).to(DEVICE))\n",
    "\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1La4pbjWakyz",
    "outputId": "70ebca1a-4e51-45a2-a03a-9b86faf1eefe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True, False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True, False,  True,  True,  True,  True,  True,  True, False,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        False,  True,  True,  True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for step, data in enumerate(train_loader):\n",
    "  data.to(DEVICE)\n",
    "  mask_and_flip_indicator = sample_mask_and_flip(data.batch, data.x)\n",
    "  break\n",
    "\n",
    "\n",
    "x = (mask_x_based_on_indicator(data.x, mask_and_flip_indicator))\n",
    "xz = x.clone()\n",
    "xx = (flip_x_based_on_indicator(x, mask_and_flip_indicator))\n",
    "\n",
    "(xz == xx).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TulPGAH8R0Eo"
   },
   "source": [
    "## Compute Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "flDsYTRKR1ZB"
   },
   "outputs": [],
   "source": [
    "bce_loss = nn.BCELoss()\n",
    "def reduce_loss(loss_for_graph, config):\n",
    "  # loss_for_graph should be > 0\n",
    "  if config.loss == \"l1\":\n",
    "    return loss_for_graph.sum() \n",
    "  elif config.loss == \"l2\":\n",
    "    return F.mse_loss(loss_for_graph, torch.zeros_like(loss_for_graph))\n",
    "  elif config.loss == \"bce\":\n",
    "    return bce_loss(loss_for_graph, torch.zeros_like(loss_for_graph))\n",
    "  else:\n",
    "    raise ValueError(\"Illegal loss value\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SVx9HGc89VFe"
   },
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "K4M0XZ5Vpk5Z"
   },
   "outputs": [],
   "source": [
    "def prepare_x_for_single_pass(mask_and_flip_indicator, x):\n",
    "  x_new = x.clone()\n",
    "  to_mask = mask_and_flip_indicator == 1\n",
    "  x_new.view(-1)[to_mask] = MASK\n",
    "  choice_indicator = mask_and_flip_indicator == 2\n",
    "  x_new.view(-1)[choice_indicator] = -1 # this will be set to zero in the one hot encoding step\n",
    "  gt = x.clone().flatten()[choice_indicator]\n",
    "  gt = torch.where(gt == EDGE_INDICATOR, torch.tensor(1.0, device = DEVICE), torch.zeros_like(gt))\n",
    "  return x_new, gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "gj5td9zue7HT"
   },
   "outputs": [],
   "source": [
    "def single_pass_prediction(data, model, config):\n",
    "  mask_and_flip_indicator = sample_mask_and_flip(data.batch, data.x)\n",
    "  x_in, out_gt = prepare_x_for_single_pass(mask_and_flip_indicator, data.x)\n",
    "\n",
    "  if model.training: x_in = flip_edges_randomly(x_in, config.noise_probability)\n",
    "\n",
    "  out_prediction = model(x_in, data.edge_index, data.batch) # between 0 ,1 \n",
    "\n",
    "  #print(\"out gt: \", out_gt.flatten(), \"   out pred:   \", out_prediction.flatten())\n",
    "\n",
    "  loss_for_graph =  torch.abs(out_prediction.flatten() - out_gt.flatten()) # between 0 and 1\n",
    "  return loss_for_graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "sUfUS3OYfNxu"
   },
   "outputs": [],
   "source": [
    "def multi_pass_prediction(data, model, config):\n",
    "  mask_and_flip_indicator = sample_mask_and_flip(data.batch, data.x) # this then should also return gt \n",
    "  x = mask_x_based_on_indicator(data.x, mask_and_flip_indicator)\n",
    "\n",
    "  if model.training: x = flip_edges_randomly(x, config.noise_probability)\n",
    "\n",
    "  out_correct = model(x, data.edge_index, data.batch)  # is supposed to be 1 everywhere\n",
    "  x = flip_x_based_on_indicator(x, mask_and_flip_indicator)  # important to use x here and not data.x\n",
    "  out_incorrect = model(x, data.edge_index, data.batch) # is supposed to be 0 everywhere\n",
    "  loss_for_graph =  out_incorrect - out_correct # between -1 and 1\n",
    "  loss_for_graph = (loss_for_graph + 1.0) / 2.0   # between 0 and 1,\n",
    "  return loss_for_graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "-_84ieMIoYh5"
   },
   "outputs": [],
   "source": [
    "def feed_data_to_model(data, model, config):\n",
    "  if config.single_pass == True:\n",
    "    return single_pass_prediction(data, model, config)\n",
    "  return multi_pass_prediction(data, model, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f8RF9E-wfDXW"
   },
   "source": [
    "### Start Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "lDBAh9XPiO-a"
   },
   "outputs": [],
   "source": [
    "def start_agent(config):\n",
    "  graph_dataset = build_dataset()\n",
    "  #graph_dataset_ = build_dataset()\n",
    "  model = build_model(config, graph_dataset)\n",
    "  wandb.log({\"num_parameters\": sum(p.numel() for p in model.parameters())})\n",
    "\n",
    "  optimizer = Adam(model.parameters(), lr = config.learning_rate) \n",
    "  train_loader = DataLoader(graph_dataset, batch_size=config.batch_size, shuffle=True)\n",
    "\n",
    "  for epoch_i in range(NUM_EPOCHS):\n",
    "    loss_list = list()\n",
    "    for step, data in enumerate(train_loader):\n",
    "      data.to(DEVICE)\n",
    "      model.train()\n",
    "      model.zero_grad()\n",
    "\n",
    "      loss_for_graph = feed_data_to_model(data, model, config) # between 0 and 1, probabilty of the incorrect choice\n",
    "      loss = reduce_loss(loss_for_graph, config)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      loss =  ((loss_for_graph.mean()).item()  -0.5 ) * 2.0 # between - 0.5 and 0.5 -> between - 1 and 1\n",
    "      loss_list.append(loss)\n",
    "      #wandb.log({\"epoch\": epoch_i+1, \"loss\": np.mean(loss_list)})\n",
    "\n",
    "    print('epoch: {:06}  loss: {:.5f}'.format(epoch_i+1 ,np.mean(loss_list)))\n",
    "    # early stopping\n",
    "    if np.mean(loss_list) > -0.000001 and (epoch_i > 199 and epoch_i % 100 == 0):\n",
    "      return\n",
    "\n",
    "    if epoch_i % 20 == 0 or epoch_i == NUM_EPOCHS-1:\n",
    "      dummy_graph = graph_dataset[0].clone().to(DEVICE)\n",
    "      num = NUM_GRAPHS_GENERATE if epoch_i != NUM_EPOCHS-1 else NUM_GRAPHS_GENERATE*5\n",
    "      deg_mean, deg_var = generate_graphs(NUM_GRAPHS_GENERATE, epoch_i, model, dummy_graph, config)\n",
    "      generator_loss = (DEGREE-deg_mean)**2 + deg_var\n",
    "      wandb.log({\"graph-unmasking/gen-loss\": generator_loss, \"mean degree\": deg_mean, \"mean degree var\":deg_var, \"graph-unmasking/loss\": np.mean(loss_list)})\n",
    "      print(deg_mean, deg_var)\n",
    "\n",
    "  torch.save(model.state_dict(), \"model.weights\")\n",
    "  wandb.log_artifact(\"model.weights\", name=f'nn_weights_{SWEEP_ID}', type='weights') \n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "qPcPralV7IF0"
   },
   "outputs": [],
   "source": [
    "def start_agent_envelope():\n",
    "  try:\n",
    "    with wandb.init():\n",
    "      config = wandb.config\n",
    "      set_seeds(SWEEP_ID)\n",
    "      print(SWEEP_ID, config)\n",
    "      if not IN_COLAB:\n",
    "        for python_file in sorted(glob.glob('*.ipynb')):\n",
    "          wandb.log_artifact(python_file, name=f\"src_ipynb_{SWEEP_ID}\", type=\"my_dataset\")\n",
    "        for python_file in sorted(glob.glob('*.py')):\n",
    "          wandb.log_artifact(python_file, name=f\"src_py_{SWEEP_ID}\", type=\"my_dataset\")\n",
    "      return start_agent(config)\n",
    "  except Exception:\n",
    "    print(traceback.format_exc())\n",
    "    wandb.log({\"graph-unmasking/gen-loss\": -1,  \"epoch\": -1, \"graph-unmasking/loss\": -1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 662
    },
    "id": "OHuZY5f_4NrN",
    "outputId": "bce6f18d-712e-4e7f-809d-6e701752623f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 001883  loss: -0.38392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: cv26m64r\n",
      "Sweep URL: https://wandb.ai/nextaid/toad_laptop_backup/sweeps/cv26m64r\n",
      "epoch: 001884  loss: -0.37709\n",
      "epoch: 001885  loss: -0.36080\n",
      "epoch: 001886  loss: -0.37131\n",
      "epoch: 001887  loss: -0.37194\n",
      "epoch: 001888  loss: -0.36696\n",
      "epoch: 001889  loss: -0.37182\n",
      "epoch: 001890  loss: -0.34019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 7h0769kj with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcandidate_selection_radius: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgraph_transform: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 5e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: bce\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: pna\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnoise_probability: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnormalization: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_post_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_pass: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttowers: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<IPython.core.display.HTML object>\n",
      "<IPython.core.display.HTML object>\n",
      "<IPython.core.display.HTML object>\n",
      "<IPython.core.display.HTML object>\n",
      "epoch: 001891  loss: -0.37691\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/gerritgrossmann/Documents/devel/MaskedGraphGen/wandb/run-20230601_100130-7h0769kj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nextaid/toad_laptop_backup/runs/7h0769kj' target=\"_blank\">dutiful-sweep-1</a></strong> to <a href='https://wandb.ai/nextaid/toad_laptop_backup' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/nextaid/toad_laptop_backup/sweeps/cv26m64r' target=\"_blank\">https://wandb.ai/nextaid/toad_laptop_backup/sweeps/cv26m64r</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nextaid/toad_laptop_backup' target=\"_blank\">https://wandb.ai/nextaid/toad_laptop_backup</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/nextaid/toad_laptop_backup/sweeps/cv26m64r' target=\"_blank\">https://wandb.ai/nextaid/toad_laptop_backup/sweeps/cv26m64r</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nextaid/toad_laptop_backup/runs/7h0769kj' target=\"_blank\">https://wandb.ai/nextaid/toad_laptop_backup/runs/7h0769kj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv26m64r {'batch_size': 100, 'candidate_selection_radius': 5, 'dropout': 0, 'graph_transform': False, 'hidden_dim': 64, 'hidden_layer': 5, 'learning_rate': 5e-05, 'loss': 'bce', 'model': 'pna', 'noise_probability': 0, 'normalization': True, 'pre_post_layers': 1, 'single_pass': True, 'towers': 2}\n",
      "epoch: 001892  loss: -0.38241\n",
      "epoch: 000001  loss: -0.08101\n",
      "epoch: 001893  loss: -0.34771\n",
      "epoch: 001894  loss: -0.34986\n",
      "epoch: 001895  loss: -0.39069\n",
      "5.583333333333333 2.036111111111111\n",
      "epoch: 001896  loss: -0.36247\n",
      "epoch: 001897  loss: -0.34428\n",
      "epoch: 000002  loss: -0.19223\n",
      "epoch: 001898  loss: -0.34436\n",
      "epoch: 000003  loss: -0.21814\n",
      "epoch: 001899  loss: -0.35211\n",
      "epoch: 000004  loss: -0.19292\n",
      "epoch: 001900  loss: -0.33607\n",
      "epoch: 001901  loss: -0.34881\n",
      "epoch: 000005  loss: -0.23121\n",
      "3.2 0.45\n",
      "epoch: 000006  loss: -0.23460\n",
      "epoch: 001902  loss: -0.33305\n",
      "epoch: 001903  loss: -0.34738\n",
      "epoch: 000007  loss: -0.22055\n",
      "epoch: 001904  loss: -0.33963\n",
      "epoch: 000008  loss: -0.27492\n",
      "epoch: 001905  loss: -0.35753\n",
      "epoch: 001906  loss: -0.35080\n",
      "epoch: 000009  loss: -0.30050\n",
      "epoch: 001907  loss: -0.33431\n",
      "epoch: 000010  loss: -0.33800\n",
      "epoch: 001908  loss: -0.34161\n",
      "epoch: 001909  loss: -0.31717\n",
      "epoch: 000011  loss: -0.40091\n",
      "epoch: 001910  loss: -0.34952\n",
      "epoch: 000012  loss: -0.37178\n",
      "epoch: 001911  loss: -0.31827\n",
      "epoch: 000013  loss: -0.38172\n",
      "epoch: 001912  loss: -0.36330\n",
      "epoch: 001913  loss: -0.36024\n",
      "epoch: 000014  loss: -0.40664\n",
      "epoch: 001914  loss: -0.36431\n",
      "epoch: 000015  loss: -0.35865\n",
      "epoch: 001915  loss: -0.39195\n",
      "epoch: 001916  loss: -0.35217\n",
      "epoch: 000016  loss: -0.42557\n",
      "epoch: 001917  loss: -0.36214\n",
      "epoch: 000017  loss: -0.44347\n",
      "epoch: 001918  loss: -0.36354\n",
      "epoch: 001919  loss: -0.35677\n",
      "epoch: 000018  loss: -0.43124\n",
      "epoch: 001920  loss: -0.34310\n",
      "epoch: 000019  loss: -0.40696\n",
      "epoch: 001921  loss: -0.39366\n",
      "2.9666666666666663 0.35555555555555557\n",
      "epoch: 000020  loss: -0.43293\n",
      "epoch: 001922  loss: -0.38152\n",
      "epoch: 000021  loss: -0.44247\n",
      "epoch: 001923  loss: -0.38080\n",
      "epoch: 001924  loss: -0.38990\n",
      "epoch: 001925  loss: -0.38638\n",
      "2.8833333333333333 0.30277777777777776\n",
      "epoch: 001926  loss: -0.37867\n",
      "epoch: 001927  loss: -0.34958\n",
      "epoch: 000022  loss: -0.41518\n",
      "epoch: 001928  loss: -0.37846\n",
      "epoch: 000023  loss: -0.45070\n",
      "epoch: 001929  loss: -0.35172\n",
      "epoch: 001930  loss: -0.34698\n",
      "epoch: 000024  loss: -0.47504\n",
      "epoch: 001931  loss: -0.35546\n",
      "epoch: 000025  loss: -0.45386\n",
      "epoch: 001932  loss: -0.39012\n",
      "epoch: 001933  loss: -0.38106\n",
      "epoch: 000026  loss: -0.43736\n",
      "epoch: 001934  loss: -0.36061\n",
      "epoch: 000027  loss: -0.43203\n",
      "epoch: 001935  loss: -0.34953\n",
      "epoch: 001936  loss: -0.37939\n",
      "epoch: 000028  loss: -0.48956\n",
      "epoch: 001937  loss: -0.35631\n",
      "epoch: 001938  loss: -0.32511\n",
      "epoch: 000029  loss: -0.48260\n",
      "epoch: 001939  loss: -0.35614\n",
      "epoch: 000030  loss: -0.41166\n",
      "epoch: 001940  loss: -0.36672\n",
      "epoch: 001941  loss: -0.37085\n",
      "epoch: 000031  loss: -0.43977\n",
      "3.2 0.3666666666666667\n",
      "epoch: 000032  loss: -0.43338\n",
      "epoch: 001942  loss: -0.37249\n",
      "epoch: 001943  loss: -0.37715\n",
      "epoch: 000033  loss: -0.48014\n",
      "epoch: 001944  loss: -0.37471\n",
      "epoch: 000034  loss: -0.47904\n",
      "epoch: 001945  loss: -0.37622\n",
      "epoch: 001946  loss: -0.35418\n",
      "epoch: 000035  loss: -0.49860\n",
      "epoch: 001947  loss: -0.36523\n",
      "epoch: 000036  loss: -0.45782\n",
      "epoch: 001948  loss: -0.34255\n",
      "epoch: 001949  loss: -0.33946\n",
      "epoch: 000037  loss: -0.50164\n",
      "epoch: 001950  loss: -0.34443\n",
      "epoch: 000038  loss: -0.45076\n",
      "epoch: 001951  loss: -0.34505\n",
      "epoch: 001952  loss: -0.32246\n",
      "epoch: 000039  loss: -0.50278\n",
      "epoch: 001953  loss: -0.39499\n",
      "epoch: 000040  loss: -0.44077\n",
      "epoch: 001954  loss: -0.35662\n",
      "epoch: 001955  loss: -0.38691\n",
      "epoch: 000041  loss: -0.47558\n",
      "epoch: 001956  loss: -0.38189\n",
      "epoch: 001957  loss: -0.38293\n",
      "3.033333333333333 0.2111111111111111\n",
      "epoch: 001958  loss: -0.39596\n",
      "epoch: 001959  loss: -0.34918\n",
      "epoch: 000042  loss: -0.47639\n",
      "epoch: 001960  loss: -0.34924\n",
      "epoch: 000043  loss: -0.47767\n",
      "epoch: 001961  loss: -0.35773\n",
      "3.3166666666666664 0.4638888888888889\n",
      "epoch: 000044  loss: -0.49111\n",
      "epoch: 001962  loss: -0.35739\n",
      "epoch: 000045  loss: -0.45872\n",
      "epoch: 001963  loss: -0.34036\n",
      "epoch: 001964  loss: -0.37425\n",
      "epoch: 000046  loss: -0.45851\n",
      "epoch: 001965  loss: -0.36202\n",
      "epoch: 000047  loss: -0.46754\n",
      "epoch: 001966  loss: -0.35692\n",
      "epoch: 001967  loss: -0.35319\n",
      "epoch: 000048  loss: -0.48608\n",
      "epoch: 001968  loss: -0.37221\n",
      "epoch: 000049  loss: -0.46279\n",
      "epoch: 001969  loss: -0.34988\n",
      "epoch: 001970  loss: -0.35823\n",
      "epoch: 000050  loss: -0.44879\n",
      "epoch: 001971  loss: -0.35631\n",
      "epoch: 000051  loss: -0.48577\n",
      "epoch: 001972  loss: -0.35607\n",
      "epoch: 001973  loss: -0.37872\n",
      "epoch: 000052  loss: -0.47938\n",
      "epoch: 001974  loss: -0.34752\n",
      "epoch: 001975  loss: -0.33651\n",
      "epoch: 000053  loss: -0.46501\n",
      "epoch: 001976  loss: -0.35546\n",
      "epoch: 000054  loss: -0.48081\n",
      "epoch: 001977  loss: -0.34727\n",
      "epoch: 001978  loss: -0.34450\n",
      "epoch: 000055  loss: -0.52293\n",
      "epoch: 001979  loss: -0.33375\n",
      "epoch: 000056  loss: -0.49855\n",
      "epoch: 001980  loss: -0.38381\n",
      "epoch: 001981  loss: -0.36059\n",
      "epoch: 000057  loss: -0.48331\n",
      "3.1166666666666667 0.42499999999999993\n",
      "epoch: 000058  loss: -0.45433\n",
      "epoch: 001982  loss: -0.36528\n",
      "epoch: 001983  loss: -0.38218\n",
      "epoch: 000059  loss: -0.51182\n",
      "epoch: 001984  loss: -0.38342\n",
      "epoch: 000060  loss: -0.48050\n",
      "epoch: 001985  loss: -0.37732\n",
      "epoch: 001986  loss: -0.37928\n",
      "epoch: 000061  loss: -0.47171\n",
      "epoch: 001987  loss: -0.38831\n",
      "epoch: 001988  loss: -0.35378\n",
      "epoch: 001989  loss: -0.35234\n",
      "2.8666666666666667 0.18888888888888888\n",
      "epoch: 001990  loss: -0.37139\n",
      "epoch: 000062  loss: -0.49866\n",
      "epoch: 001991  loss: -0.36640\n",
      "epoch: 001992  loss: -0.35436\n",
      "epoch: 000063  loss: -0.45014\n",
      "epoch: 001993  loss: -0.37700\n",
      "epoch: 000064  loss: -0.49483\n",
      "epoch: 001994  loss: -0.33829\n",
      "epoch: 000065  loss: -0.48831\n",
      "epoch: 001995  loss: -0.33246\n",
      "epoch: 001996  loss: -0.36617\n",
      "epoch: 000066  loss: -0.45886\n",
      "epoch: 001997  loss: -0.33616\n",
      "epoch: 000067  loss: -0.46630\n",
      "epoch: 001998  loss: -0.33632\n",
      "epoch: 001999  loss: -0.37165\n",
      "epoch: 000068  loss: -0.50603\n",
      "epoch: 002000  loss: -0.35053\n",
      "epoch: 000069  loss: -0.50251\n",
      "3.033333333333333 0.35555555555555557\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/6s/8ht7sjwn76x7837542yzs3hc0000gn/T/ipykernel_15685/3423752096.py\", line 12, in start_agent_envelope\n",
      "    return start_agent(config)\n",
      "  File \"/Users/gerritgrossmann/anaconda3/envs/nextaid/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 3053, in __exit__\n",
      "    self._finish(exit_code)\n",
      "  File \"/Users/gerritgrossmann/anaconda3/envs/nextaid/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 1892, in _finish\n",
      "    tel.feature.finish = True\n",
      "  File \"/Users/gerritgrossmann/anaconda3/envs/nextaid/lib/python3.9/site-packages/wandb/sdk/lib/telemetry.py\", line 42, in __exit__\n",
      "    self._run._telemetry_callback(self._obj)\n",
      "  File \"/Users/gerritgrossmann/anaconda3/envs/nextaid/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 717, in _telemetry_callback\n",
      "    self._telemetry_flush()\n",
      "  File \"/Users/gerritgrossmann/anaconda3/envs/nextaid/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 728, in _telemetry_flush\n",
      "    self._backend.interface._publish_telemetry(self._telemetry_obj)\n",
      "  File \"/Users/gerritgrossmann/anaconda3/envs/nextaid/lib/python3.9/site-packages/wandb/sdk/interface/interface_shared.py\", line 101, in _publish_telemetry\n",
      "    self._publish(rec)\n",
      "  File \"/Users/gerritgrossmann/anaconda3/envs/nextaid/lib/python3.9/site-packages/wandb/sdk/interface/interface_sock.py\", line 51, in _publish\n",
      "    self._sock_client.send_record_publish(record)\n",
      "  File \"/Users/gerritgrossmann/anaconda3/envs/nextaid/lib/python3.9/site-packages/wandb/sdk/lib/sock_client.py\", line 221, in send_record_publish\n",
      "    self.send_server_request(server_req)\n",
      "  File \"/Users/gerritgrossmann/anaconda3/envs/nextaid/lib/python3.9/site-packages/wandb/sdk/lib/sock_client.py\", line 155, in send_server_request\n",
      "    self._send_message(msg)\n",
      "  File \"/Users/gerritgrossmann/anaconda3/envs/nextaid/lib/python3.9/site-packages/wandb/sdk/lib/sock_client.py\", line 152, in _send_message\n",
      "    self._sendall_with_error_handle(header + data)\n",
      "  File \"/Users/gerritgrossmann/anaconda3/envs/nextaid/lib/python3.9/site-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n",
      "    sent = self._sock.send(data)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 000070  loss: -0.49751\n",
      "epoch: 000071  loss: -0.50957\n",
      "epoch: 000072  loss: -0.51796\n",
      "epoch: 000073  loss: -0.48986\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>graph-unmasking/gen-loss</td><td></td></tr><tr><td>graph-unmasking/loss</td><td></td></tr><tr><td>mean degree</td><td></td></tr><tr><td>mean degree var</td><td></td></tr><tr><td>num_parameters</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>-1</td></tr><tr><td>graph-unmasking/gen-loss</td><td>-1</td></tr><tr><td>graph-unmasking/loss</td><td>-1</td></tr><tr><td>mean degree</td><td>3.03333</td></tr><tr><td>mean degree var</td><td>0.35556</td></tr><tr><td>num_parameters</td><td>332251</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dutiful-sweep-1</strong> at: <a href='https://wandb.ai/nextaid/toad_laptop_backup/runs/7h0769kj' target=\"_blank\">https://wandb.ai/nextaid/toad_laptop_backup/runs/7h0769kj</a><br/>Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230601_100130-7h0769kj/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 000074  loss: -0.50598\n",
      "epoch: 000075  loss: -0.48847\n",
      "epoch: 000076  loss: -0.50130\n",
      "epoch: 000077  loss: -0.47186\n",
      "epoch: 000078  loss: -0.50638\n",
      "epoch: 000079  loss: -0.49178\n",
      "epoch: 000080  loss: -0.45078\n",
      "epoch: 000081  loss: -0.45498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 7h0769kj errored: Error('You must call wandb.init() before wandb.log()')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/6s/8ht7sjwn76x7837542yzs3hc0000gn/T/ipykernel_15685/3423752096.py\", line 12, in start_agent_envelope\n",
      "    return start_agent(config)\n",
      "  File \"/var/folders/6s/8ht7sjwn76x7837542yzs3hc0000gn/T/ipykernel_15685/3964869227.py\", line 36, in start_agent\n",
      "    wandb.log({\"graph-unmasking/gen-loss\": generator_loss, \"mean degree\": deg_mean, \"mean degree var\":deg_var, \"graph-unmasking/loss\": np.mean(loss_list)})\n",
      "  File \"/Users/gerritgrossmann/anaconda3/envs/nextaid/lib/python3.9/site-packages/wandb/sdk/lib/preinit.py\", line 36, in preinit_wrapper\n",
      "    raise wandb.Error(f\"You must call wandb.init() before {name}()\")\n",
      "wandb.errors.Error: You must call wandb.init() before wandb.log()\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: xwcbr8hw with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 500\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcandidate_selection_radius: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgraph_transform: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer: 6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss: bce\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: pna\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnoise_probability: 0.05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnormalization: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpre_post_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsingle_pass: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \ttowers: 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/gerritgrossmann/Documents/devel/MaskedGraphGen/wandb/run-20230601_120020-xwcbr8hw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nextaid/toad_laptop_backup/runs/xwcbr8hw' target=\"_blank\">solar-sweep-2</a></strong> to <a href='https://wandb.ai/nextaid/toad_laptop_backup' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/nextaid/toad_laptop_backup/sweeps/cv26m64r' target=\"_blank\">https://wandb.ai/nextaid/toad_laptop_backup/sweeps/cv26m64r</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nextaid/toad_laptop_backup' target=\"_blank\">https://wandb.ai/nextaid/toad_laptop_backup</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/nextaid/toad_laptop_backup/sweeps/cv26m64r' target=\"_blank\">https://wandb.ai/nextaid/toad_laptop_backup/sweeps/cv26m64r</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nextaid/toad_laptop_backup/runs/xwcbr8hw' target=\"_blank\">https://wandb.ai/nextaid/toad_laptop_backup/runs/xwcbr8hw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv26m64r {'batch_size': 500, 'candidate_selection_radius': 5, 'dropout': 0, 'graph_transform': True, 'hidden_dim': 16, 'hidden_layer': 6, 'learning_rate': 1e-05, 'loss': 'bce', 'model': 'pna', 'noise_probability': 0.05, 'normalization': False, 'pre_post_layers': 1, 'single_pass': True, 'towers': 2}\n",
      "epoch: 000001  loss: 0.03530\n",
      "5.933333333333334 2.638888888888889\n",
      "epoch: 000002  loss: 0.03945\n",
      "epoch: 000003  loss: 0.04199\n",
      "epoch: 000004  loss: 0.03764\n",
      "epoch: 000005  loss: 0.03857\n",
      "epoch: 000006  loss: 0.04090\n",
      "epoch: 000007  loss: 0.03872\n",
      "epoch: 000008  loss: 0.03489\n",
      "epoch: 000009  loss: 0.03526\n",
      "epoch: 000010  loss: 0.03413\n",
      "epoch: 000011  loss: 0.03153\n",
      "epoch: 000012  loss: 0.03395\n",
      "epoch: 000013  loss: 0.03370\n",
      "epoch: 000014  loss: 0.03218\n",
      "epoch: 000015  loss: 0.02891\n",
      "epoch: 000016  loss: 0.03393\n",
      "epoch: 000017  loss: 0.03060\n",
      "epoch: 000018  loss: 0.03236\n",
      "epoch: 000019  loss: 0.03233\n",
      "epoch: 000020  loss: 0.02700\n",
      "epoch: 000021  loss: 0.02412\n",
      "5.833333333333334 2.3111111111111113\n",
      "epoch: 000022  loss: 0.02784\n",
      "epoch: 000023  loss: 0.03252\n",
      "epoch: 000024  loss: 0.02953\n",
      "epoch: 000025  loss: 0.03029\n",
      "epoch: 000026  loss: 0.02673\n",
      "epoch: 000027  loss: 0.03099\n",
      "epoch: 000028  loss: 0.02735\n",
      "epoch: 000029  loss: 0.02672\n",
      "epoch: 000030  loss: 0.02829\n",
      "epoch: 000031  loss: 0.02513\n",
      "epoch: 000032  loss: 0.02605\n",
      "epoch: 000033  loss: 0.02401\n",
      "epoch: 000034  loss: 0.02677\n",
      "epoch: 000035  loss: 0.02474\n",
      "epoch: 000036  loss: 0.02411\n",
      "epoch: 000037  loss: 0.02552\n",
      "epoch: 000038  loss: 0.02464\n",
      "epoch: 000039  loss: 0.02456\n",
      "epoch: 000040  loss: 0.02370\n",
      "epoch: 000041  loss: 0.02366\n",
      "5.716666666666667 2.236111111111111\n",
      "epoch: 000042  loss: 0.02625\n",
      "epoch: 000043  loss: 0.02531\n",
      "epoch: 000044  loss: 0.02395\n",
      "epoch: 000045  loss: 0.02354\n",
      "epoch: 000046  loss: 0.02303\n",
      "epoch: 000047  loss: 0.02460\n",
      "epoch: 000048  loss: 0.02156\n",
      "epoch: 000049  loss: 0.02161\n",
      "epoch: 000050  loss: 0.02225\n",
      "epoch: 000051  loss: 0.02196\n",
      "epoch: 000052  loss: 0.02042\n",
      "epoch: 000053  loss: 0.01769\n",
      "epoch: 000054  loss: 0.01961\n",
      "epoch: 000055  loss: 0.01780\n",
      "epoch: 000056  loss: 0.01627\n",
      "epoch: 000057  loss: 0.01763\n",
      "epoch: 000058  loss: 0.01667\n",
      "epoch: 000059  loss: 0.01557\n",
      "epoch: 000060  loss: 0.01490\n",
      "epoch: 000061  loss: 0.01733\n",
      "5.583333333333334 2.375\n",
      "epoch: 000062  loss: 0.01531\n",
      "epoch: 000063  loss: 0.01415\n",
      "epoch: 000064  loss: 0.01646\n",
      "epoch: 000065  loss: 0.01368\n",
      "epoch: 000066  loss: 0.01396\n",
      "epoch: 000067  loss: 0.01336\n",
      "epoch: 000068  loss: 0.01450\n",
      "epoch: 000069  loss: 0.01144\n",
      "epoch: 000070  loss: 0.01220\n",
      "epoch: 000071  loss: 0.01144\n",
      "epoch: 000072  loss: 0.01184\n",
      "epoch: 000073  loss: 0.01046\n",
      "epoch: 000074  loss: 0.00961\n",
      "epoch: 000075  loss: 0.01042\n",
      "epoch: 000076  loss: 0.01045\n",
      "epoch: 000077  loss: 0.00919\n",
      "epoch: 000078  loss: 0.00782\n",
      "epoch: 000079  loss: 0.00793\n",
      "epoch: 000080  loss: 0.00742\n",
      "epoch: 000081  loss: 0.00675\n",
      "5.733333333333333 2.644444444444444\n",
      "epoch: 000082  loss: 0.00755\n",
      "epoch: 000083  loss: 0.00550\n",
      "epoch: 000084  loss: 0.00645\n",
      "epoch: 000085  loss: 0.00532\n",
      "epoch: 000086  loss: 0.00482\n",
      "epoch: 000087  loss: 0.00484\n",
      "epoch: 000088  loss: 0.00455\n",
      "epoch: 000089  loss: 0.00472\n",
      "epoch: 000090  loss: 0.00401\n",
      "epoch: 000091  loss: 0.00439\n",
      "epoch: 000092  loss: 0.00321\n",
      "epoch: 000093  loss: 0.00297\n",
      "epoch: 000094  loss: 0.00253\n",
      "epoch: 000095  loss: 0.00233\n",
      "epoch: 000096  loss: 0.00202\n",
      "epoch: 000097  loss: 0.00194\n",
      "epoch: 000098  loss: 0.00139\n",
      "epoch: 000099  loss: 0.00106\n",
      "epoch: 000100  loss: 0.00070\n",
      "epoch: 000101  loss: 0.00048\n",
      "5.5 2.527777777777778\n",
      "epoch: 000102  loss: 0.00012\n",
      "epoch: 000103  loss: -0.00019\n",
      "epoch: 000104  loss: -0.00060\n",
      "epoch: 000105  loss: -0.00087\n",
      "epoch: 000106  loss: -0.00116\n",
      "epoch: 000107  loss: -0.00136\n",
      "epoch: 000108  loss: -0.00194\n",
      "epoch: 000109  loss: -0.00227\n",
      "epoch: 000110  loss: -0.00259\n",
      "epoch: 000111  loss: -0.00298\n",
      "epoch: 000112  loss: -0.00367\n",
      "epoch: 000113  loss: -0.00403\n",
      "epoch: 000114  loss: -0.00424\n",
      "epoch: 000115  loss: -0.00439\n",
      "epoch: 000116  loss: -0.00490\n",
      "epoch: 000117  loss: -0.00618\n",
      "epoch: 000118  loss: -0.00555\n",
      "epoch: 000119  loss: -0.00589\n",
      "epoch: 000120  loss: -0.00707\n",
      "epoch: 000121  loss: -0.00723\n",
      "5.3500000000000005 2.6027777777777774\n",
      "epoch: 000122  loss: -0.00737\n",
      "epoch: 000123  loss: -0.00754\n",
      "epoch: 000124  loss: -0.00872\n",
      "epoch: 000125  loss: -0.00844\n",
      "epoch: 000126  loss: -0.01071\n",
      "epoch: 000127  loss: -0.01040\n",
      "epoch: 000128  loss: -0.00929\n",
      "epoch: 000129  loss: -0.01037\n",
      "epoch: 000130  loss: -0.01237\n",
      "epoch: 000131  loss: -0.01278\n",
      "epoch: 000132  loss: -0.01247\n",
      "epoch: 000133  loss: -0.01381\n",
      "epoch: 000134  loss: -0.01380\n",
      "epoch: 000135  loss: -0.01306\n",
      "epoch: 000136  loss: -0.01570\n",
      "epoch: 000137  loss: -0.01726\n",
      "epoch: 000138  loss: -0.01520\n",
      "epoch: 000139  loss: -0.01687\n",
      "epoch: 000140  loss: -0.01570\n",
      "epoch: 000141  loss: -0.01875\n",
      "4.750000000000001 2.341666666666667\n",
      "epoch: 000142  loss: -0.02006\n",
      "epoch: 000143  loss: -0.01814\n",
      "epoch: 000144  loss: -0.02074\n",
      "epoch: 000145  loss: -0.02297\n",
      "epoch: 000146  loss: -0.02476\n",
      "epoch: 000147  loss: -0.02140\n",
      "epoch: 000148  loss: -0.02426\n",
      "epoch: 000149  loss: -0.02513\n",
      "epoch: 000150  loss: -0.02800\n",
      "epoch: 000151  loss: -0.03032\n",
      "epoch: 000152  loss: -0.03028\n",
      "epoch: 000153  loss: -0.02944\n",
      "epoch: 000154  loss: -0.03179\n",
      "epoch: 000155  loss: -0.03575\n",
      "epoch: 000156  loss: -0.03654\n",
      "epoch: 000157  loss: -0.03854\n",
      "epoch: 000158  loss: -0.03733\n",
      "epoch: 000159  loss: -0.04088\n",
      "epoch: 000160  loss: -0.04007\n",
      "epoch: 000161  loss: -0.04685\n",
      "5.033333333333333 2.422222222222222\n",
      "epoch: 000162  loss: -0.03977\n",
      "epoch: 000163  loss: -0.04509\n",
      "epoch: 000164  loss: -0.04105\n",
      "epoch: 000165  loss: -0.05043\n",
      "epoch: 000166  loss: -0.05718\n",
      "epoch: 000167  loss: -0.04564\n",
      "epoch: 000168  loss: -0.05540\n",
      "epoch: 000169  loss: -0.06792\n",
      "epoch: 000170  loss: -0.05953\n",
      "epoch: 000171  loss: -0.06632\n",
      "epoch: 000172  loss: -0.06482\n",
      "epoch: 000173  loss: -0.06210\n",
      "epoch: 000174  loss: -0.07544\n",
      "epoch: 000175  loss: -0.07289\n",
      "epoch: 000176  loss: -0.08763\n",
      "epoch: 000177  loss: -0.09086\n",
      "epoch: 000178  loss: -0.08692\n",
      "epoch: 000179  loss: -0.09416\n",
      "epoch: 000180  loss: -0.08482\n",
      "epoch: 000181  loss: -0.10387\n",
      "4.416666666666667 2.4972222222222227\n",
      "epoch: 000182  loss: -0.08540\n",
      "epoch: 000183  loss: -0.10135\n",
      "epoch: 000184  loss: -0.12062\n",
      "epoch: 000185  loss: -0.09829\n",
      "epoch: 000186  loss: -0.12317\n",
      "epoch: 000187  loss: -0.12267\n",
      "epoch: 000188  loss: -0.13478\n",
      "epoch: 000189  loss: -0.13091\n",
      "epoch: 000190  loss: -0.12429\n",
      "epoch: 000191  loss: -0.13154\n",
      "epoch: 000192  loss: -0.12266\n",
      "epoch: 000193  loss: -0.14413\n",
      "epoch: 000194  loss: -0.14796\n",
      "epoch: 000195  loss: -0.16508\n",
      "epoch: 000196  loss: -0.15162\n",
      "epoch: 000197  loss: -0.15710\n",
      "epoch: 000198  loss: -0.15621\n",
      "epoch: 000199  loss: -0.15836\n",
      "epoch: 000200  loss: -0.13884\n",
      "epoch: 000201  loss: -0.16068\n",
      "3.833333333333333 1.9333333333333331\n",
      "epoch: 000202  loss: -0.15982\n",
      "epoch: 000203  loss: -0.16059\n",
      "epoch: 000204  loss: -0.17350\n",
      "epoch: 000205  loss: -0.18573\n",
      "epoch: 000206  loss: -0.17074\n",
      "epoch: 000207  loss: -0.15199\n",
      "epoch: 000208  loss: -0.16678\n",
      "epoch: 000209  loss: -0.15195\n",
      "epoch: 000210  loss: -0.16685\n",
      "epoch: 000211  loss: -0.15678\n",
      "epoch: 000212  loss: -0.16999\n",
      "epoch: 000213  loss: -0.15799\n",
      "epoch: 000214  loss: -0.16370\n",
      "epoch: 000215  loss: -0.16417\n",
      "epoch: 000216  loss: -0.16361\n",
      "epoch: 000217  loss: -0.15868\n",
      "epoch: 000218  loss: -0.18334\n",
      "epoch: 000219  loss: -0.16199\n",
      "epoch: 000220  loss: -0.17044\n",
      "epoch: 000221  loss: -0.17698\n",
      "3.65 2.069444444444444\n",
      "epoch: 000222  loss: -0.17509\n",
      "epoch: 000223  loss: -0.17046\n",
      "epoch: 000224  loss: -0.17294\n",
      "epoch: 000225  loss: -0.15789\n",
      "epoch: 000226  loss: -0.17742\n",
      "epoch: 000227  loss: -0.17950\n",
      "epoch: 000228  loss: -0.16084\n",
      "epoch: 000229  loss: -0.16335\n",
      "epoch: 000230  loss: -0.17450\n",
      "epoch: 000231  loss: -0.17669\n",
      "epoch: 000232  loss: -0.17510\n",
      "epoch: 000233  loss: -0.16322\n",
      "epoch: 000234  loss: -0.15993\n",
      "epoch: 000235  loss: -0.16066\n",
      "epoch: 000236  loss: -0.15617\n",
      "epoch: 000237  loss: -0.16765\n",
      "epoch: 000238  loss: -0.15798\n",
      "epoch: 000239  loss: -0.17540\n",
      "epoch: 000240  loss: -0.18551\n",
      "epoch: 000241  loss: -0.15686\n",
      "3.383333333333333 1.9249999999999996\n",
      "epoch: 000242  loss: -0.16097\n",
      "epoch: 000243  loss: -0.15880\n",
      "epoch: 000244  loss: -0.19267\n",
      "epoch: 000245  loss: -0.14650\n",
      "epoch: 000246  loss: -0.14819\n",
      "epoch: 000247  loss: -0.19910\n",
      "epoch: 000248  loss: -0.17183\n",
      "epoch: 000249  loss: -0.16301\n",
      "epoch: 000250  loss: -0.17908\n",
      "epoch: 000251  loss: -0.17746\n",
      "epoch: 000252  loss: -0.16373\n",
      "epoch: 000253  loss: -0.18212\n",
      "epoch: 000254  loss: -0.17819\n",
      "epoch: 000255  loss: -0.16570\n",
      "epoch: 000256  loss: -0.16131\n",
      "epoch: 000257  loss: -0.14480\n",
      "epoch: 000258  loss: -0.15275\n",
      "epoch: 000259  loss: -0.16669\n",
      "epoch: 000260  loss: -0.16185\n",
      "epoch: 000261  loss: -0.17688\n",
      "3.3166666666666673 2.0027777777777773\n",
      "epoch: 000262  loss: -0.15974\n",
      "epoch: 000263  loss: -0.16535\n",
      "epoch: 000264  loss: -0.16822\n",
      "epoch: 000265  loss: -0.17813\n",
      "epoch: 000266  loss: -0.18346\n",
      "epoch: 000267  loss: -0.18606\n",
      "epoch: 000268  loss: -0.16892\n",
      "epoch: 000269  loss: -0.15641\n",
      "epoch: 000270  loss: -0.17859\n",
      "epoch: 000271  loss: -0.17439\n",
      "epoch: 000272  loss: -0.16232\n",
      "epoch: 000273  loss: -0.14663\n",
      "epoch: 000274  loss: -0.15902\n",
      "epoch: 000275  loss: -0.16206\n",
      "epoch: 000276  loss: -0.14070\n",
      "epoch: 000277  loss: -0.15533\n",
      "epoch: 000278  loss: -0.18149\n",
      "epoch: 000279  loss: -0.17284\n",
      "epoch: 000280  loss: -0.17581\n",
      "epoch: 000281  loss: -0.17621\n",
      "3.1 1.6111111111111112\n",
      "epoch: 000282  loss: -0.16545\n",
      "epoch: 000283  loss: -0.16008\n",
      "epoch: 000284  loss: -0.15209\n",
      "epoch: 000285  loss: -0.18009\n",
      "epoch: 000286  loss: -0.17839\n",
      "epoch: 000287  loss: -0.17396\n",
      "epoch: 000288  loss: -0.16340\n",
      "epoch: 000289  loss: -0.14835\n",
      "epoch: 000290  loss: -0.16718\n",
      "epoch: 000291  loss: -0.18398\n",
      "epoch: 000292  loss: -0.16708\n",
      "epoch: 000293  loss: -0.15620\n",
      "epoch: 000294  loss: -0.16984\n",
      "epoch: 000295  loss: -0.16092\n",
      "epoch: 000296  loss: -0.15309\n",
      "epoch: 000297  loss: -0.17819\n",
      "epoch: 000298  loss: -0.17232\n",
      "epoch: 000299  loss: -0.17575\n",
      "epoch: 000300  loss: -0.16581\n",
      "epoch: 000301  loss: -0.16291\n",
      "3.6166666666666663 1.6305555555555553\n",
      "epoch: 000302  loss: -0.17442\n",
      "epoch: 000303  loss: -0.16552\n",
      "epoch: 000304  loss: -0.14393\n",
      "epoch: 000305  loss: -0.17267\n",
      "epoch: 000306  loss: -0.18058\n",
      "epoch: 000307  loss: -0.16928\n",
      "epoch: 000308  loss: -0.15642\n",
      "epoch: 000309  loss: -0.17325\n",
      "epoch: 000310  loss: -0.17252\n",
      "epoch: 000311  loss: -0.16828\n",
      "epoch: 000312  loss: -0.15480\n",
      "epoch: 000313  loss: -0.16576\n",
      "epoch: 000314  loss: -0.17356\n",
      "epoch: 000315  loss: -0.19064\n",
      "epoch: 000316  loss: -0.17376\n",
      "epoch: 000317  loss: -0.17896\n",
      "epoch: 000318  loss: -0.16159\n",
      "epoch: 000319  loss: -0.18764\n",
      "epoch: 000320  loss: -0.18404\n",
      "epoch: 000321  loss: -0.17369\n",
      "3.35 1.847222222222222\n",
      "epoch: 000322  loss: -0.16278\n",
      "epoch: 000323  loss: -0.17431\n",
      "epoch: 000324  loss: -0.16322\n",
      "epoch: 000325  loss: -0.17216\n",
      "epoch: 000326  loss: -0.17024\n",
      "epoch: 000327  loss: -0.17263\n",
      "epoch: 000328  loss: -0.17267\n",
      "epoch: 000329  loss: -0.18662\n",
      "epoch: 000330  loss: -0.16947\n",
      "epoch: 000331  loss: -0.16841\n",
      "epoch: 000332  loss: -0.18352\n",
      "epoch: 000333  loss: -0.16427\n",
      "epoch: 000334  loss: -0.16971\n",
      "epoch: 000335  loss: -0.16866\n",
      "epoch: 000336  loss: -0.16803\n",
      "epoch: 000337  loss: -0.17586\n",
      "epoch: 000338  loss: -0.17919\n",
      "epoch: 000339  loss: -0.16953\n",
      "epoch: 000340  loss: -0.17550\n",
      "epoch: 000341  loss: -0.17926\n",
      "3.4333333333333336 1.7722222222222226\n",
      "epoch: 000342  loss: -0.16815\n",
      "epoch: 000343  loss: -0.17026\n",
      "epoch: 000344  loss: -0.19011\n",
      "epoch: 000345  loss: -0.16970\n",
      "epoch: 000346  loss: -0.17932\n",
      "epoch: 000347  loss: -0.19396\n",
      "epoch: 000348  loss: -0.17182\n",
      "epoch: 000349  loss: -0.18705\n",
      "epoch: 000350  loss: -0.16591\n",
      "epoch: 000351  loss: -0.16944\n",
      "epoch: 000352  loss: -0.19976\n",
      "epoch: 000353  loss: -0.17122\n",
      "epoch: 000354  loss: -0.18799\n",
      "epoch: 000355  loss: -0.18527\n",
      "epoch: 000356  loss: -0.19914\n",
      "epoch: 000357  loss: -0.17696\n",
      "epoch: 000358  loss: -0.16277\n",
      "epoch: 000359  loss: -0.19334\n",
      "epoch: 000360  loss: -0.16330\n",
      "epoch: 000361  loss: -0.18361\n",
      "3.6333333333333337 1.8166666666666669\n",
      "epoch: 000362  loss: -0.17425\n",
      "epoch: 000363  loss: -0.19429\n",
      "epoch: 000364  loss: -0.17303\n",
      "epoch: 000365  loss: -0.19162\n",
      "epoch: 000366  loss: -0.16851\n",
      "epoch: 000367  loss: -0.17520\n",
      "epoch: 000368  loss: -0.18838\n",
      "epoch: 000369  loss: -0.18793\n",
      "epoch: 000370  loss: -0.19541\n",
      "epoch: 000371  loss: -0.16447\n",
      "epoch: 000372  loss: -0.17213\n",
      "epoch: 000373  loss: -0.19908\n",
      "epoch: 000374  loss: -0.17262\n",
      "epoch: 000375  loss: -0.19935\n",
      "epoch: 000376  loss: -0.19524\n",
      "epoch: 000377  loss: -0.16637\n",
      "epoch: 000378  loss: -0.16908\n",
      "epoch: 000379  loss: -0.16587\n",
      "epoch: 000380  loss: -0.18330\n",
      "epoch: 000381  loss: -0.17855\n",
      "3.3666666666666663 1.911111111111111\n",
      "epoch: 000382  loss: -0.19300\n",
      "epoch: 000383  loss: -0.19852\n",
      "epoch: 000384  loss: -0.17626\n",
      "epoch: 000385  loss: -0.17555\n",
      "epoch: 000386  loss: -0.18792\n",
      "epoch: 000387  loss: -0.19041\n",
      "epoch: 000388  loss: -0.18542\n",
      "epoch: 000389  loss: -0.17487\n",
      "epoch: 000390  loss: -0.18253\n",
      "epoch: 000391  loss: -0.17888\n",
      "epoch: 000392  loss: -0.17590\n",
      "epoch: 000393  loss: -0.16552\n",
      "epoch: 000394  loss: -0.19641\n",
      "epoch: 000395  loss: -0.20913\n",
      "epoch: 000396  loss: -0.17012\n",
      "epoch: 000397  loss: -0.19690\n",
      "epoch: 000398  loss: -0.17261\n",
      "epoch: 000399  loss: -0.17136\n",
      "epoch: 000400  loss: -0.17118\n",
      "epoch: 000401  loss: -0.17953\n",
      "3.0666666666666664 1.8055555555555558\n",
      "epoch: 000402  loss: -0.18593\n",
      "epoch: 000403  loss: -0.19648\n",
      "epoch: 000404  loss: -0.18602\n",
      "epoch: 000405  loss: -0.19764\n",
      "epoch: 000406  loss: -0.18963\n",
      "epoch: 000407  loss: -0.16838\n",
      "epoch: 000408  loss: -0.19873\n",
      "epoch: 000409  loss: -0.18648\n",
      "epoch: 000410  loss: -0.18728\n",
      "epoch: 000411  loss: -0.18877\n",
      "epoch: 000412  loss: -0.17059\n",
      "epoch: 000413  loss: -0.17528\n",
      "epoch: 000414  loss: -0.16765\n",
      "epoch: 000415  loss: -0.20485\n",
      "epoch: 000416  loss: -0.18376\n",
      "epoch: 000417  loss: -0.19564\n",
      "epoch: 000418  loss: -0.18423\n",
      "epoch: 000419  loss: -0.20791\n",
      "epoch: 000420  loss: -0.18959\n",
      "epoch: 000421  loss: -0.18982\n",
      "2.85 1.8972222222222221\n",
      "epoch: 000422  loss: -0.17175\n",
      "epoch: 000423  loss: -0.18419\n",
      "epoch: 000424  loss: -0.17398\n",
      "epoch: 000425  loss: -0.19883\n",
      "epoch: 000426  loss: -0.18957\n",
      "epoch: 000427  loss: -0.18002\n",
      "epoch: 000428  loss: -0.19075\n",
      "epoch: 000429  loss: -0.16235\n",
      "epoch: 000430  loss: -0.18550\n",
      "epoch: 000431  loss: -0.17348\n",
      "epoch: 000432  loss: -0.18709\n",
      "epoch: 000433  loss: -0.16292\n",
      "epoch: 000434  loss: -0.19293\n",
      "epoch: 000435  loss: -0.21123\n",
      "epoch: 000436  loss: -0.19824\n",
      "epoch: 000437  loss: -0.17777\n",
      "epoch: 000438  loss: -0.17024\n",
      "epoch: 000439  loss: -0.18664\n",
      "epoch: 000440  loss: -0.18567\n",
      "epoch: 000441  loss: -0.16921\n",
      "3.5333333333333328 2.0833333333333335\n",
      "epoch: 000442  loss: -0.19216\n",
      "epoch: 000443  loss: -0.17040\n",
      "epoch: 000444  loss: -0.18077\n",
      "epoch: 000445  loss: -0.15344\n",
      "epoch: 000446  loss: -0.17362\n",
      "epoch: 000447  loss: -0.16632\n",
      "epoch: 000448  loss: -0.17737\n",
      "epoch: 000449  loss: -0.18843\n",
      "epoch: 000450  loss: -0.17267\n",
      "epoch: 000451  loss: -0.16605\n",
      "epoch: 000452  loss: -0.19394\n",
      "epoch: 000453  loss: -0.19321\n",
      "epoch: 000454  loss: -0.17495\n",
      "epoch: 000455  loss: -0.17825\n",
      "epoch: 000456  loss: -0.17953\n",
      "epoch: 000457  loss: -0.15814\n",
      "epoch: 000458  loss: -0.17882\n",
      "epoch: 000459  loss: -0.18253\n",
      "epoch: 000460  loss: -0.16846\n",
      "epoch: 000461  loss: -0.17666\n",
      "2.9999999999999996 2.1166666666666663\n",
      "epoch: 000462  loss: -0.17918\n",
      "epoch: 000463  loss: -0.17532\n",
      "epoch: 000464  loss: -0.17395\n",
      "epoch: 000465  loss: -0.18084\n",
      "epoch: 000466  loss: -0.17762\n",
      "epoch: 000467  loss: -0.18332\n",
      "epoch: 000468  loss: -0.15973\n",
      "epoch: 000469  loss: -0.19029\n",
      "epoch: 000470  loss: -0.17622\n",
      "epoch: 000471  loss: -0.18179\n",
      "epoch: 000472  loss: -0.17595\n",
      "epoch: 000473  loss: -0.17161\n",
      "epoch: 000474  loss: -0.17301\n",
      "epoch: 000475  loss: -0.17196\n",
      "epoch: 000476  loss: -0.18614\n",
      "epoch: 000477  loss: -0.16866\n",
      "epoch: 000478  loss: -0.16964\n",
      "epoch: 000479  loss: -0.16618\n",
      "epoch: 000480  loss: -0.17322\n",
      "epoch: 000481  loss: -0.18712\n",
      "3.2 1.7277777777777779\n",
      "epoch: 000482  loss: -0.18234\n",
      "epoch: 000483  loss: -0.17067\n",
      "epoch: 000484  loss: -0.17151\n",
      "epoch: 000485  loss: -0.15995\n",
      "epoch: 000486  loss: -0.17932\n",
      "epoch: 000487  loss: -0.18592\n",
      "epoch: 000488  loss: -0.17549\n",
      "epoch: 000489  loss: -0.18564\n",
      "epoch: 000490  loss: -0.17529\n",
      "epoch: 000491  loss: -0.18890\n",
      "epoch: 000492  loss: -0.16649\n",
      "epoch: 000493  loss: -0.18852\n",
      "epoch: 000494  loss: -0.18998\n",
      "epoch: 000495  loss: -0.16714\n",
      "epoch: 000496  loss: -0.18736\n",
      "epoch: 000497  loss: -0.16415\n",
      "epoch: 000498  loss: -0.18374\n",
      "epoch: 000499  loss: -0.17361\n",
      "epoch: 000500  loss: -0.15735\n",
      "epoch: 000501  loss: -0.20708\n",
      "3.3 2.2\n",
      "epoch: 000502  loss: -0.18067\n",
      "epoch: 000503  loss: -0.18927\n",
      "epoch: 000504  loss: -0.17028\n",
      "epoch: 000505  loss: -0.19878\n",
      "epoch: 000506  loss: -0.17027\n",
      "epoch: 000507  loss: -0.18609\n",
      "epoch: 000508  loss: -0.18395\n",
      "epoch: 000509  loss: -0.17458\n",
      "epoch: 000510  loss: -0.16971\n",
      "epoch: 000511  loss: -0.17750\n",
      "epoch: 000512  loss: -0.17673\n",
      "epoch: 000513  loss: -0.17934\n",
      "epoch: 000514  loss: -0.17677\n",
      "epoch: 000515  loss: -0.19548\n",
      "epoch: 000516  loss: -0.17457\n",
      "epoch: 000517  loss: -0.20411\n",
      "epoch: 000518  loss: -0.17037\n",
      "epoch: 000519  loss: -0.17397\n",
      "epoch: 000520  loss: -0.17237\n",
      "epoch: 000521  loss: -0.19165\n",
      "3.3166666666666673 2.1638888888888888\n",
      "epoch: 000522  loss: -0.16787\n",
      "epoch: 000523  loss: -0.15396\n",
      "epoch: 000524  loss: -0.18132\n",
      "epoch: 000525  loss: -0.18392\n",
      "epoch: 000526  loss: -0.16857\n",
      "epoch: 000527  loss: -0.18851\n",
      "epoch: 000528  loss: -0.16232\n",
      "epoch: 000529  loss: -0.17416\n",
      "epoch: 000530  loss: -0.17953\n",
      "epoch: 000531  loss: -0.17209\n",
      "epoch: 000532  loss: -0.17479\n",
      "epoch: 000533  loss: -0.17817\n",
      "epoch: 000534  loss: -0.19000\n",
      "epoch: 000535  loss: -0.16940\n",
      "epoch: 000536  loss: -0.16996\n",
      "epoch: 000537  loss: -0.18450\n",
      "epoch: 000538  loss: -0.17234\n",
      "epoch: 000539  loss: -0.19157\n",
      "epoch: 000540  loss: -0.17383\n",
      "epoch: 000541  loss: -0.18288\n",
      "3.4666666666666663 2.166666666666667\n",
      "epoch: 000542  loss: -0.16838\n",
      "epoch: 000543  loss: -0.17703\n",
      "epoch: 000544  loss: -0.19011\n",
      "epoch: 000545  loss: -0.17975\n",
      "epoch: 000546  loss: -0.17394\n",
      "epoch: 000547  loss: -0.19339\n",
      "epoch: 000548  loss: -0.18860\n",
      "epoch: 000549  loss: -0.17643\n",
      "epoch: 000550  loss: -0.18035\n",
      "epoch: 000551  loss: -0.19158\n",
      "epoch: 000552  loss: -0.17633\n",
      "epoch: 000553  loss: -0.18321\n",
      "epoch: 000554  loss: -0.17788\n",
      "epoch: 000555  loss: -0.19087\n",
      "epoch: 000556  loss: -0.18153\n",
      "epoch: 000557  loss: -0.18902\n",
      "epoch: 000558  loss: -0.16168\n",
      "epoch: 000559  loss: -0.17468\n",
      "epoch: 000560  loss: -0.17918\n",
      "epoch: 000561  loss: -0.15813\n",
      "3.633333333333333 1.9777777777777774\n",
      "epoch: 000562  loss: -0.18756\n",
      "epoch: 000563  loss: -0.19916\n",
      "epoch: 000564  loss: -0.18819\n",
      "epoch: 000565  loss: -0.18159\n",
      "epoch: 000566  loss: -0.19247\n",
      "epoch: 000567  loss: -0.18930\n",
      "epoch: 000568  loss: -0.17161\n",
      "epoch: 000569  loss: -0.18384\n",
      "epoch: 000570  loss: -0.18450\n",
      "epoch: 000571  loss: -0.17930\n",
      "epoch: 000572  loss: -0.18388\n",
      "epoch: 000573  loss: -0.18175\n",
      "epoch: 000574  loss: -0.15567\n",
      "epoch: 000575  loss: -0.20403\n",
      "epoch: 000576  loss: -0.19144\n",
      "epoch: 000577  loss: -0.18104\n",
      "epoch: 000578  loss: -0.16128\n",
      "epoch: 000579  loss: -0.18280\n",
      "epoch: 000580  loss: -0.17929\n",
      "epoch: 000581  loss: -0.18647\n",
      "2.783333333333333 1.597222222222222\n",
      "epoch: 000582  loss: -0.18038\n",
      "epoch: 000583  loss: -0.17615\n",
      "epoch: 000584  loss: -0.18928\n",
      "epoch: 000585  loss: -0.18714\n",
      "epoch: 000586  loss: -0.17740\n",
      "epoch: 000587  loss: -0.18431\n",
      "epoch: 000588  loss: -0.16405\n",
      "epoch: 000589  loss: -0.21154\n",
      "epoch: 000590  loss: -0.18932\n",
      "epoch: 000591  loss: -0.18243\n",
      "epoch: 000592  loss: -0.18533\n",
      "epoch: 000593  loss: -0.19319\n",
      "epoch: 000594  loss: -0.19964\n",
      "epoch: 000595  loss: -0.19736\n",
      "epoch: 000596  loss: -0.20907\n",
      "epoch: 000597  loss: -0.20242\n",
      "epoch: 000598  loss: -0.19515\n",
      "epoch: 000599  loss: -0.20146\n",
      "epoch: 000600  loss: -0.19157\n",
      "epoch: 000601  loss: -0.20886\n",
      "2.966666666666667 1.9166666666666667\n",
      "epoch: 000602  loss: -0.21188\n",
      "epoch: 000603  loss: -0.19009\n",
      "epoch: 000604  loss: -0.19446\n",
      "epoch: 000605  loss: -0.21761\n",
      "epoch: 000606  loss: -0.20142\n",
      "epoch: 000607  loss: -0.18747\n",
      "epoch: 000608  loss: -0.17334\n",
      "epoch: 000609  loss: -0.20108\n",
      "epoch: 000610  loss: -0.19257\n",
      "epoch: 000611  loss: -0.20925\n",
      "epoch: 000612  loss: -0.18501\n",
      "epoch: 000613  loss: -0.19782\n",
      "epoch: 000614  loss: -0.20303\n",
      "epoch: 000615  loss: -0.21160\n",
      "epoch: 000616  loss: -0.18178\n",
      "epoch: 000617  loss: -0.19508\n",
      "epoch: 000618  loss: -0.19286\n",
      "epoch: 000619  loss: -0.19933\n",
      "epoch: 000620  loss: -0.21540\n",
      "epoch: 000621  loss: -0.20553\n",
      "3.1333333333333337 1.838888888888889\n",
      "epoch: 000622  loss: -0.17796\n",
      "epoch: 000623  loss: -0.19344\n",
      "epoch: 000624  loss: -0.19144\n",
      "epoch: 000625  loss: -0.18811\n",
      "epoch: 000626  loss: -0.16477\n",
      "epoch: 000627  loss: -0.20136\n",
      "epoch: 000628  loss: -0.19284\n",
      "epoch: 000629  loss: -0.16996\n",
      "epoch: 000630  loss: -0.17409\n",
      "epoch: 000631  loss: -0.19412\n",
      "epoch: 000632  loss: -0.18769\n",
      "epoch: 000633  loss: -0.19060\n",
      "epoch: 000634  loss: -0.19195\n",
      "epoch: 000635  loss: -0.17703\n",
      "epoch: 000636  loss: -0.18637\n",
      "epoch: 000637  loss: -0.19705\n",
      "epoch: 000638  loss: -0.20156\n",
      "epoch: 000639  loss: -0.18697\n",
      "epoch: 000640  loss: -0.19174\n",
      "epoch: 000641  loss: -0.17992\n",
      "3.3 1.9\n",
      "epoch: 000642  loss: -0.17805\n",
      "epoch: 000643  loss: -0.19032\n",
      "epoch: 000644  loss: -0.18249\n",
      "epoch: 000645  loss: -0.20676\n",
      "epoch: 000646  loss: -0.21007\n",
      "epoch: 000647  loss: -0.19501\n",
      "epoch: 000648  loss: -0.19370\n",
      "epoch: 000649  loss: -0.20474\n",
      "epoch: 000650  loss: -0.20152\n",
      "epoch: 000651  loss: -0.20704\n",
      "epoch: 000652  loss: -0.19202\n",
      "epoch: 000653  loss: -0.16958\n",
      "epoch: 000654  loss: -0.19042\n",
      "epoch: 000655  loss: -0.16784\n",
      "epoch: 000656  loss: -0.18972\n",
      "epoch: 000657  loss: -0.17566\n",
      "epoch: 000658  loss: -0.17403\n",
      "epoch: 000659  loss: -0.18324\n",
      "epoch: 000660  loss: -0.18472\n",
      "epoch: 000661  loss: -0.17900\n",
      "3.2666666666666666 1.827777777777778\n",
      "epoch: 000662  loss: -0.19621\n",
      "epoch: 000663  loss: -0.18723\n",
      "epoch: 000664  loss: -0.17744\n",
      "epoch: 000665  loss: -0.17752\n",
      "epoch: 000666  loss: -0.17001\n",
      "epoch: 000667  loss: -0.18248\n",
      "epoch: 000668  loss: -0.18710\n",
      "epoch: 000669  loss: -0.18474\n",
      "epoch: 000670  loss: -0.17861\n",
      "epoch: 000671  loss: -0.20987\n",
      "epoch: 000672  loss: -0.19797\n",
      "epoch: 000673  loss: -0.18797\n",
      "epoch: 000674  loss: -0.19497\n",
      "epoch: 000675  loss: -0.18693\n",
      "epoch: 000676  loss: -0.16771\n",
      "epoch: 000677  loss: -0.17005\n",
      "epoch: 000678  loss: -0.20123\n",
      "epoch: 000679  loss: -0.17814\n",
      "epoch: 000680  loss: -0.18233\n",
      "epoch: 000681  loss: -0.17077\n",
      "3.6333333333333337 1.8277777777777775\n",
      "epoch: 000682  loss: -0.16231\n",
      "epoch: 000683  loss: -0.17521\n",
      "epoch: 000684  loss: -0.19275\n",
      "epoch: 000685  loss: -0.19023\n",
      "epoch: 000686  loss: -0.16852\n",
      "epoch: 000687  loss: -0.17883\n",
      "epoch: 000688  loss: -0.18539\n",
      "epoch: 000689  loss: -0.18409\n",
      "epoch: 000690  loss: -0.17702\n",
      "epoch: 000691  loss: -0.18583\n",
      "epoch: 000692  loss: -0.18854\n",
      "epoch: 000693  loss: -0.17282\n",
      "epoch: 000694  loss: -0.21276\n",
      "epoch: 000695  loss: -0.16500\n",
      "epoch: 000696  loss: -0.17080\n",
      "epoch: 000697  loss: -0.17405\n",
      "epoch: 000698  loss: -0.17487\n",
      "epoch: 000699  loss: -0.20343\n",
      "epoch: 000700  loss: -0.18070\n",
      "epoch: 000701  loss: -0.18763\n",
      "2.9 1.6388888888888888\n",
      "epoch: 000702  loss: -0.19380\n",
      "epoch: 000703  loss: -0.18606\n",
      "epoch: 000704  loss: -0.16862\n",
      "epoch: 000705  loss: -0.17628\n",
      "epoch: 000706  loss: -0.18076\n",
      "epoch: 000707  loss: -0.19682\n",
      "epoch: 000708  loss: -0.18257\n",
      "epoch: 000709  loss: -0.18585\n",
      "epoch: 000710  loss: -0.18289\n",
      "epoch: 000711  loss: -0.19597\n",
      "epoch: 000712  loss: -0.17956\n",
      "epoch: 000713  loss: -0.16669\n",
      "epoch: 000714  loss: -0.17515\n",
      "epoch: 000715  loss: -0.17751\n",
      "epoch: 000716  loss: -0.18847\n",
      "epoch: 000717  loss: -0.17307\n",
      "epoch: 000718  loss: -0.19504\n",
      "epoch: 000719  loss: -0.18191\n",
      "epoch: 000720  loss: -0.19250\n",
      "epoch: 000721  loss: -0.20295\n",
      "3.5166666666666666 2.136111111111111\n",
      "epoch: 000722  loss: -0.17490\n",
      "epoch: 000723  loss: -0.19849\n",
      "epoch: 000724  loss: -0.18879\n",
      "epoch: 000725  loss: -0.20182\n",
      "epoch: 000726  loss: -0.19172\n",
      "epoch: 000727  loss: -0.20751\n",
      "epoch: 000728  loss: -0.20864\n",
      "epoch: 000729  loss: -0.17042\n",
      "epoch: 000730  loss: -0.18106\n",
      "epoch: 000731  loss: -0.18383\n",
      "epoch: 000732  loss: -0.18460\n",
      "epoch: 000733  loss: -0.19075\n",
      "epoch: 000734  loss: -0.19550\n",
      "epoch: 000735  loss: -0.19701\n",
      "epoch: 000736  loss: -0.18982\n",
      "epoch: 000737  loss: -0.21709\n",
      "epoch: 000738  loss: -0.18347\n",
      "epoch: 000739  loss: -0.20605\n",
      "epoch: 000740  loss: -0.19019\n",
      "epoch: 000741  loss: -0.19114\n",
      "3.1500000000000004 1.9416666666666669\n",
      "epoch: 000742  loss: -0.20274\n",
      "epoch: 000743  loss: -0.20115\n",
      "epoch: 000744  loss: -0.19884\n",
      "epoch: 000745  loss: -0.18660\n",
      "epoch: 000746  loss: -0.20611\n",
      "epoch: 000747  loss: -0.21422\n",
      "epoch: 000748  loss: -0.20063\n",
      "epoch: 000749  loss: -0.17933\n",
      "epoch: 000750  loss: -0.17569\n",
      "epoch: 000751  loss: -0.18662\n",
      "epoch: 000752  loss: -0.17736\n",
      "epoch: 000753  loss: -0.20070\n",
      "epoch: 000754  loss: -0.18457\n",
      "epoch: 000755  loss: -0.19231\n",
      "epoch: 000756  loss: -0.18232\n",
      "epoch: 000757  loss: -0.18553\n",
      "epoch: 000758  loss: -0.20890\n",
      "epoch: 000759  loss: -0.19400\n",
      "epoch: 000760  loss: -0.19452\n",
      "epoch: 000761  loss: -0.19845\n",
      "3.3166666666666673 1.6472222222222226\n",
      "epoch: 000762  loss: -0.18763\n",
      "epoch: 000763  loss: -0.17756\n",
      "epoch: 000764  loss: -0.17969\n",
      "epoch: 000765  loss: -0.19426\n",
      "epoch: 000766  loss: -0.18584\n",
      "epoch: 000767  loss: -0.18456\n",
      "epoch: 000768  loss: -0.18285\n",
      "epoch: 000769  loss: -0.17321\n",
      "epoch: 000770  loss: -0.20966\n",
      "epoch: 000771  loss: -0.18970\n",
      "epoch: 000772  loss: -0.18629\n",
      "epoch: 000773  loss: -0.19573\n",
      "epoch: 000774  loss: -0.18605\n",
      "epoch: 000775  loss: -0.19082\n",
      "epoch: 000776  loss: -0.19617\n",
      "epoch: 000777  loss: -0.20954\n",
      "epoch: 000778  loss: -0.19005\n",
      "epoch: 000779  loss: -0.20180\n",
      "epoch: 000780  loss: -0.19147\n",
      "epoch: 000781  loss: -0.19403\n",
      "3.383333333333333 1.7194444444444443\n",
      "epoch: 000782  loss: -0.17674\n",
      "epoch: 000783  loss: -0.19689\n",
      "epoch: 000784  loss: -0.20384\n",
      "epoch: 000785  loss: -0.19597\n",
      "epoch: 000786  loss: -0.19756\n",
      "epoch: 000787  loss: -0.18793\n",
      "epoch: 000788  loss: -0.20761\n",
      "epoch: 000789  loss: -0.20880\n",
      "epoch: 000790  loss: -0.18579\n",
      "epoch: 000791  loss: -0.18828\n",
      "epoch: 000792  loss: -0.19601\n",
      "epoch: 000793  loss: -0.19114\n",
      "epoch: 000794  loss: -0.20242\n",
      "epoch: 000795  loss: -0.18385\n",
      "epoch: 000796  loss: -0.19170\n",
      "epoch: 000797  loss: -0.21936\n",
      "epoch: 000798  loss: -0.21286\n",
      "epoch: 000799  loss: -0.19565\n",
      "epoch: 000800  loss: -0.20772\n",
      "epoch: 000801  loss: -0.19136\n",
      "3.0666666666666664 1.9777777777777779\n",
      "epoch: 000802  loss: -0.16772\n",
      "epoch: 000803  loss: -0.19024\n",
      "epoch: 000804  loss: -0.22755\n",
      "epoch: 000805  loss: -0.20040\n",
      "epoch: 000806  loss: -0.19841\n",
      "epoch: 000807  loss: -0.21819\n",
      "epoch: 000808  loss: -0.20903\n",
      "epoch: 000809  loss: -0.20928\n",
      "epoch: 000810  loss: -0.20549\n",
      "epoch: 000811  loss: -0.19580\n",
      "epoch: 000812  loss: -0.20698\n",
      "epoch: 000813  loss: -0.21352\n",
      "epoch: 000814  loss: -0.21064\n",
      "epoch: 000815  loss: -0.20382\n",
      "epoch: 000816  loss: -0.20851\n",
      "epoch: 000817  loss: -0.19523\n",
      "epoch: 000818  loss: -0.21071\n",
      "epoch: 000819  loss: -0.20636\n",
      "epoch: 000820  loss: -0.19251\n",
      "epoch: 000821  loss: -0.20003\n",
      "3.05 1.7583333333333335\n",
      "epoch: 000822  loss: -0.21678\n",
      "epoch: 000823  loss: -0.18626\n",
      "epoch: 000824  loss: -0.22173\n",
      "epoch: 000825  loss: -0.20758\n",
      "epoch: 000826  loss: -0.19026\n",
      "epoch: 000827  loss: -0.21034\n",
      "epoch: 000828  loss: -0.21124\n",
      "epoch: 000829  loss: -0.20701\n",
      "epoch: 000830  loss: -0.20348\n",
      "epoch: 000831  loss: -0.18921\n",
      "epoch: 000832  loss: -0.19770\n",
      "epoch: 000833  loss: -0.19235\n",
      "epoch: 000834  loss: -0.18692\n",
      "epoch: 000835  loss: -0.20444\n",
      "epoch: 000836  loss: -0.19290\n",
      "epoch: 000837  loss: -0.20322\n",
      "epoch: 000838  loss: -0.21686\n",
      "epoch: 000839  loss: -0.19231\n",
      "epoch: 000840  loss: -0.19235\n",
      "epoch: 000841  loss: -0.21501\n",
      "3.0333333333333337 1.9999999999999996\n",
      "epoch: 000842  loss: -0.20224\n",
      "epoch: 000843  loss: -0.20634\n",
      "epoch: 000844  loss: -0.19326\n",
      "epoch: 000845  loss: -0.19617\n",
      "epoch: 000846  loss: -0.20922\n",
      "epoch: 000847  loss: -0.18921\n",
      "epoch: 000848  loss: -0.19096\n",
      "epoch: 000849  loss: -0.20573\n",
      "epoch: 000850  loss: -0.18484\n",
      "epoch: 000851  loss: -0.18765\n",
      "epoch: 000852  loss: -0.21155\n",
      "epoch: 000853  loss: -0.19493\n",
      "epoch: 000854  loss: -0.19413\n",
      "epoch: 000855  loss: -0.20543\n",
      "epoch: 000856  loss: -0.21753\n",
      "epoch: 000857  loss: -0.21007\n",
      "epoch: 000858  loss: -0.18693\n",
      "epoch: 000859  loss: -0.22140\n",
      "epoch: 000860  loss: -0.20606\n",
      "epoch: 000861  loss: -0.21450\n",
      "3.25 1.975\n",
      "epoch: 000862  loss: -0.20527\n",
      "epoch: 000863  loss: -0.21450\n",
      "epoch: 000864  loss: -0.21919\n",
      "epoch: 000865  loss: -0.21349\n",
      "epoch: 000866  loss: -0.21013\n",
      "epoch: 000867  loss: -0.20219\n",
      "epoch: 000868  loss: -0.21610\n",
      "epoch: 000869  loss: -0.19592\n",
      "epoch: 000870  loss: -0.20461\n",
      "epoch: 000871  loss: -0.22039\n",
      "epoch: 000872  loss: -0.18311\n",
      "epoch: 000873  loss: -0.19989\n",
      "epoch: 000874  loss: -0.19363\n",
      "epoch: 000875  loss: -0.20613\n",
      "epoch: 000876  loss: -0.20185\n",
      "epoch: 000877  loss: -0.18834\n",
      "epoch: 000878  loss: -0.18310\n",
      "epoch: 000879  loss: -0.20682\n",
      "epoch: 000880  loss: -0.17869\n",
      "epoch: 000881  loss: -0.20364\n",
      "3.0166666666666666 1.9305555555555558\n",
      "epoch: 000882  loss: -0.19676\n",
      "epoch: 000883  loss: -0.18346\n",
      "epoch: 000884  loss: -0.18065\n",
      "epoch: 000885  loss: -0.20102\n",
      "epoch: 000886  loss: -0.19087\n",
      "epoch: 000887  loss: -0.17999\n",
      "epoch: 000888  loss: -0.19057\n",
      "epoch: 000889  loss: -0.19824\n",
      "epoch: 000890  loss: -0.20134\n",
      "epoch: 000891  loss: -0.20858\n",
      "epoch: 000892  loss: -0.18924\n",
      "epoch: 000893  loss: -0.20678\n",
      "epoch: 000894  loss: -0.19086\n",
      "epoch: 000895  loss: -0.17731\n",
      "epoch: 000896  loss: -0.19940\n",
      "epoch: 000897  loss: -0.19886\n",
      "epoch: 000898  loss: -0.18390\n",
      "epoch: 000899  loss: -0.22582\n",
      "epoch: 000900  loss: -0.20316\n",
      "epoch: 000901  loss: -0.20688\n",
      "3.3 2.1888888888888887\n",
      "epoch: 000902  loss: -0.19943\n",
      "epoch: 000903  loss: -0.18781\n",
      "epoch: 000904  loss: -0.20343\n",
      "epoch: 000905  loss: -0.19653\n",
      "epoch: 000906  loss: -0.21262\n",
      "epoch: 000907  loss: -0.20578\n",
      "epoch: 000908  loss: -0.19035\n",
      "epoch: 000909  loss: -0.21902\n",
      "epoch: 000910  loss: -0.21055\n",
      "epoch: 000911  loss: -0.16864\n",
      "epoch: 000912  loss: -0.18826\n",
      "epoch: 000913  loss: -0.18697\n",
      "epoch: 000914  loss: -0.20789\n",
      "epoch: 000915  loss: -0.20013\n",
      "epoch: 000916  loss: -0.17582\n",
      "epoch: 000917  loss: -0.21005\n",
      "epoch: 000918  loss: -0.19118\n",
      "epoch: 000919  loss: -0.18830\n",
      "epoch: 000920  loss: -0.21291\n",
      "epoch: 000921  loss: -0.19075\n",
      "3.15 1.8916666666666668\n",
      "epoch: 000922  loss: -0.19787\n",
      "epoch: 000923  loss: -0.21579\n",
      "epoch: 000924  loss: -0.19927\n",
      "epoch: 000925  loss: -0.18876\n",
      "epoch: 000926  loss: -0.20890\n",
      "epoch: 000927  loss: -0.21274\n",
      "epoch: 000928  loss: -0.19880\n",
      "epoch: 000929  loss: -0.19815\n",
      "epoch: 000930  loss: -0.18517\n",
      "epoch: 000931  loss: -0.17239\n",
      "epoch: 000932  loss: -0.19303\n",
      "epoch: 000933  loss: -0.19667\n",
      "epoch: 000934  loss: -0.21379\n",
      "epoch: 000935  loss: -0.18170\n",
      "epoch: 000936  loss: -0.21205\n",
      "epoch: 000937  loss: -0.18696\n",
      "epoch: 000938  loss: -0.18769\n",
      "epoch: 000939  loss: -0.19662\n",
      "epoch: 000940  loss: -0.18633\n",
      "epoch: 000941  loss: -0.17743\n",
      "3.1166666666666667 2.2416666666666663\n",
      "epoch: 000942  loss: -0.18970\n",
      "epoch: 000943  loss: -0.19172\n",
      "epoch: 000944  loss: -0.19139\n",
      "epoch: 000945  loss: -0.19980\n",
      "epoch: 000946  loss: -0.17688\n",
      "epoch: 000947  loss: -0.18923\n",
      "epoch: 000948  loss: -0.19740\n",
      "epoch: 000949  loss: -0.20146\n",
      "epoch: 000950  loss: -0.20314\n",
      "epoch: 000951  loss: -0.19295\n",
      "epoch: 000952  loss: -0.16513\n",
      "epoch: 000953  loss: -0.21376\n",
      "epoch: 000954  loss: -0.18073\n",
      "epoch: 000955  loss: -0.19878\n",
      "epoch: 000956  loss: -0.19526\n",
      "epoch: 000957  loss: -0.19886\n",
      "epoch: 000958  loss: -0.21584\n",
      "epoch: 000959  loss: -0.19693\n",
      "epoch: 000960  loss: -0.19716\n",
      "epoch: 000961  loss: -0.18331\n",
      "2.9333333333333336 2.105555555555555\n",
      "epoch: 000962  loss: -0.22235\n",
      "epoch: 000963  loss: -0.19841\n",
      "epoch: 000964  loss: -0.20100\n",
      "epoch: 000965  loss: -0.21353\n",
      "epoch: 000966  loss: -0.18236\n",
      "epoch: 000967  loss: -0.19113\n",
      "epoch: 000968  loss: -0.18787\n",
      "epoch: 000969  loss: -0.21548\n",
      "epoch: 000970  loss: -0.18911\n",
      "epoch: 000971  loss: -0.20055\n",
      "epoch: 000972  loss: -0.20844\n",
      "epoch: 000973  loss: -0.19402\n",
      "epoch: 000974  loss: -0.20619\n",
      "epoch: 000975  loss: -0.20117\n",
      "epoch: 000976  loss: -0.21980\n",
      "epoch: 000977  loss: -0.19390\n",
      "epoch: 000978  loss: -0.20135\n",
      "epoch: 000979  loss: -0.19613\n",
      "epoch: 000980  loss: -0.19009\n",
      "epoch: 000981  loss: -0.18840\n",
      "3.1666666666666665 1.7444444444444442\n",
      "epoch: 000982  loss: -0.18577\n",
      "epoch: 000983  loss: -0.22166\n",
      "epoch: 000984  loss: -0.20173\n",
      "epoch: 000985  loss: -0.18355\n",
      "epoch: 000986  loss: -0.19841\n",
      "epoch: 000987  loss: -0.20522\n",
      "epoch: 000988  loss: -0.19004\n",
      "epoch: 000989  loss: -0.20011\n",
      "epoch: 000990  loss: -0.20113\n",
      "epoch: 000991  loss: -0.21285\n",
      "epoch: 000992  loss: -0.18052\n",
      "epoch: 000993  loss: -0.21950\n",
      "epoch: 000994  loss: -0.20183\n",
      "epoch: 000995  loss: -0.19243\n",
      "epoch: 000996  loss: -0.20575\n",
      "epoch: 000997  loss: -0.18564\n",
      "epoch: 000998  loss: -0.21744\n",
      "epoch: 000999  loss: -0.20033\n",
      "epoch: 001000  loss: -0.21716\n",
      "epoch: 001001  loss: -0.18862\n",
      "2.766666666666667 1.7777777777777775\n",
      "epoch: 001002  loss: -0.20563\n",
      "epoch: 001003  loss: -0.20840\n",
      "epoch: 001004  loss: -0.19455\n",
      "epoch: 001005  loss: -0.22997\n",
      "epoch: 001006  loss: -0.20481\n",
      "epoch: 001007  loss: -0.20958\n",
      "epoch: 001008  loss: -0.20160\n",
      "epoch: 001009  loss: -0.22615\n",
      "epoch: 001010  loss: -0.22058\n",
      "epoch: 001011  loss: -0.20267\n",
      "epoch: 001012  loss: -0.22476\n",
      "epoch: 001013  loss: -0.19096\n",
      "epoch: 001014  loss: -0.20149\n",
      "epoch: 001015  loss: -0.19854\n",
      "epoch: 001016  loss: -0.18347\n",
      "epoch: 001017  loss: -0.20400\n",
      "epoch: 001018  loss: -0.21092\n",
      "epoch: 001019  loss: -0.20961\n",
      "epoch: 001020  loss: -0.21403\n",
      "epoch: 001021  loss: -0.23887\n",
      "3.0166666666666666 2.575\n",
      "epoch: 001022  loss: -0.19327\n",
      "epoch: 001023  loss: -0.21309\n",
      "epoch: 001024  loss: -0.19243\n",
      "epoch: 001025  loss: -0.22222\n",
      "epoch: 001026  loss: -0.20713\n",
      "epoch: 001027  loss: -0.19529\n",
      "epoch: 001028  loss: -0.21017\n",
      "epoch: 001029  loss: -0.20453\n",
      "epoch: 001030  loss: -0.18837\n",
      "epoch: 001031  loss: -0.21263\n",
      "epoch: 001032  loss: -0.18936\n",
      "epoch: 001033  loss: -0.20359\n",
      "epoch: 001034  loss: -0.21159\n",
      "epoch: 001035  loss: -0.19762\n",
      "epoch: 001036  loss: -0.20627\n",
      "epoch: 001037  loss: -0.20270\n",
      "epoch: 001038  loss: -0.19485\n",
      "epoch: 001039  loss: -0.20061\n",
      "epoch: 001040  loss: -0.21934\n",
      "epoch: 001041  loss: -0.16472\n",
      "3.0 1.9555555555555553\n",
      "epoch: 001042  loss: -0.18249\n",
      "epoch: 001043  loss: -0.19855\n",
      "epoch: 001044  loss: -0.19435\n",
      "epoch: 001045  loss: -0.19579\n",
      "epoch: 001046  loss: -0.19218\n",
      "epoch: 001047  loss: -0.19136\n",
      "epoch: 001048  loss: -0.20649\n",
      "epoch: 001049  loss: -0.18826\n",
      "epoch: 001050  loss: -0.21577\n",
      "epoch: 001051  loss: -0.18726\n",
      "epoch: 001052  loss: -0.22026\n",
      "epoch: 001053  loss: -0.20154\n",
      "epoch: 001054  loss: -0.20093\n",
      "epoch: 001055  loss: -0.21452\n",
      "epoch: 001056  loss: -0.18711\n",
      "epoch: 001057  loss: -0.18288\n",
      "epoch: 001058  loss: -0.22081\n",
      "epoch: 001059  loss: -0.20674\n",
      "epoch: 001060  loss: -0.21570\n",
      "epoch: 001061  loss: -0.21573\n",
      "2.85 1.7194444444444443\n",
      "epoch: 001062  loss: -0.21360\n",
      "epoch: 001063  loss: -0.19945\n",
      "epoch: 001064  loss: -0.20007\n",
      "epoch: 001065  loss: -0.19829\n",
      "epoch: 001066  loss: -0.20642\n",
      "epoch: 001067  loss: -0.21432\n",
      "epoch: 001068  loss: -0.23031\n",
      "epoch: 001069  loss: -0.22862\n",
      "epoch: 001070  loss: -0.17782\n",
      "epoch: 001071  loss: -0.18549\n",
      "epoch: 001072  loss: -0.21433\n",
      "epoch: 001073  loss: -0.20161\n",
      "epoch: 001074  loss: -0.18535\n",
      "epoch: 001075  loss: -0.20584\n",
      "epoch: 001076  loss: -0.19626\n",
      "epoch: 001077  loss: -0.22430\n",
      "epoch: 001078  loss: -0.22952\n",
      "epoch: 001079  loss: -0.20293\n",
      "epoch: 001080  loss: -0.20182\n",
      "epoch: 001081  loss: -0.20195\n",
      "3.2666666666666666 2.2222222222222223\n",
      "epoch: 001082  loss: -0.19587\n",
      "epoch: 001083  loss: -0.20388\n",
      "epoch: 001084  loss: -0.21378\n",
      "epoch: 001085  loss: -0.20737\n",
      "epoch: 001086  loss: -0.21456\n",
      "epoch: 001087  loss: -0.18404\n",
      "epoch: 001088  loss: -0.19740\n",
      "epoch: 001089  loss: -0.21240\n",
      "epoch: 001090  loss: -0.20554\n",
      "epoch: 001091  loss: -0.20928\n",
      "epoch: 001092  loss: -0.21095\n",
      "epoch: 001093  loss: -0.19698\n",
      "epoch: 001094  loss: -0.19832\n",
      "epoch: 001095  loss: -0.22987\n",
      "epoch: 001096  loss: -0.19294\n",
      "epoch: 001097  loss: -0.19953\n",
      "epoch: 001098  loss: -0.19158\n",
      "epoch: 001099  loss: -0.20892\n",
      "epoch: 001100  loss: -0.21155\n",
      "epoch: 001101  loss: -0.19957\n",
      "3.1333333333333333 1.7333333333333336\n",
      "epoch: 001102  loss: -0.20690\n",
      "epoch: 001103  loss: -0.17252\n",
      "epoch: 001104  loss: -0.20769\n",
      "epoch: 001105  loss: -0.22401\n",
      "epoch: 001106  loss: -0.21930\n",
      "epoch: 001107  loss: -0.22075\n",
      "epoch: 001108  loss: -0.21799\n",
      "epoch: 001109  loss: -0.19617\n",
      "epoch: 001110  loss: -0.18549\n",
      "epoch: 001111  loss: -0.23337\n",
      "epoch: 001112  loss: -0.19163\n",
      "epoch: 001113  loss: -0.17201\n",
      "epoch: 001114  loss: -0.20552\n",
      "epoch: 001115  loss: -0.20440\n",
      "epoch: 001116  loss: -0.22001\n",
      "epoch: 001117  loss: -0.19512\n",
      "epoch: 001118  loss: -0.19689\n",
      "epoch: 001119  loss: -0.18294\n",
      "epoch: 001120  loss: -0.19355\n",
      "epoch: 001121  loss: -0.19431\n",
      "2.8666666666666667 1.777777777777778\n",
      "epoch: 001122  loss: -0.22705\n",
      "epoch: 001123  loss: -0.21028\n",
      "epoch: 001124  loss: -0.18318\n",
      "epoch: 001125  loss: -0.19931\n",
      "epoch: 001126  loss: -0.21024\n",
      "epoch: 001127  loss: -0.18916\n",
      "epoch: 001128  loss: -0.18491\n",
      "epoch: 001129  loss: -0.19377\n",
      "epoch: 001130  loss: -0.20849\n",
      "epoch: 001131  loss: -0.19719\n",
      "epoch: 001132  loss: -0.18288\n",
      "epoch: 001133  loss: -0.18927\n",
      "epoch: 001134  loss: -0.18925\n",
      "epoch: 001135  loss: -0.19951\n",
      "epoch: 001136  loss: -0.18202\n",
      "epoch: 001137  loss: -0.19330\n",
      "epoch: 001138  loss: -0.20299\n",
      "epoch: 001139  loss: -0.19085\n",
      "epoch: 001140  loss: -0.19280\n",
      "epoch: 001141  loss: -0.20638\n",
      "3.1999999999999997 1.8055555555555554\n",
      "epoch: 001142  loss: -0.18869\n",
      "epoch: 001143  loss: -0.20298\n",
      "epoch: 001144  loss: -0.18475\n",
      "epoch: 001145  loss: -0.19959\n",
      "epoch: 001146  loss: -0.19343\n",
      "epoch: 001147  loss: -0.20529\n",
      "epoch: 001148  loss: -0.19881\n",
      "epoch: 001149  loss: -0.19010\n",
      "epoch: 001150  loss: -0.22744\n",
      "epoch: 001151  loss: -0.20587\n",
      "epoch: 001152  loss: -0.20904\n",
      "epoch: 001153  loss: -0.22048\n",
      "epoch: 001154  loss: -0.20041\n",
      "epoch: 001155  loss: -0.20128\n",
      "epoch: 001156  loss: -0.19257\n",
      "epoch: 001157  loss: -0.21157\n",
      "epoch: 001158  loss: -0.21003\n",
      "epoch: 001159  loss: -0.22782\n",
      "epoch: 001160  loss: -0.20264\n",
      "epoch: 001161  loss: -0.21836\n",
      "3.3166666666666673 1.713888888888889\n",
      "epoch: 001162  loss: -0.22313\n",
      "epoch: 001163  loss: -0.23651\n",
      "epoch: 001164  loss: -0.18628\n",
      "epoch: 001165  loss: -0.18876\n",
      "epoch: 001166  loss: -0.21597\n",
      "epoch: 001167  loss: -0.22226\n",
      "epoch: 001168  loss: -0.20574\n",
      "epoch: 001169  loss: -0.21154\n",
      "epoch: 001170  loss: -0.22386\n",
      "epoch: 001171  loss: -0.20033\n",
      "epoch: 001172  loss: -0.21839\n",
      "epoch: 001173  loss: -0.22076\n",
      "epoch: 001174  loss: -0.18825\n",
      "epoch: 001175  loss: -0.19466\n",
      "epoch: 001176  loss: -0.19535\n",
      "epoch: 001177  loss: -0.22406\n",
      "epoch: 001178  loss: -0.19521\n",
      "epoch: 001179  loss: -0.21108\n",
      "epoch: 001180  loss: -0.22699\n",
      "epoch: 001181  loss: -0.18003\n",
      "2.95 1.9305555555555558\n",
      "epoch: 001182  loss: -0.18810\n",
      "epoch: 001183  loss: -0.20313\n",
      "epoch: 001184  loss: -0.21317\n",
      "epoch: 001185  loss: -0.20509\n",
      "epoch: 001186  loss: -0.18986\n",
      "epoch: 001187  loss: -0.22270\n",
      "epoch: 001188  loss: -0.21126\n",
      "epoch: 001189  loss: -0.21308\n",
      "epoch: 001190  loss: -0.20457\n",
      "epoch: 001191  loss: -0.19636\n",
      "epoch: 001192  loss: -0.19810\n",
      "epoch: 001193  loss: -0.20996\n",
      "epoch: 001194  loss: -0.21042\n",
      "epoch: 001195  loss: -0.18955\n",
      "epoch: 001196  loss: -0.20901\n",
      "epoch: 001197  loss: -0.21705\n",
      "epoch: 001198  loss: -0.20468\n",
      "epoch: 001199  loss: -0.23476\n",
      "epoch: 001200  loss: -0.20243\n",
      "epoch: 001201  loss: -0.19714\n",
      "3.166666666666667 1.9055555555555557\n",
      "epoch: 001202  loss: -0.18460\n",
      "epoch: 001203  loss: -0.21263\n",
      "epoch: 001204  loss: -0.23416\n",
      "epoch: 001205  loss: -0.21731\n",
      "epoch: 001206  loss: -0.20281\n",
      "epoch: 001207  loss: -0.21376\n",
      "epoch: 001208  loss: -0.20784\n",
      "epoch: 001209  loss: -0.20787\n",
      "epoch: 001210  loss: -0.20537\n",
      "epoch: 001211  loss: -0.22026\n",
      "epoch: 001212  loss: -0.21118\n",
      "epoch: 001213  loss: -0.19532\n",
      "epoch: 001214  loss: -0.20495\n",
      "epoch: 001215  loss: -0.21248\n",
      "epoch: 001216  loss: -0.22368\n",
      "epoch: 001217  loss: -0.19156\n",
      "epoch: 001218  loss: -0.20736\n",
      "epoch: 001219  loss: -0.20386\n",
      "epoch: 001220  loss: -0.22745\n",
      "epoch: 001221  loss: -0.20827\n",
      "2.966666666666667 2.2777777777777777\n",
      "epoch: 001222  loss: -0.21074\n",
      "epoch: 001223  loss: -0.22221\n",
      "epoch: 001224  loss: -0.20051\n",
      "epoch: 001225  loss: -0.21964\n",
      "epoch: 001226  loss: -0.21570\n",
      "epoch: 001227  loss: -0.21641\n",
      "epoch: 001228  loss: -0.21079\n",
      "epoch: 001229  loss: -0.20860\n",
      "epoch: 001230  loss: -0.21086\n",
      "epoch: 001231  loss: -0.22180\n",
      "epoch: 001232  loss: -0.21343\n",
      "epoch: 001233  loss: -0.20828\n",
      "epoch: 001234  loss: -0.20468\n",
      "epoch: 001235  loss: -0.20271\n",
      "epoch: 001236  loss: -0.18955\n",
      "epoch: 001237  loss: -0.20561\n",
      "epoch: 001238  loss: -0.20645\n",
      "epoch: 001239  loss: -0.21468\n",
      "epoch: 001240  loss: -0.21086\n",
      "epoch: 001241  loss: -0.21111\n",
      "3.116666666666667 1.7305555555555554\n",
      "epoch: 001242  loss: -0.19984\n",
      "epoch: 001243  loss: -0.20521\n",
      "epoch: 001244  loss: -0.19379\n",
      "epoch: 001245  loss: -0.18699\n",
      "epoch: 001246  loss: -0.20701\n",
      "epoch: 001247  loss: -0.20667\n",
      "epoch: 001248  loss: -0.19602\n",
      "epoch: 001249  loss: -0.20615\n",
      "epoch: 001250  loss: -0.22392\n",
      "epoch: 001251  loss: -0.19935\n",
      "epoch: 001252  loss: -0.19637\n",
      "epoch: 001253  loss: -0.20541\n",
      "epoch: 001254  loss: -0.22252\n",
      "epoch: 001255  loss: -0.19628\n",
      "epoch: 001256  loss: -0.22574\n",
      "epoch: 001257  loss: -0.20958\n",
      "epoch: 001258  loss: -0.23115\n",
      "epoch: 001259  loss: -0.18619\n",
      "epoch: 001260  loss: -0.24255\n",
      "epoch: 001261  loss: -0.21883\n",
      "3.183333333333333 1.9027777777777775\n",
      "epoch: 001262  loss: -0.21245\n",
      "epoch: 001263  loss: -0.20316\n",
      "epoch: 001264  loss: -0.21819\n",
      "epoch: 001265  loss: -0.19778\n",
      "epoch: 001266  loss: -0.20446\n",
      "epoch: 001267  loss: -0.21999\n",
      "epoch: 001268  loss: -0.20935\n",
      "epoch: 001269  loss: -0.21008\n",
      "epoch: 001270  loss: -0.20445\n",
      "epoch: 001271  loss: -0.21645\n",
      "epoch: 001272  loss: -0.18168\n",
      "epoch: 001273  loss: -0.20696\n",
      "epoch: 001274  loss: -0.19354\n",
      "epoch: 001275  loss: -0.19314\n",
      "epoch: 001276  loss: -0.18964\n",
      "epoch: 001277  loss: -0.19904\n",
      "epoch: 001278  loss: -0.20223\n",
      "epoch: 001279  loss: -0.21180\n",
      "epoch: 001280  loss: -0.21213\n",
      "epoch: 001281  loss: -0.20591\n",
      "3.2 1.8055555555555554\n",
      "epoch: 001282  loss: -0.22490\n",
      "epoch: 001283  loss: -0.24874\n",
      "epoch: 001284  loss: -0.21479\n",
      "epoch: 001285  loss: -0.23234\n",
      "epoch: 001286  loss: -0.19685\n",
      "epoch: 001287  loss: -0.21019\n",
      "epoch: 001288  loss: -0.21581\n",
      "epoch: 001289  loss: -0.21769\n",
      "epoch: 001290  loss: -0.20343\n",
      "epoch: 001291  loss: -0.21264\n",
      "epoch: 001292  loss: -0.19946\n",
      "epoch: 001293  loss: -0.20214\n",
      "epoch: 001294  loss: -0.21477\n",
      "epoch: 001295  loss: -0.22449\n",
      "epoch: 001296  loss: -0.22324\n",
      "epoch: 001297  loss: -0.21101\n",
      "epoch: 001298  loss: -0.19571\n",
      "epoch: 001299  loss: -0.19921\n",
      "epoch: 001300  loss: -0.19995\n",
      "epoch: 001301  loss: -0.21114\n",
      "3.2666666666666666 1.855555555555556\n",
      "epoch: 001302  loss: -0.22228\n",
      "epoch: 001303  loss: -0.22328\n",
      "epoch: 001304  loss: -0.22543\n",
      "epoch: 001305  loss: -0.21215\n",
      "epoch: 001306  loss: -0.20079\n",
      "epoch: 001307  loss: -0.19730\n",
      "epoch: 001308  loss: -0.21728\n",
      "epoch: 001309  loss: -0.21278\n",
      "epoch: 001310  loss: -0.20719\n",
      "epoch: 001311  loss: -0.21906\n",
      "epoch: 001312  loss: -0.21770\n",
      "epoch: 001313  loss: -0.21048\n",
      "epoch: 001314  loss: -0.22287\n",
      "epoch: 001315  loss: -0.21340\n",
      "epoch: 001316  loss: -0.19792\n",
      "epoch: 001317  loss: -0.23368\n",
      "epoch: 001318  loss: -0.20494\n",
      "epoch: 001319  loss: -0.21666\n",
      "epoch: 001320  loss: -0.20773\n",
      "epoch: 001321  loss: -0.20414\n",
      "2.7333333333333334 1.5611111111111113\n",
      "epoch: 001322  loss: -0.22807\n",
      "epoch: 001323  loss: -0.22776\n",
      "epoch: 001324  loss: -0.19992\n",
      "epoch: 001325  loss: -0.22736\n",
      "epoch: 001326  loss: -0.20288\n",
      "epoch: 001327  loss: -0.21232\n",
      "epoch: 001328  loss: -0.20266\n",
      "epoch: 001329  loss: -0.22724\n",
      "epoch: 001330  loss: -0.21060\n",
      "epoch: 001331  loss: -0.22015\n",
      "epoch: 001332  loss: -0.20647\n",
      "epoch: 001333  loss: -0.24120\n",
      "epoch: 001334  loss: -0.20173\n",
      "epoch: 001335  loss: -0.22318\n",
      "epoch: 001336  loss: -0.21621\n",
      "epoch: 001337  loss: -0.21596\n",
      "epoch: 001338  loss: -0.20452\n",
      "epoch: 001339  loss: -0.19444\n",
      "epoch: 001340  loss: -0.20118\n",
      "epoch: 001341  loss: -0.18620\n",
      "2.75 2.0694444444444446\n",
      "epoch: 001342  loss: -0.21011\n",
      "epoch: 001343  loss: -0.19998\n",
      "epoch: 001344  loss: -0.20208\n",
      "epoch: 001345  loss: -0.19716\n",
      "epoch: 001346  loss: -0.21045\n",
      "epoch: 001347  loss: -0.20527\n",
      "epoch: 001348  loss: -0.20156\n",
      "epoch: 001349  loss: -0.21460\n",
      "epoch: 001350  loss: -0.21722\n",
      "epoch: 001351  loss: -0.18698\n",
      "epoch: 001352  loss: -0.20927\n",
      "epoch: 001353  loss: -0.20520\n",
      "epoch: 001354  loss: -0.20540\n",
      "epoch: 001355  loss: -0.19237\n",
      "epoch: 001356  loss: -0.23981\n",
      "epoch: 001357  loss: -0.21611\n",
      "epoch: 001358  loss: -0.19683\n",
      "epoch: 001359  loss: -0.21863\n",
      "epoch: 001360  loss: -0.18373\n",
      "epoch: 001361  loss: -0.20824\n",
      "2.5500000000000003 1.2638888888888888\n",
      "epoch: 001362  loss: -0.20505\n",
      "epoch: 001363  loss: -0.21320\n",
      "epoch: 001364  loss: -0.21202\n",
      "epoch: 001365  loss: -0.20727\n",
      "epoch: 001366  loss: -0.22351\n",
      "epoch: 001367  loss: -0.20743\n",
      "epoch: 001368  loss: -0.21346\n",
      "epoch: 001369  loss: -0.20349\n",
      "epoch: 001370  loss: -0.19777\n",
      "epoch: 001371  loss: -0.21887\n",
      "epoch: 001372  loss: -0.17568\n",
      "epoch: 001373  loss: -0.22317\n",
      "epoch: 001374  loss: -0.20195\n",
      "epoch: 001375  loss: -0.19722\n",
      "epoch: 001376  loss: -0.20595\n",
      "epoch: 001377  loss: -0.19618\n",
      "epoch: 001378  loss: -0.19760\n",
      "epoch: 001379  loss: -0.19380\n",
      "epoch: 001380  loss: -0.18067\n",
      "epoch: 001381  loss: -0.18116\n",
      "2.8999999999999995 1.9666666666666668\n",
      "epoch: 001382  loss: -0.21139\n",
      "epoch: 001383  loss: -0.22650\n",
      "epoch: 001384  loss: -0.18007\n",
      "epoch: 001385  loss: -0.18615\n",
      "epoch: 001386  loss: -0.19895\n",
      "epoch: 001387  loss: -0.19720\n",
      "epoch: 001388  loss: -0.19984\n",
      "epoch: 001389  loss: -0.23058\n",
      "epoch: 001390  loss: -0.19617\n",
      "epoch: 001391  loss: -0.20123\n",
      "epoch: 001392  loss: -0.18709\n",
      "epoch: 001393  loss: -0.19377\n",
      "epoch: 001394  loss: -0.18055\n",
      "epoch: 001395  loss: -0.19511\n",
      "epoch: 001396  loss: -0.18429\n",
      "epoch: 001397  loss: -0.18193\n",
      "epoch: 001398  loss: -0.21113\n",
      "epoch: 001399  loss: -0.17115\n",
      "epoch: 001400  loss: -0.18255\n",
      "epoch: 001401  loss: -0.20176\n",
      "3.45 1.8972222222222221\n",
      "epoch: 001402  loss: -0.20085\n",
      "epoch: 001403  loss: -0.20594\n",
      "epoch: 001404  loss: -0.17894\n",
      "epoch: 001405  loss: -0.20480\n",
      "epoch: 001406  loss: -0.17929\n",
      "epoch: 001407  loss: -0.19940\n",
      "epoch: 001408  loss: -0.20255\n",
      "epoch: 001409  loss: -0.20038\n",
      "epoch: 001410  loss: -0.19929\n",
      "epoch: 001411  loss: -0.18991\n",
      "epoch: 001412  loss: -0.18980\n",
      "epoch: 001413  loss: -0.20043\n",
      "epoch: 001414  loss: -0.19802\n",
      "epoch: 001415  loss: -0.19955\n",
      "epoch: 001416  loss: -0.18983\n",
      "epoch: 001417  loss: -0.22859\n",
      "epoch: 001418  loss: -0.19350\n",
      "epoch: 001419  loss: -0.20566\n",
      "epoch: 001420  loss: -0.20854\n",
      "epoch: 001421  loss: -0.20133\n",
      "3.0166666666666666 1.863888888888889\n",
      "epoch: 001422  loss: -0.20715\n",
      "epoch: 001423  loss: -0.20868\n",
      "epoch: 001424  loss: -0.20486\n",
      "epoch: 001425  loss: -0.19540\n",
      "epoch: 001426  loss: -0.21260\n",
      "epoch: 001427  loss: -0.21948\n",
      "epoch: 001428  loss: -0.21743\n",
      "epoch: 001429  loss: -0.21122\n",
      "epoch: 001430  loss: -0.20457\n",
      "epoch: 001431  loss: -0.22025\n",
      "epoch: 001432  loss: -0.22149\n",
      "epoch: 001433  loss: -0.20116\n",
      "epoch: 001434  loss: -0.20042\n",
      "epoch: 001435  loss: -0.20259\n",
      "epoch: 001436  loss: -0.20728\n",
      "epoch: 001437  loss: -0.21042\n",
      "epoch: 001438  loss: -0.20318\n",
      "epoch: 001439  loss: -0.21466\n",
      "epoch: 001440  loss: -0.21414\n",
      "epoch: 001441  loss: -0.18077\n",
      "3.166666666666667 2.1722222222222225\n",
      "epoch: 001442  loss: -0.21227\n",
      "epoch: 001443  loss: -0.19061\n",
      "epoch: 001444  loss: -0.21272\n",
      "epoch: 001445  loss: -0.19340\n",
      "epoch: 001446  loss: -0.20100\n",
      "epoch: 001447  loss: -0.19270\n",
      "epoch: 001448  loss: -0.19849\n",
      "epoch: 001449  loss: -0.22730\n",
      "epoch: 001450  loss: -0.21392\n",
      "epoch: 001451  loss: -0.20818\n",
      "epoch: 001452  loss: -0.19854\n",
      "epoch: 001453  loss: -0.20969\n",
      "epoch: 001454  loss: -0.20404\n",
      "epoch: 001455  loss: -0.20156\n",
      "epoch: 001456  loss: -0.22525\n",
      "epoch: 001457  loss: -0.21009\n",
      "epoch: 001458  loss: -0.21168\n",
      "epoch: 001459  loss: -0.21956\n",
      "epoch: 001460  loss: -0.19950\n",
      "epoch: 001461  loss: -0.23837\n",
      "2.7666666666666666 1.4833333333333334\n",
      "epoch: 001462  loss: -0.21970\n",
      "epoch: 001463  loss: -0.22098\n",
      "epoch: 001464  loss: -0.21772\n",
      "epoch: 001465  loss: -0.21768\n",
      "epoch: 001466  loss: -0.20798\n",
      "epoch: 001467  loss: -0.21230\n",
      "epoch: 001468  loss: -0.23323\n",
      "epoch: 001469  loss: -0.21988\n",
      "epoch: 001470  loss: -0.21012\n",
      "epoch: 001471  loss: -0.21342\n",
      "epoch: 001472  loss: -0.19339\n",
      "epoch: 001473  loss: -0.22011\n",
      "epoch: 001474  loss: -0.19580\n",
      "epoch: 001475  loss: -0.21320\n",
      "epoch: 001476  loss: -0.22395\n",
      "epoch: 001477  loss: -0.22391\n",
      "epoch: 001478  loss: -0.22152\n",
      "epoch: 001479  loss: -0.19031\n",
      "epoch: 001480  loss: -0.19704\n",
      "epoch: 001481  loss: -0.21729\n",
      "3.15 2.2583333333333337\n",
      "epoch: 001482  loss: -0.20744\n",
      "epoch: 001483  loss: -0.21371\n",
      "epoch: 001484  loss: -0.23764\n",
      "epoch: 001485  loss: -0.22534\n",
      "epoch: 001486  loss: -0.19846\n",
      "epoch: 001487  loss: -0.19331\n",
      "epoch: 001488  loss: -0.21435\n",
      "epoch: 001489  loss: -0.20008\n",
      "epoch: 001490  loss: -0.20971\n",
      "epoch: 001491  loss: -0.20411\n",
      "epoch: 001492  loss: -0.21831\n",
      "epoch: 001493  loss: -0.21753\n",
      "epoch: 001494  loss: -0.21969\n",
      "epoch: 001495  loss: -0.18411\n",
      "epoch: 001496  loss: -0.18597\n",
      "epoch: 001497  loss: -0.20153\n",
      "epoch: 001498  loss: -0.21608\n",
      "epoch: 001499  loss: -0.19284\n",
      "epoch: 001500  loss: -0.19366\n",
      "epoch: 001501  loss: -0.19794\n",
      "2.9333333333333336 1.672222222222222\n",
      "epoch: 001502  loss: -0.18997\n",
      "epoch: 001503  loss: -0.18172\n",
      "epoch: 001504  loss: -0.19573\n",
      "epoch: 001505  loss: -0.21332\n",
      "epoch: 001506  loss: -0.21130\n",
      "epoch: 001507  loss: -0.20650\n",
      "epoch: 001508  loss: -0.19823\n",
      "epoch: 001509  loss: -0.19342\n",
      "epoch: 001510  loss: -0.20308\n",
      "epoch: 001511  loss: -0.19600\n",
      "epoch: 001512  loss: -0.21457\n",
      "epoch: 001513  loss: -0.17928\n",
      "epoch: 001514  loss: -0.18818\n",
      "epoch: 001515  loss: -0.19958\n",
      "epoch: 001516  loss: -0.20099\n",
      "epoch: 001517  loss: -0.18057\n",
      "epoch: 001518  loss: -0.20303\n",
      "epoch: 001519  loss: -0.20570\n",
      "epoch: 001520  loss: -0.19841\n",
      "epoch: 001521  loss: -0.20963\n",
      "2.8833333333333333 1.5305555555555557\n",
      "epoch: 001522  loss: -0.18299\n",
      "epoch: 001523  loss: -0.18007\n",
      "epoch: 001524  loss: -0.20173\n",
      "epoch: 001525  loss: -0.20680\n",
      "epoch: 001526  loss: -0.19700\n",
      "epoch: 001527  loss: -0.20225\n",
      "epoch: 001528  loss: -0.20037\n",
      "epoch: 001529  loss: -0.19167\n",
      "epoch: 001530  loss: -0.21149\n",
      "epoch: 001531  loss: -0.19219\n",
      "epoch: 001532  loss: -0.21315\n",
      "epoch: 001533  loss: -0.18821\n",
      "epoch: 001534  loss: -0.21800\n",
      "epoch: 001535  loss: -0.20732\n",
      "epoch: 001536  loss: -0.19366\n",
      "epoch: 001537  loss: -0.19879\n",
      "epoch: 001538  loss: -0.20079\n",
      "epoch: 001539  loss: -0.21426\n",
      "epoch: 001540  loss: -0.18727\n",
      "epoch: 001541  loss: -0.18773\n",
      "2.8500000000000005 1.9583333333333335\n",
      "epoch: 001542  loss: -0.21236\n",
      "epoch: 001543  loss: -0.20544\n",
      "epoch: 001544  loss: -0.20693\n",
      "epoch: 001545  loss: -0.22069\n",
      "epoch: 001546  loss: -0.21703\n",
      "epoch: 001547  loss: -0.19909\n",
      "epoch: 001548  loss: -0.21391\n",
      "epoch: 001549  loss: -0.20913\n",
      "epoch: 001550  loss: -0.21918\n",
      "epoch: 001551  loss: -0.20778\n",
      "epoch: 001552  loss: -0.18377\n",
      "epoch: 001553  loss: -0.21401\n",
      "epoch: 001554  loss: -0.18952\n",
      "epoch: 001555  loss: -0.23968\n",
      "epoch: 001556  loss: -0.22770\n",
      "epoch: 001557  loss: -0.19379\n",
      "epoch: 001558  loss: -0.21955\n",
      "epoch: 001559  loss: -0.21029\n",
      "epoch: 001560  loss: -0.20142\n",
      "epoch: 001561  loss: -0.22188\n",
      "2.9833333333333334 2.052777777777778\n",
      "epoch: 001562  loss: -0.21993\n",
      "epoch: 001563  loss: -0.18874\n",
      "epoch: 001564  loss: -0.18851\n",
      "epoch: 001565  loss: -0.20824\n",
      "epoch: 001566  loss: -0.21894\n",
      "epoch: 001567  loss: -0.19582\n",
      "epoch: 001568  loss: -0.20807\n",
      "epoch: 001569  loss: -0.19235\n",
      "epoch: 001570  loss: -0.19003\n",
      "epoch: 001571  loss: -0.19348\n",
      "epoch: 001572  loss: -0.17253\n",
      "epoch: 001573  loss: -0.19101\n",
      "epoch: 001574  loss: -0.21302\n",
      "epoch: 001575  loss: -0.19568\n",
      "epoch: 001576  loss: -0.17608\n",
      "epoch: 001577  loss: -0.22377\n",
      "epoch: 001578  loss: -0.22306\n",
      "epoch: 001579  loss: -0.20114\n",
      "epoch: 001580  loss: -0.19527\n",
      "epoch: 001581  loss: -0.17915\n",
      "2.933333333333333 1.911111111111111\n",
      "epoch: 001582  loss: -0.20209\n",
      "epoch: 001583  loss: -0.21680\n",
      "epoch: 001584  loss: -0.22244\n",
      "epoch: 001585  loss: -0.22752\n",
      "epoch: 001586  loss: -0.23224\n",
      "epoch: 001587  loss: -0.20342\n",
      "epoch: 001588  loss: -0.22593\n",
      "epoch: 001589  loss: -0.22384\n",
      "epoch: 001590  loss: -0.21852\n",
      "epoch: 001591  loss: -0.18317\n",
      "epoch: 001592  loss: -0.21001\n",
      "epoch: 001593  loss: -0.19283\n",
      "epoch: 001594  loss: -0.19386\n",
      "epoch: 001595  loss: -0.22257\n",
      "epoch: 001596  loss: -0.19699\n",
      "epoch: 001597  loss: -0.19914\n",
      "epoch: 001598  loss: -0.19792\n",
      "epoch: 001599  loss: -0.21022\n",
      "epoch: 001600  loss: -0.23042\n",
      "epoch: 001601  loss: -0.20457\n",
      "2.8666666666666667 1.65\n",
      "epoch: 001602  loss: -0.17495\n",
      "epoch: 001603  loss: -0.20647\n",
      "epoch: 001604  loss: -0.18908\n",
      "epoch: 001605  loss: -0.22441\n",
      "epoch: 001606  loss: -0.20085\n",
      "epoch: 001607  loss: -0.21683\n",
      "epoch: 001608  loss: -0.22608\n",
      "epoch: 001609  loss: -0.23082\n",
      "epoch: 001610  loss: -0.20942\n",
      "epoch: 001611  loss: -0.23546\n",
      "epoch: 001612  loss: -0.22803\n",
      "epoch: 001613  loss: -0.23635\n",
      "epoch: 001614  loss: -0.21339\n",
      "epoch: 001615  loss: -0.18688\n",
      "epoch: 001616  loss: -0.19833\n",
      "epoch: 001617  loss: -0.20538\n",
      "epoch: 001618  loss: -0.23298\n",
      "epoch: 001619  loss: -0.23579\n",
      "epoch: 001620  loss: -0.22582\n",
      "epoch: 001621  loss: -0.19281\n",
      "2.783333333333333 1.8138888888888889\n",
      "epoch: 001622  loss: -0.19362\n",
      "epoch: 001623  loss: -0.20232\n",
      "epoch: 001624  loss: -0.20695\n",
      "epoch: 001625  loss: -0.21280\n",
      "epoch: 001626  loss: -0.21464\n",
      "epoch: 001627  loss: -0.20946\n",
      "epoch: 001628  loss: -0.19603\n",
      "epoch: 001629  loss: -0.19127\n",
      "epoch: 001630  loss: -0.22012\n",
      "epoch: 001631  loss: -0.20245\n",
      "epoch: 001632  loss: -0.20608\n",
      "epoch: 001633  loss: -0.18375\n",
      "epoch: 001634  loss: -0.21051\n",
      "epoch: 001635  loss: -0.17109\n",
      "epoch: 001636  loss: -0.20855\n",
      "epoch: 001637  loss: -0.20373\n",
      "epoch: 001638  loss: -0.21546\n",
      "epoch: 001639  loss: -0.20582\n",
      "epoch: 001640  loss: -0.19380\n",
      "epoch: 001641  loss: -0.17613\n",
      "2.7666666666666666 1.8611111111111112\n",
      "epoch: 001642  loss: -0.21209\n",
      "epoch: 001643  loss: -0.19327\n",
      "epoch: 001644  loss: -0.18906\n",
      "epoch: 001645  loss: -0.18690\n",
      "epoch: 001646  loss: -0.19481\n",
      "epoch: 001647  loss: -0.20695\n",
      "epoch: 001648  loss: -0.20822\n",
      "epoch: 001649  loss: -0.21907\n",
      "epoch: 001650  loss: -0.20484\n",
      "epoch: 001651  loss: -0.20791\n",
      "epoch: 001652  loss: -0.22044\n",
      "epoch: 001653  loss: -0.18997\n",
      "epoch: 001654  loss: -0.20038\n",
      "epoch: 001655  loss: -0.19818\n",
      "epoch: 001656  loss: -0.20672\n",
      "epoch: 001657  loss: -0.21350\n",
      "epoch: 001658  loss: -0.22422\n",
      "epoch: 001659  loss: -0.21602\n",
      "epoch: 001660  loss: -0.18084\n",
      "epoch: 001661  loss: -0.19464\n",
      "3.066666666666667 1.9222222222222225\n",
      "epoch: 001662  loss: -0.18779\n",
      "epoch: 001663  loss: -0.22574\n",
      "epoch: 001664  loss: -0.22744\n",
      "epoch: 001665  loss: -0.20941\n",
      "epoch: 001666  loss: -0.20338\n",
      "epoch: 001667  loss: -0.20390\n",
      "epoch: 001668  loss: -0.23178\n",
      "epoch: 001669  loss: -0.20863\n",
      "epoch: 001670  loss: -0.21925\n",
      "epoch: 001671  loss: -0.22709\n",
      "epoch: 001672  loss: -0.22214\n",
      "epoch: 001673  loss: -0.23015\n",
      "epoch: 001674  loss: -0.19413\n",
      "epoch: 001675  loss: -0.20826\n",
      "epoch: 001676  loss: -0.20588\n",
      "epoch: 001677  loss: -0.20653\n",
      "epoch: 001678  loss: -0.19735\n",
      "epoch: 001679  loss: -0.21052\n",
      "epoch: 001680  loss: -0.20980\n",
      "epoch: 001681  loss: -0.17916\n",
      "3.1833333333333336 2.297222222222222\n",
      "epoch: 001682  loss: -0.21816\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"WANDB_MODE\"] = \"online\" #\"dryrun\"\n",
    "\n",
    "SWEEP_ID = wandb.sweep(sweep_config, project=PROJECT_NAME)\n",
    "wandb.agent(SWEEP_ID, project=PROJECT_NAME, function=start_agent_envelope, count=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DHcAvy-w6Zlu"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
